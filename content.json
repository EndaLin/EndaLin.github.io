{"meta":{"title":"Enda Lin","subtitle":"keep foolish, keep sharp","description":"所有的伟大都是从零开始","author":"Enda Lin","url":"https://wt-git-repository.github.io"},"pages":[{"title":"404","date":"2019-03-06T09:36:02.000Z","updated":"2019-07-08T01:15:52.653Z","comments":true,"path":"404/index.html","permalink":"https://wt-git-repository.github.io/404/index.html","excerpt":"","text":""},{"title":"Enda Lin","date":"2019-03-06T09:36:26.000Z","updated":"2019-07-08T01:15:52.739Z","comments":true,"path":"about/index.html","permalink":"https://wt-git-repository.github.io/about/index.html","excerpt":"","text":"13727782882 &nbsp;&nbsp;&nbsp;endawt.lin@gmail.com广东省东莞市松山湖高新技术产业开发区大学路1号 求职意向: JAVA后端开发实习生 教育背景 2016年 - 至今&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;东莞理工学院&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;本科（一本专业）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;软件工程(卓越计划班) 在校成绩 专业绩点稳定前5%, 曾夺绩点专业第一 个人技能 熟悉掌握JAVA， 了解Python、c/c++等语言 熟悉在Linux环境下编程，熟悉使用Docker基本命令，熟悉编写Dockerfile与docker-compose.yml文件 熟悉常用的数据结构与算法 熟悉Mysql基本操作， 了解Oracle 熟悉掌握Spring、Spring MVC、MyBatis等常用框架，了解消息队列等其它框架 熟悉Eureka、Zuul、Spring boot admin、Ribbon、 Hystrix等微服务框架的常用配置 熟悉使用Nginx反向代理与负载均衡 熟悉git、GitHub、gitlab的使用 项目经验2019年1月20日-至今&nbsp;&nbsp;&nbsp;&nbsp;东莞理工学院心理测评系统&nbsp;&nbsp;&nbsp;&nbsp;系统开发主要负责人 职责: ① 负责这个系统的开发流程，保证系统的开发进度 ② 使用Spring、Spring MVC、Druid、MyBatis以及Redis搭建后台框架，对用户填写的问卷数据进行清洗，并将分析的结果返回给用户 ③基于Websocket实现前后端的实时通讯，让用户可以及时地获知问卷分析的进度 ④基于Druid搭建系统性能的监控平台 ⑤使用Docker将项目部署到学校服务器中。 2018年4月20日-2018年5月20日&nbsp;&nbsp;&nbsp;&nbsp;基于人脸识别的考勤系统&nbsp;&nbsp;&nbsp;&nbsp;后端开发主要负责人 职责: ①负责技术开发相关的总体事项，保证项目的进度 ②基予Servlet实现后端功能，为小程序提供人脸识别、基于人脸数据去定位学生信息、自动录入并更新考勤数据、录入课程表、录入学生脸部等一系列功能 ③搭建WEB后台管理，对考勤数据、学生信息管理、班级管理等提供一系列的支持。 获奖经历（算法类） 2019年第十届蓝桥杯全国总决赛JAVA程序设计二等奖 2019年第十届蓝桥杯广东省赛区JAVA程序设计一等奖 2018年度软件工程系”微三云杯”程序设计竞赛(算法类)一等奖（JAVA） 2018年第九届蓝桥杯广东省赛区C/C++程序设计二等奖 2017年第八届蓝桥杯广东省赛区C/C++程序设计三等奖 相关主页 github 个人博客 致谢 感谢您花时间阅读我的简历，期待能有机会和您共事。"},{"title":"All categories","date":"2019-03-06T09:18:23.000Z","updated":"2019-07-08T01:15:52.740Z","comments":true,"path":"categories/index.html","permalink":"https://wt-git-repository.github.io/categories/index.html","excerpt":"","text":""},{"title":"All tags","date":"2019-03-06T09:16:39.000Z","updated":"2019-07-08T01:15:52.741Z","comments":true,"path":"tags/index.html","permalink":"https://wt-git-repository.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Spring Secutiry 登陆源码分析","slug":"CasAuthenticationFilter","date":"2019-07-11T01:18:30.000Z","updated":"2019-07-11T06:26:56.421Z","comments":true,"path":"2019/07/11/CasAuthenticationFilter/","link":"","permalink":"https://wt-git-repository.github.io/2019/07/11/CasAuthenticationFilter/","excerpt":"CasAuthenticationFilter 简介|（版本：3.0.7）处理Cas service ticket Service Tickets一个服务票据是由一串加密的票证字符串组成， 服务票据是用户的浏览器通过Cas Server 认证后， 通过HTTP Redirect 到资源服务器中， 而服务票据是通过其中的请求参数中获取到的。 过滤器监视着Service URL 以致于它可以接收到服务票据并进行处理，The CAS server knows which service URL to use via the ServiceProperties.getService() method。 Processing the service ticket involves creating a UsernamePasswordAuthenticationToken(the principal and the opaque ticket string as the credentials) which uses CAS_STATEFUL_IDENTIFIER for the principal and the opaque ticket string as the credentials.(通过服务票据生成 UsernamePasswordAuthenticationToken) The configured AuthenticationManager is expected to provide a provider that can recognise UsernamePasswordAuthenticationTokens containing this special principal name, and process them accordingly by validation with the CAS server.（通过AuthenticationManager 依据Cas server 来处理识别该证书）","text":"CasAuthenticationFilter 简介|（版本：3.0.7）处理Cas service ticket Service Tickets一个服务票据是由一串加密的票证字符串组成， 服务票据是用户的浏览器通过Cas Server 认证后， 通过HTTP Redirect 到资源服务器中， 而服务票据是通过其中的请求参数中获取到的。 过滤器监视着Service URL 以致于它可以接收到服务票据并进行处理，The CAS server knows which service URL to use via the ServiceProperties.getService() method。 Processing the service ticket involves creating a UsernamePasswordAuthenticationToken(the principal and the opaque ticket string as the credentials) which uses CAS_STATEFUL_IDENTIFIER for the principal and the opaque ticket string as the credentials.(通过服务票据生成 UsernamePasswordAuthenticationToken) The configured AuthenticationManager is expected to provide a provider that can recognise UsernamePasswordAuthenticationTokens containing this special principal name, and process them accordingly by validation with the CAS server.（通过AuthenticationManager 依据Cas server 来处理识别该证书） By configuring a shared ProxyGrantingTicketStorage between the TicketValidator and the CasAuthenticationFilter one can have the CasAuthenticationFilter handle the proxying requirements for CAS. In addition, the URI endpoint for the proxying would also need to be configured (i.e. the part after protocol, hostname, and port).（代理相关） Spring Secutiry 登陆基本流程（源码分析）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226 /** * AbstractAuthenticationProcessingFilter */ public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws IOException, ServletException &#123; HttpServletRequest request = (HttpServletRequest)req; HttpServletResponse response = (HttpServletResponse)res; /* * Invokes the requiresAuthentication method to determine whether the request is for * authentication and should be handled by this filter.（如果是需要认证的话， 再进入此过滤类） */ if (!this.requiresAuthentication(request, response)) &#123; chain.doFilter(request, response); &#125; else &#123; if (this.logger.isDebugEnabled()) &#123; this.logger.debug(\"Request is to process authentication\"); &#125; Authentication authResult; try &#123; /* * If it is an authentication request, the attemptAuthentication will be invoked to perform the authentication. (调用了子类的方法) */ authResult = this.attemptAuthentication(request, response); if (authResult == null) &#123; return; &#125; // // 最终认证成功后，会处理一些与session相关的方法（比如将认证信息存到session等操作） this.sessionStrategy.onAuthentication(authResult, request, response); &#125; catch (InternalAuthenticationServiceException var8) &#123; this.logger.error(\"An internal error occurred while trying to authenticate the user.\", var8); this.unsuccessfulAuthentication(request, response, var8); return; &#125; catch (AuthenticationException var9) &#123; this.unsuccessfulAuthentication(request, response, var9); return; &#125; if (this.continueChainBeforeSuccessfulAuthentication) &#123; chain.doFilter(request, response); &#125; /* * 最终认证成功后的相关回调方法，主要将当前的认证信息放到SecurityContextHolder中 * 并调用成功处理器做相应的操作。 */ this.successfulAuthentication(request, response, chain, authResult); &#125; &#125; /** * CasAuthenticationFilter * * Performs actual authentication. * 1.Return a populated authentication token for the authenticated user, indicating * successful authentication * 2.Return null, indicating that the authentication process is still in progress. Before * returning, the implementation should perform any additional work required to complete the * process. * 3.Throw an AuthenticationException if the authentication process fails */ public Authentication attemptAuthentication(HttpServletRequest request, HttpServletResponse response) throws AuthenticationException, IOException &#123; if (this.proxyReceptorRequest(request)) &#123; this.logger.debug(\"Responding to proxy receptor request\"); CommonUtils.readAndRespondToProxyReceptorRequest(request, response, this.proxyGrantingTicketStorage); return null; &#125; else &#123; boolean serviceTicketRequest = this.serviceTicketRequest(request, response); String username = serviceTicketRequest ? \"_cas_stateful_\" : \"_cas_stateless_\"; String password = this.obtainArtifact(request); if (password == null) &#123; this.logger.debug(\"Failed to obtain an artifact (cas ticket)\"); password = \"\"; &#125; UsernamePasswordAuthenticationToken authRequest = new UsernamePasswordAuthenticationToken(username, password); authRequest.setDetails(this.authenticationDetailsSource.buildDetails(request)); // 调用Authentication（ProviderManager） return this.getAuthenticationManager().authenticate(authRequest); &#125; &#125; /* * UsernamePasswordAuthenticationToken * * 保存用户信息， 并设置授权为false */ public UsernamePasswordAuthenticationToken(Object principal, Object credentials) &#123; super((Collection)null); this.principal = principal; this.credentials = credentials; this.setAuthenticated(false); &#125; /* * AuthenticationManager -&gt; ProviderManager * * 进行校验工作 */ public Authentication authenticate(Authentication authentication) throws AuthenticationException &#123; Class&lt;? extends Authentication&gt; toTest = authentication.getClass(); AuthenticationException lastException = null; Authentication result = null; boolean debug = logger.isDebugEnabled(); Iterator var6 = this.getProviders().iterator(); while(var6.hasNext()) &#123; AuthenticationProvider provider = (AuthenticationProvider)var6.next(); if (provider.supports(toTest)) &#123; if (debug) &#123; logger.debug(\"Authentication attempt using \" + provider.getClass().getName()); &#125; try &#123; result = provider.authenticate(authentication); // 如果有处理器成功处理， 则退出 if (result != null) &#123; this.copyDetails(authentication, result); break; &#125; &#125; catch (AccountStatusException var11) &#123; this.prepareException(var11, authentication); throw var11; &#125; catch (InternalAuthenticationServiceException var12) &#123; this.prepareException(var12, authentication); throw var12; &#125; catch (AuthenticationException var13) &#123; lastException = var13; &#125; &#125; &#125; // 如果没有处理器能够处理， 则调用父类的 if (result == null &amp;&amp; this.parent != null) &#123; try &#123; result = this.parent.authenticate(authentication); &#125; catch (ProviderNotFoundException var9) &#123; ; &#125; catch (AuthenticationException var10) &#123; lastException = var10; &#125; &#125; if (result != null) &#123; if (this.eraseCredentialsAfterAuthentication &amp;&amp; result instanceof CredentialsContainer) &#123; ((CredentialsContainer)result).eraseCredentials(); &#125; this.eventPublisher.publishAuthenticationSuccess(result); return result; &#125; else &#123; if (lastException == null) &#123; lastException = new ProviderNotFoundException(this.messages.getMessage(\"ProviderManager.providerNotFound\", new Object[]&#123;toTest.getName()&#125;, \"No AuthenticationProvider found for &#123;0&#125;\")); &#125; this.prepareException((AuthenticationException)lastException, authentication); throw lastException; &#125; &#125; /* * AuthenticationProvider -&gt; AbstractUserDetailsAuthenticationProvider */ public Authentication authenticate(Authentication authentication) throws AuthenticationException &#123; Assert.isInstanceOf(UsernamePasswordAuthenticationToken.class, authentication, this.messages.getMessage(\"AbstractUserDetailsAuthenticationProvider.onlySupports\", \"Only UsernamePasswordAuthenticationToken is supported\")); String username = authentication.getPrincipal() == null ? \"NONE_PROVIDED\" : authentication.getName(); boolean cacheWasUsed = true; UserDetails user = this.userCache.getUserFromCache(username); if (user == null) &#123; cacheWasUsed = false; try &#123; user = this.retrieveUser(username, (UsernamePasswordAuthenticationToken)authentication); &#125; catch (UsernameNotFoundException var6) &#123; this.logger.debug(\"User '\" + username + \"' not found\"); if (this.hideUserNotFoundExceptions) &#123; throw new BadCredentialsException(this.messages.getMessage(\"AbstractUserDetailsAuthenticationProvider.badCredentials\", \"Bad credentials\")); &#125; throw var6; &#125; Assert.notNull(user, \"retrieveUser returned null - a violation of the interface contract\"); &#125; /** * DaoAuthenticationProvider */ protected final UserDetails retrieveUser(String username, UsernamePasswordAuthenticationToken authentication) throws AuthenticationException &#123; UserDetails loadedUser; try &#123; loadedUser = this.getUserDetailsService().loadUserByUsername(username); &#125; catch (UsernameNotFoundException var6) &#123; if (authentication.getCredentials() != null) &#123; String presentedPassword = authentication.getCredentials().toString(); this.passwordEncoder.isPasswordValid(this.userNotFoundEncodedPassword, presentedPassword, (Object)null); &#125; throw var6; &#125; catch (Exception var7) &#123; throw new InternalAuthenticationServiceException(var7.getMessage(), var7); &#125; if (loadedUser == null) &#123; throw new InternalAuthenticationServiceException(\"UserDetailsService returned null, which is an interface contract violation\"); &#125; else &#123; return loadedUser; &#125; &#125; /* * DaoUserDetailsService 自定义 */ @Overridepublic UserDetails loadUserByUsername(final String username) throws UsernameNotFoundException &#123; try &#123; final User user = userRepository.loadUserByUsername(username); if (user == null) &#123; throw new Exception(\"用户名或密码错误\"); &#125; MyUserPrincipal myPrincipal = new MyUserPrincipal(user.getIsadmin(), user.getRealname(),user.getId(), user.getPassword(), MyUserPrincipal.getAuthorities(user.getRoles())); return myPrincipal; &#125; catch (final Exception e) &#123; throw new RuntimeException(e); &#125;&#125; 官方文档 CasAuthenticationFilter 官方文档 AbstractAuthenticationProcessingFilter 官方文档 简书上的相关解释","categories":[],"tags":[{"name":"Spring Secutiry, Cas","slug":"Spring-Secutiry-Cas","permalink":"https://wt-git-repository.github.io/tags/Spring-Secutiry-Cas/"}]},{"title":"基于pageable实现分页操作","slug":"基于Pageable实现分页操作","date":"2019-07-10T03:49:23.000Z","updated":"2019-07-10T03:57:57.979Z","comments":true,"path":"2019/07/10/基于Pageable实现分页操作/","link":"","permalink":"https://wt-git-repository.github.io/2019/07/10/基于Pageable实现分页操作/","excerpt":"","text":"简介 Pageable 是Spring Data库中定义的一个接口，该接口是所有分页相关信息的一个抽象，通过该接口，我们可以得到和分页相关所有信息（例如pageNumber、pageSize等），这样，Jpa就能够通过pageable参数来得到一个带分页信息的Sql语句。 Page类也是Spring Data提供的一个接口，该接口表示一部分数据的集合以及其相关的下一部分数据、数据总数等相关信息，通过该接口，我们可以得到数据的总体信息（数据总数、总页数…）以及当前数据的信息（当前数据的集合、当前页数等） 通过参数获取Pageable1234567@RequestMapping(value = \"/params\", method=RequestMethod.GET)public Page&lt;Blog&gt; getEntryByParams(@RequestParam(value = \"page\", defaultValue = \"0\") Integer page, @RequestParam(value = \"size\", defaultValue = \"15\") Integer size) &#123; Sort sort = new Sort(Direction.DESC, \"id\"); Pageable pageable = new PageRequest(page, size, sort); return blogRepository.findAll(pageable);&#125; 直接获取Pageable 对象当Spring发现这个参数时，Spring会自动的根据request的参数来组装该pageable对象，Spring支持的request参数如下： page，第几页，从0开始，默认为第0页 size，每一页的大小，默认为20 sort，排序相关的信息，以property,property(,ASC|DESC)的方式组织，例如sort=firstname&amp;sort=lastname,desc表示在按firstname正序排列基础上按lastname倒序排列 12345@RequestMapping(value = \"\", method=RequestMethod.GET)public Page&lt;Blog&gt; getEntryByPageable(@PageableDefault(value = 15, sort = &#123; \"id\" &#125;, direction = Sort.Direction.DESC) Pageable pageable) &#123; return blogRepository.findAll(pageable);&#125; 参考 Spring Data Jpa: 分页和排序 Pageable 前台传参","categories":[],"tags":[{"name":"Spring Data Jpa","slug":"Spring-Data-Jpa","permalink":"https://wt-git-repository.github.io/tags/Spring-Data-Jpa/"}]},{"title":"Java自定义Annotation注解","slug":"Java自定义Annotation注解","date":"2019-07-10T01:35:39.000Z","updated":"2019-07-10T03:38:25.501Z","comments":true,"path":"2019/07/10/Java自定义Annotation注解/","link":"","permalink":"https://wt-git-repository.github.io/2019/07/10/Java自定义Annotation注解/","excerpt":"元注解元注解的作用在于： 负责注解其它注解。 @Target @Retention @Documented @Inherited @Target@Target 说明了Annotation 所修饰的对象的范围， 使用枚举类ElementType 来指定。 123456789101112131415161718192021222324252627282930313233343536373839public enum ElementType &#123; /** Class, interface (including annotation type), or enum declaration */ TYPE, /** Field declaration (includes enum constants) */ FIELD, /** Method declaration */ METHOD, /** Formal parameter declaration */ PARAMETER, /** Constructor declaration */ CONSTRUCTOR, /** Local variable declaration */ LOCAL_VARIABLE, /** Annotation type declaration */ ANNOTATION_TYPE, /** Package declaration */ PACKAGE, /** * Type parameter declaration * * @since 1.8 */ TYPE_PARAMETER, /** * Use of a type * * @since 1.8 */ TYPE_USE&#125;","text":"元注解元注解的作用在于： 负责注解其它注解。 @Target @Retention @Documented @Inherited @Target@Target 说明了Annotation 所修饰的对象的范围， 使用枚举类ElementType 来指定。 123456789101112131415161718192021222324252627282930313233343536373839public enum ElementType &#123; /** Class, interface (including annotation type), or enum declaration */ TYPE, /** Field declaration (includes enum constants) */ FIELD, /** Method declaration */ METHOD, /** Formal parameter declaration */ PARAMETER, /** Constructor declaration */ CONSTRUCTOR, /** Local variable declaration */ LOCAL_VARIABLE, /** Annotation type declaration */ ANNOTATION_TYPE, /** Package declaration */ PACKAGE, /** * Type parameter declaration * * @since 1.8 */ TYPE_PARAMETER, /** * Use of a type * * @since 1.8 */ TYPE_USE&#125; @Retention@Retention ： 用于描述注解的生命周期， 即被描述的注解在什么范围内有效。 取值范围有(在枚举类RetentionPolicy 中有说明)： SOURCE：在源文件中有效（即在源文件中保留） CLASS：在class 文件中有效（即在CLASS 文件中保留） RUNTIME：在运行时有效（即在运行时保留） 123456789101112131415161718192021public enum RetentionPolicy &#123; /** * Annotations are to be discarded by the compiler. */ SOURCE, /** * Annotations are to be recorded in the class file by the compiler * but need not be retained by the VM at run time. This is the default * behavior. */ CLASS, /** * Annotations are to be recorded in the class file by the compiler and * retained by the VM at run time, so they may be read reflectively. * * @see java.lang.reflect.AnnotatedElement */ RUNTIME&#125; @Documented@Documented 用于描述其它类型的annotation应该被作为被标注的程序成员的公共API，因此可以被例如javadoc此类的工具文档化。Documented是一个标记注解，没有成员。 @Inherited@Inherited 是一个标记注解， 阐述了某个被标注的类型是被继承的， 参考文档 深入理解Java：注解（Annotation）自定义注解入门 秒懂，Java 注解 （Annotation）你可以这样学 深入了解Java 发射机制","categories":[],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://wt-git-repository.github.io/tags/JAVA/"}]},{"title":"Hadoop学习笔记⑤","slug":"hadoop学习笔记⑤","date":"2019-06-29T01:21:33.000Z","updated":"2019-07-11T11:25:25.272Z","comments":true,"path":"2019/06/29/hadoop学习笔记⑤/","link":"","permalink":"https://wt-git-repository.github.io/2019/06/29/hadoop学习笔记⑤/","excerpt":"云计算云计算是分布式计算、并行计算、效用计算、网络存储、虚拟化、负载均衡等计算机和网络技术发展融合的产物。 云计算主要包括3种类型： IaaS、PaaS 和SaaS。 云数据库云数据库是部署和虚拟化在云计算环境中的数据库。 MapReduce思想: 分而治之， 把一个大的数据块拆分为多个小的数据块在不同的机器上并行处理。","text":"云计算云计算是分布式计算、并行计算、效用计算、网络存储、虚拟化、负载均衡等计算机和网络技术发展融合的产物。 云计算主要包括3种类型： IaaS、PaaS 和SaaS。 云数据库云数据库是部署和虚拟化在云计算环境中的数据库。 MapReduce思想: 分而治之， 把一个大的数据块拆分为多个小的数据块在不同的机器上并行处理。 Map - Reduce 任务： 通常运行为数据存储节点上， 由此可使计算任务和数据存储在同一个节点之上， 无需额外的数据传输开销， 当Map 任务结束之后， 会生成以&lt;K, V&gt; 形式的中间结果， 然后分配给多个Reduce 任务去执行， 具有相同的Key 的任务会被分配到同一个Reduce 任务， Reduce 任务会对中间结果进行处理， 得到最终结果， 然后输出的分布式配置文件中。 注意： 不同的Map 任务之间以及不同的Reduce 任务之间是不会发生任何的信息交换。 工作流程 首先使用InputFormat 模块做Map 前的预处理， 然后将文件切分为逻辑上多个InputSplit， InputSplit 是Map Reduce 对文件进行处理和运算的处理单位， 只是一个逻辑概念， 并没有进行实际的切分， 只是记录了需要处理的数据的位置和长度。 由于InputSplit 是逻辑分而不是物理分， 所以还需要通过RecordReader 根据InputSplit 中的信息来处理InputSplit 中的具体信息， 加载数据并转换成适合Map 任务读取的键值对. Map 任务会根据用户自定义的映射规则， 输出一系列的&lt;K, V&gt; 作为中间结果 在将Map 任务输出的中间结果交给Reduce 任务处理之前， 需要经过shuffle 处理， 从无序的&lt;key, value&gt; 到有序的&lt;key, value-list&gt;。 Reduce 以一系列&lt;key, value-list&gt; 作为输入， 按照用户定义的逻辑， 将处理结果输出到OutFormat 模块。 OutputFormat 会验证输出目录是否存在, 或者输出类型是否符合配置文件中的配置类型, 如果都满足则输出到HDFS 中. Shuffle 过程详解Shuffle 是整个MapReduce 的核心， 对Map 输出结果进行分区、排序以及合并等处理并交给Reduce 的过程， Shuffle 分为Map 端操作和Reduce 端操作。 在Map 端的Shuffle 过程 每个Map 任务都会被分配到一个缓存， 默认大写是100M Map 的输出结果会暂时被写入缓存中， 当缓存满时， 会启动溢写操作， 把缓存中的数据进行分区， 并对同一个分区里面的数据进行合并（合并是指对有着相同Key 值的数据加起来， 以减少需要溢写到磁盘的数据量）， 然后写入磁盘文件（此举可以减少对磁盘的I/O 操作）， 并清空缓存， 每次溢写操作， 都会生成一个溢写文件， 当Map 任务结束之后， 这些溢写文件就会被合并成一个大的磁盘文件(此时会对所有的数据进行合并操作)， 最终会生成一个统一的大文件， 但是这个大文件是被分区的， 然后通知Reduce 来领取属于自己的处理数据， 不同分区的数据会被分发到不同的Reduce 上执行。 为了使得Map 的写入操作可以持续进行， 需要让缓存留有一定的空间， 而不是等缓存满了之后在进行溢写操作。此处会有一个溢写比例。 合并例子： &lt;k1, v1&gt; 与&lt;k1, v2&gt; 合并成&lt;k1, &lt;v1, v2&gt;&gt; 在Reduce 端的Shuffle 过程Reduce 任务从Map 端的不同机器领取属于自己的那一份数据， 然后对数据进行合并， 接着进行处理。 两个流程： 领取数据： Reduce会开多个线程去向多个Map 任务所在的机器去领取数据 归并数据： 从Map 端领取回来的数据会先保存在缓存中， 如果缓存占满了， 会触发溢写操作（此时也会对数据进行合并）， 将数据写到磁盘中， 每次溢写都会产生一个溢写文件， 最后当所有数据都被领取完毕之后， 就会对所有的溢写文件进行归并排序 将数据输入到Reduce 任务：经过多轮归并会生成多个大文件（Map 端是一个）， 这几个大文件不会继续归并成一个新的大文件， 而是直接输入到Reduce 任务中， 接下来Reduce 任务会执行操作， 将处理结果输出到HDFS 中。","categories":[],"tags":[{"name":"Hadoop","slug":"Hadoop","permalink":"https://wt-git-repository.github.io/tags/Hadoop/"}]},{"title":"Hadoop学习笔记④","slug":"hadoop学习笔记④","date":"2019-06-28T01:05:05.000Z","updated":"2019-07-08T01:15:52.718Z","comments":true,"path":"2019/06/28/hadoop学习笔记④/","link":"","permalink":"https://wt-git-repository.github.io/2019/06/28/hadoop学习笔记④/","excerpt":"NoSQL典型的NoSQL 数据库通常包括键值数据库、列族数据库、文档数据库和图数据库。 键值数据库（Redis）键值数据库会使用一个哈希表， 这个表有一个特定的Key 和一个指定特定的Value。 键值数据库可以划分为内存键值数据库和持久化键值数据库。 弱点： 条件查询、多表查询， 不支持回滚， 无法支持事务。","text":"NoSQL典型的NoSQL 数据库通常包括键值数据库、列族数据库、文档数据库和图数据库。 键值数据库（Redis）键值数据库会使用一个哈希表， 这个表有一个特定的Key 和一个指定特定的Value。 键值数据库可以划分为内存键值数据库和持久化键值数据库。 弱点： 条件查询、多表查询， 不支持回滚， 无法支持事务。 列族数据库（BigTable、HBase）列族数据库一般采用列族数据库模型， 数据库由多个行构成， 每行数据包括多个列族， 不同的行可以具有不同数量的列族， 属于同一列族的数据会被存储在一起。 文档数据库（MongoDB）在文档数据库中， 文档是数据库的最小单位。 虽然每一种文档数据库的部署有所不同， 但是大都假定文档以某种标准化格式封装并对数据进行加密， 同时用多种格式进行解密， 包括XML、 YAML 和JSON 等等。 文档数据库既可以根据键Key来构建索引， 也可以基于文档内容来构建索引。 图数据库图数据库是以图论为基础， 一个图是一个数学概念， 用来表示一个对象集合， 包括顶点以及连接顶点的边。 NoSQL的三大基石NoSQL 的三大基石包括CAP、 BASE 和最终一致性。 NewSQL 数据库（Spanner）NewSQL 不但具有NoSQL 对海量数据的存储管理能力， 还保持了传统数据库支持ACID 和SQL 等特性。 各类数据库的汇集","categories":[],"tags":[{"name":"Hadoop","slug":"Hadoop","permalink":"https://wt-git-repository.github.io/tags/Hadoop/"}]},{"title":"Hadoop学习笔记③","slug":"hadoop学习笔记③","date":"2019-06-27T04:53:00.000Z","updated":"2019-07-08T01:15:52.716Z","comments":true,"path":"2019/06/27/hadoop学习笔记③/","link":"","permalink":"https://wt-git-repository.github.io/2019/06/27/hadoop学习笔记③/","excerpt":"分布式数据库HBaseHBase 是BigTable的开源实现， 高可靠、高性能、面向列、可伸缩的分布式数据库， 主要用来存储非结构化数据和半结构化的松散数据， HBase支持超大规模数据存储， 可以通过水平扩展的方式， 利用廉价计算机集群处理超过10亿行数据和数百位列组成的数据表。 BigTableBigTable是一个分布式存储系统， 利用谷歌提出的MapReduce分布式并行计算模型来处理海量初级， 利用GFS作为底层数据存储， 并采用Chubby提供协同服务管理， 可以扩展到PB级别的数据和上千台机器。","text":"分布式数据库HBaseHBase 是BigTable的开源实现， 高可靠、高性能、面向列、可伸缩的分布式数据库， 主要用来存储非结构化数据和半结构化的松散数据， HBase支持超大规模数据存储， 可以通过水平扩展的方式， 利用廉价计算机集群处理超过10亿行数据和数百位列组成的数据表。 BigTableBigTable是一个分布式存储系统， 利用谷歌提出的MapReduce分布式并行计算模型来处理海量初级， 利用GFS作为底层数据存储， 并采用Chubby提供协同服务管理， 可以扩展到PB级别的数据和上千台机器。 HBase 利用Hadoop MapReduce来处理HBase中的海量数据， 实现高性能计算 利用Zookpper来作为协同服务， 实现稳定服务和失败恢复 利用HDFS作为高可靠的底层存储， 利用廉价集群提供海量数据存储能力 为了方便在HBase上进行数据处理， Sqoop为HBase提供了高效、便捷的RDBMS数据导入功能， Pig和Hive为HBase提供了高层语言支持。 HBase 数据类型HBase 是一个稀疏、多维度、排序的映射表， 这张表的索引是行健、列族、列限定符和时间戳， 每个值是一个未经解释的字符串byte[]， 没有数据类型。 用户在表中存储数据， 每一行都有一个可排序的行键和任意多的列。 表在水平方向有一个或者多个列族组成， 一个列族可以包含任意多个列， 同一个列族里面的数据存储在一起。 列族支持动态扩展， 无需预定列的数量以及类型， 所有列均以字符串形式存储， 同一张表里面的每一行数据都可以有截然不同的列。 在HBase 中执行更新操作时， 并不会删除数据旧的版本， 而是生成一个新的版本， 旧的版本仍然保留， HBase 可以对允许保留的版本的数量进行设置。 HBase 数据模型的相关概念 表 行 列族 列限定符 单元格 时间戳 HBase 使用坐标来定位表中数据， 四维坐标[行键， 列族， 列限定符， 时间戳]。 行式数据库和列式数据库行式数据库主要适合于小批量的数据处理 列式数据库适合于批量数据处理和即席查询， 可以降低I/O开销， 支持大量并发用户查询， 其数据处理速度比传统方法快100倍， 因为仅仅需要处理可以回答这些查询的列， 而不是分类整理与特定查询无关的数据行， 具有较高的数据压缩比。 HBase 的实现原理HBase 的功能组件： 库函数（链接到每个客户端） 一个Master主服务器： 负责管理和维护HBase 表的分区信息。 许多个Region服务器: 负责维护存储和维护分配给自己的Region， 处理来自客户端的读写请求。 客户端并不是直接从Master主服务器读取数据， 而是在获取Region 的存储位置信息后， 直接从Region上读取数据， HBase 客户端并不依赖Master 而是借助 Zookeeper 来获取Region的位置信息的。 表与Region 对于每一个HBase 表而言， 表中的行是根据行键的值的字段序进行维护的， 由于表中包含的行的数量可能非常庞大， 无法存储在一台机器上， 所有需要分布式存储， 需要根据行键的值对表中的行进行分区， 每个行区间构成一个Region， 它是负载均衡和数据分发的基本单位， 这些Region会被分发到不同的Region服务器。 Region 的定位 每个Region 都有一个Region ID（表名 + 开始主键 + Region ID）来标识它的唯一性。 Region 映射表（元数据表 or .META表）： Region 标识符 + Region服务器标识符。 -ROOT-表（根数据表）， 当.META表的条目非常多时， 也会被分裂成多个Rigion， 其映射表是根数据表-ROOT-表。 HBase 运行机制访问流程： 首先访问Zookeeper。 获取-ROOT-表的位置信息， 然后访问-ROOT-表， 获取.META表的信息， 接着访问.META表， 找到所需的Region具体位于哪个Region服务器， 最后找到该Region服务器读取数据。（客户端会缓存位置信息， 提高寻址效率） Zoopkeeper 中保存了-ROOT-表的地址和Master 的地址， 客户端可以通过访问ZoopKeeper 获得-ROOT-表的地址， 最后通过三级寻址来找到所需要的地址。 HBase自身不具备数据复制和维护数据副本的功能， 而HDFS可以为HBase提供这些支持。 Region 服务器的工作原理Region 服务器内部管理一系列的Region 对象和一个HLog 文件。 HLog 文件： 磁盘上面的记录文件， 它记录着所有的更新操作。 Region 对象： 由多个Store 组成， 每个Store 对应表中的一个列族的存储 Store： 包含一个MemStore 和若干个StoreFile， 其中， MemStore 是内存中的缓存， 保存最近更新的数据， StoreFile 是磁盘中的文件（B+树结构）， StoreFile 在底层的实现方式是HDFS 文件系统的HFile， 而HFile 的数据块通过采用压缩的方式存储， 压缩之后可以大大减少网络IO和磁盘IO。 用户读写数据的过程当用户写入数据时， 会被分配到相应的Region 服务器执行操作， 用户数据被写入MemStore 和HLog 中， 当操作写入Hlog 之后， commit()调用才会将其返回给客户端。 当用户读取数据时， Region 服务器首先会访问MemStore 缓存， 如果数据不在缓存中， 才会到磁盘上面的StoreFile 中去寻找。 缓存的刷新MemStore的缓存容量有限， 所有会周期性地将MemStore 的数据存入到磁盘的StoreFile 中， 同时在HLog中写入一个标记， 以表示缓存中的内容已经写入到磁盘中， 每次刷新操作都会在磁盘中生成一个新的StoreFile， 所有每个Store 都会含有多个StoreFile。 Region 每次启动都会去检查HLog， 以确保缓存中的数据已经写入到StoreFile 中， 若没有， 则先将更新写入MemStore， 再刷新缓存， 写入到StoreFile中， 最后删除旧的HLog。 StoreFile 的合并当StoreFile文化的数量达到一个阀值时， 会进行合并操作。 Store 的工作原理 HLog 的工作原理每个Region 服务器维护共同一个HLog, 当Region服务器出现故障时， Zoopkeeper 会同时Master， 首先处理故障服务器上遗留的HLog 文件， 根据Region对象拆分日志， 分配到各自对象的目录下， 然后再将失效的Region分配到可用的Region服务器中， 新的服务器会将分配到给自己的HLog 日志重新执行一边， 然后刷新缓存。","categories":[],"tags":[{"name":"Hadoop","slug":"Hadoop","permalink":"https://wt-git-repository.github.io/tags/Hadoop/"}]},{"title":"Hadoop学习笔记②","slug":"hadoop学习笔记②","date":"2019-06-25T03:17:14.000Z","updated":"2019-07-08T01:15:52.703Z","comments":true,"path":"2019/06/25/hadoop学习笔记②/","link":"","permalink":"https://wt-git-repository.github.io/2019/06/25/hadoop学习笔记②/","excerpt":"","text":"分布式文件系统HDFS计算机集群架构集群中的计算机结点存放在机架上， 每个机架可以存放8-64个结点， 同一个机架上的不同节点通过网络互联， 多个不同机架之间采用另一级网络或交换机互联。 分布式文件系统的结构分布式文件系统在物理结构上是由计算机集群中的多个节点构成的， 这些节点分为两类： 主节点或者是名称节点(NameNode)：负责文件和目录的创建、删除和重命名等，同时管理着数据节点和文件块的映射关系， 客户端只有访问名称结点才能请求文件块所在的位置，进而找到相应位置读取所需文件块。 从结点或者是数据结点(DataNode)：负责数据的存储和读取， 在存储时， 由名称结点分配存储位置， 然后由客户端把数据直接写入相应数据节点 在读取数据时， 客户端从名称节点获取数据节点和文件块的映射关系， 然后就可以到相应位置访问文件块。 数据节点也要根据名称节点的命令创建、删除数据块和冗余复制。 为了保证数据的完整性， 分布式文件系统通常采用多副本存储， 文件块会被复制为多个副本， 存储在不同的节点上， 而且存储同一个文件块的不同副本的各个节点会分布在不同机架上， 这样， 在单个节点出现故障时， 就可以快速调用副本重启单个节点上的计算过程， 而不用重启整个计算过程。 分布式文件系统是针对大规模数据存储而设计的（TB级别）， 规模过小会影响性能。 HDFS特性 兼容廉价硬件设备 流数据读写 大数据集 简单的文件模型 强大的跨平台特性 不适合低延迟数据访问， 主要面向大规模数据批量处理而设计的， 采用流式数据读取， 具有很高的吞吐率， 高延迟（对于低延时要求的应用程序， HBase是一个更好的选择） 无法高效存储大量小文件 不支持多用户写入以及任意修改文件 HDFS的 相关概念块在传统的文件系统中，为了提高磁盘的读写效率， 一般以数据块为单位， 而不是以字节为单位。 HDFS也采用了快的概念， 默认一个块大小是64MB， 在HDFS中的文件会被拆分成多个块， 每个块作为独立的单元进行存储。 HDFS在块的大小设计明显大于普通文件系统， 为的是最小化寻址开销（磁盘寻道开销和数据块定位开销） 通常MapReduce中的Map任务一次只处理一个块中中的数据 HDFS采用抽象块概念可以带来几个好处： 支持大规模文件存储： 一个大规模文件可以被拆分成若干个文件块， 不同的文件块被分发到不同的节点上， 因此一个文件的大小不会受到单个节点的存储容量的限制， 可以远大于任意节点的存储容量。 简化系统设计：方便计算一个节点可以存储多少个文件块，其次，方便元数据的管理，元数据不需要和文件夹一起存储，可以由其他系统负责管理元数据。 适合数据备份：每个文件块可以冗余存储到多个节点上，大大提高了系统的容错性和可用性。 名称节点和数据节点在名称节点（NameNode）中， 负责管理分布式文件系统的命名空间（Namespace）， 保存了两个核心的数据结构， 即FsImage和EditLog。 FsImage用于维护文件系统树以及文件树中所有的文件和文件夹的元数据 EditLog是操作日志文件，记录了所有针对文件的创建、删除、重命名等操作。 名称节点记录了每个文件各个块所在的数据节点的位置信息， 但是不会持久化保存这些数据， 而是在系统每次启动时， 扫描所有数据节点然后重构这些信息。 名称节点启动时会处于安全模式， 对外只提供读操作。 名称节点在启动时， 会将FsImage加载到内存中， 然后执行EditLog文件中的各项操作， 是的内存中的元数据保持最新， 然后创建一个新的FsImage和空的EditLog文件， 名称节点启动成功之后进入正常运行状态， HDFS中的更新操作都会写入EditLog中， 而不是直接写入FsImage中， 因为在分布式文件系统中， FsImage都十分庞大， 如果每次的更新都往FsImage里面添加， 会带来十分大的系统开销， 而Editlog十分小， 写入操作是十分高效的。 数据节点（DataNode）是分布式文件系统HDFS的工作节点， 负责数据的存储和读取， 会根据客户端或者名称节点的调度来进行数据的存储和检索， 并向名称节点定期发送自己所存储的块列表。 第二名称节点在名称节点运行期间， HDFS会不断发生更新操作， 会使EditLog文件逐渐变大， 当名称节点重启时， 需要逐条执行EditLog的记录， 这个过程就会变得十分缓慢。 为了解决这个问题， HDFS采用第二名称节点（Secondary NameNode）， 来完成合并EditLog与FsImage的合并操作， 减少EditLog的文件大小， 缩短名称节点重启时间 HDFS体系结构HDFS 采用主/从结构模型， 一个HDFS集群包括一个名称节点和若干个数据节点。 名称节点是中心服务器， 负责管理文件系统的命名空间以及客户端对文件的访问。 集群中的数据节点一般是一个节点运行一个数据节点进程， 负责处理文件系统客户端的读写请求， 在名称节点的统一调度之下进行数据块的创建、删除和复制等操作，每个数据节点的数据是保存在本地Linux文件系统中的， 每个数据节点会周期性地向名称节点发送“心跳”信息， 报告自己的状态， 对于没有按时发送心跳信息的数据结构会被标记为死机， 不会在给它分配任务。 用户在使用HDFS时， 仍然可以像普通文件系统那样， 使用文件名去存储和访问文件， 在系统内部， HDFS会将一个文件切分为若干个数据块， 这些数据块会被分布存储到若干个数据节点上。 访问流程：客户端访问文件， 将文件名发送给名称节点-&gt;名称节点根据文件名查找到对应的数据块-&gt;根据数据块信息找到数据节点的位置-&gt; 把数据节点的位置发送给客户端-&gt;客户端直接访问数据节点获取数据信息 HDFS命名空间管理HDFS通信协议RPC HDFS客户端Shell and Java API HDFS 的存储原理数据的冗余存储作为分布式文件系统， 为了保证系统的容错性和可用性， HDFS采用了多副本方式对数据进行冗余存储， 通过一个数据块的多个副本会被分布到不同的数据节点上。 好处： 加快数据传输速度： 当多个客户端需要同时访问同一个文件时， 可以让各个客户端分别从不同的数据块副本读取数据， 加快数据的传输速度 检查数据错误 保证数据的可靠性 数据的存取策略数据存放：HDFS采用机架为基础的数据存放策略， HDFS默认的冗余复制因子是3， 每一个文件块会被同时保存到3个地方， 其中， 有两份副本放在同一个机架上的不同机器上， 第三个副本放在不同机架的机器上。 数据读取 数据复制 数据错误与恢复名称节点出错 把名称节点上的元数据同步存储到其他文件系统 运行一个第二名称节点 数据节点出错 心跳检测 数据出错由于网络传输和磁盘错误等因素造成的数据错误。 采用md5和sha1对数据块进行校验。 HDFS数据读写过程（待写）","categories":[],"tags":[{"name":"Hadoop","slug":"Hadoop","permalink":"https://wt-git-repository.github.io/tags/Hadoop/"}]},{"title":"Hadoop学习笔记①","slug":"hadoop学习笔记①","date":"2019-06-25T01:57:47.000Z","updated":"2019-07-08T01:15:52.703Z","comments":true,"path":"2019/06/25/hadoop学习笔记①/","link":"","permalink":"https://wt-git-repository.github.io/2019/06/25/hadoop学习笔记①/","excerpt":"Hadoop 简介Hadoop 是一个开源的、可运行于大规模集群上的分布式计算平台， 实现了MapReduce计算模型和分布式文件系统HDFS等功能 Hadoop的核心是分布式文件系统HDFS和MapReduce， HDFS是针对谷歌GFS的开源实现， 是面向普通硬件环境的分布式文件系统， 具有支持大规模数据的分布式存储。 MapReduce允许用户在不了解分布式系统底层细节的情况下开发并行应用程序， 整合分布式文件系统上的数据， 保证分析和处理数据的高效性。","text":"Hadoop 简介Hadoop 是一个开源的、可运行于大规模集群上的分布式计算平台， 实现了MapReduce计算模型和分布式文件系统HDFS等功能 Hadoop的核心是分布式文件系统HDFS和MapReduce， HDFS是针对谷歌GFS的开源实现， 是面向普通硬件环境的分布式文件系统， 具有支持大规模数据的分布式存储。 MapReduce允许用户在不了解分布式系统底层细节的情况下开发并行应用程序， 整合分布式文件系统上的数据， 保证分析和处理数据的高效性。 Hadoop生态系统 HDFSHadoop分布式文件系统是Hadoop项目的两大核心之一， 具有处理超大数据、流式处理、可以运行在廉价商用服务其上等优点, HDFS在访问应用层程序时，具有很高的吞吐率， 因此对于超大数据集的应用程序而言，选择HDFS作为底层数据存储是较好的选择。 HBaseHBase是一个高可靠性、高性能、可伸缩、实时读写、分布式的列式数据库， 一般采用HDFS作为底层数据存储 HBase是针对Google BigTable的开源实现， 具有强大的非结构化数据存储能力 HBase具有良好的横向扩展能力 MapReduceMapReduce是一种编程模型， 用于大规模数据的并行运算， 它将复杂、运行于大规模集群上的并行计算过程高度抽象到了两个函数–Map和Reduce上 MapReduce的核心思想是分而治之， 它把输入的数据切分为若干个数据块， 分发给一个主节点管理下各个分结点来共同并行完成， 最后， 通过整合各个结点的中间结果得到最终结果。 HiveHive是基于Hadoop的一个数据存库工具， 可以用于对Hadoop文件中的数据集进行整理、特殊查询和分析存储， 提供了类似SQL语言的查询语言Hive QL， 可以通过Hive QL快速实现简单的MapReduce统计， Hive自身可以将Hive QL语句装换成MapReduce任务进行运行， 适合数据存库的统计分析。 PigPig是一种数据流语言和运行环境， 适合使用Hadoop和MapReduce平台来查询大型半结构化数据集 Mahout数据挖掘等智能应用相关 ZookeeperZookeeper是针对谷歌Chubby的一个开源实现，是高效可靠的协同工作系统， 提供分布式锁之类的基本服务， 用于构建分布式应用， 减轻分布式应用程序所承担的协调任务。 FlumeFlume是Cloudera提供的一个高可用、高可靠、分布式的海量日志采集、聚合和传输的系统。 Sqoop(SQL-to-Hadoop)主要用于Hadoop和关系数据库之间交换数据 Ambari一种基于Web的根据， 支持Hadoop集群的安装、部署、配置和管理。","categories":[],"tags":[{"name":"Hadoop","slug":"Hadoop","permalink":"https://wt-git-repository.github.io/tags/Hadoop/"}]},{"title":"hadoop伪分布式安装（配置文件相关）","slug":"hadoop伪分布式安装（配置文件相关）","date":"2019-06-20T07:06:09.000Z","updated":"2019-07-08T01:15:52.702Z","comments":true,"path":"2019/06/20/hadoop伪分布式安装（配置文件相关）/","link":"","permalink":"https://wt-git-repository.github.io/2019/06/20/hadoop伪分布式安装（配置文件相关）/","excerpt":"推荐使用docker去部署hadoop集群Github - Big Data Europe","text":"推荐使用docker去部署hadoop集群Github - Big Data Europe 手动安装 /etc/hadoop hadoop-env指定JDK 路径 1export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.201.b09-2.el7_6.x86_64 core-site.xml12345678910111213&lt;configuration&gt; &lt;!--hdfs主节点地址--&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://namenode:9000&lt;/value&gt; &lt;/property&gt; &lt;!--指定hadoop运行时产生文件的存储目录--&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;file:/root/hadoop/data/&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; hdfs-site.xml1234567&lt;configuration&gt; &lt;!--hdfs副本数--&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; mapred-site.xml1234567&lt;configuration&gt; &lt;!--指明mapreduce的资源调度程序--&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; yarn-site.xml12345678910111213141516&lt;configuration&gt;&lt;!-- Site specific YARN configuration properties --&gt;&lt;!--yarn主结点--&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;resourcemanager&lt;/value&gt; &lt;!--yarn主结点--&gt; &lt;/property&gt; &lt;!--指定map传递数据给reduce的机制--&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt;","categories":[],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"https://wt-git-repository.github.io/tags/hadoop/"}]},{"title":"hadoop对海量数据处理的解决思路","slug":"hadoop对海量数据处理的解决思路","date":"2019-06-20T03:39:06.000Z","updated":"2019-07-08T01:15:52.719Z","comments":true,"path":"2019/06/20/hadoop对海量数据处理的解决思路/","link":"","permalink":"https://wt-git-repository.github.io/2019/06/20/hadoop对海量数据处理的解决思路/","excerpt":"","text":"如何解决海量数据的存储问题 如何解决海量数据的计算MapReduce Map: 计算本地数据， 在各个结点下计算， 本地并发 Reduce: 全局处理， 可以分组处理， 对各个Map的中间结果进行处理","categories":[],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"https://wt-git-repository.github.io/tags/hadoop/"}]},{"title":"《浪潮之巅》读书笔记","slug":"《浪潮之巅》读书笔记","date":"2019-06-20T01:52:59.000Z","updated":"2019-07-08T01:15:52.725Z","comments":true,"path":"2019/06/20/《浪潮之巅》读书笔记/","link":"","permalink":"https://wt-git-repository.github.io/2019/06/20/《浪潮之巅》读书笔记/","excerpt":"","text":"近百年来，总有一些公司很幸运地、有意识或无意识地站在技术革命的浪尖之上， 一旦处于那个位置， 即使不做任何事情， 也可以随着波浪顺顺当当地先前漂泊个十年甚至更长的世纪。 在这十几年间， 它们代表着科技的浪潮， 直到下一波浪潮的来临。 AT&amp;T由电话之父压力上大·贝尔创立， 第一次实现了人类的远程实时的交互通信。 它创建的贝尔实验室， 走出了计算机的Unix系统和C语言等等 错过了2000年前后的网络革命和90年代中期延续至今的无线通信，这两个极佳的发展机遇， 并丢了性命 AT&amp;T后来被分成了三部分，从事电信业务的AT&amp;T、从事设备制造业务的朗讯和从事计算机业务的NCR。 朗讯后来为MCI和Sprint提供设备，曾一度股价暴涨， 但是如果需要保证股票的持续增长， 它的销售额和利润就必须不断超过华尔街的预期， 为了支撑这一个高股价， 朗讯走了一步败笔的险棋， 具体做法是， 有朗讯借钱给各个公司买朗讯的设备， 从而促进销售额的增长， 但是到了后来互联网泡沫破灭之后， 借钱买设备的公司统统倒闭了， 朗讯这笔钱一下子变成了收不回来的账了， 从此便不得不关闭贝尔实验室的几乎全部研究部门， 走向没落。 当一个公司没有人对它有控制时，它的长期发展就会出现问题， 在上个世纪九十年代， AT&amp;T已经不属于任何一个人，任何一个机构，没有人对它的发展着想， 而跟多的是， 从华尔街到它的高管和员工， 都希望从它身上快快地捞一笔。","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://wt-git-repository.github.io/tags/随笔/"}]},{"title":"Vue常用命令","slug":"Vue常用命令","date":"2019-06-19T07:59:57.000Z","updated":"2019-07-08T01:15:52.697Z","comments":true,"path":"2019/06/19/Vue常用命令/","link":"","permalink":"https://wt-git-repository.github.io/2019/06/19/Vue常用命令/","excerpt":"","text":"起步安装12345# 安装vuenpm install vue# 安装vue-clinpm install -g @vue/cli 项目创建123vue create my-project# ORvue ui 相关文档 Vue.js官方文档 Vue CLI官方文档","categories":[],"tags":[{"name":"Vue","slug":"Vue","permalink":"https://wt-git-repository.github.io/tags/Vue/"}]},{"title":"《JAVA并发编程的艺术》读书笔记⑥","slug":"《JAVA并发编程的艺术》读书笔记⑥","date":"2019-06-17T06:49:49.000Z","updated":"2019-07-08T01:15:52.724Z","comments":true,"path":"2019/06/17/《JAVA并发编程的艺术》读书笔记⑥/","link":"","permalink":"https://wt-git-repository.github.io/2019/06/17/《JAVA并发编程的艺术》读书笔记⑥/","excerpt":"Java并发编程基础线程优先级在Java线程中，通过一个整型成员变量priority来控制优先级， 优先级分为从1-10， 在线程构建的时候可以通过setPriority(int)方法来修改优先级， 默认优先级是5， 优先级高的线程分配时间片的数量要多余优先级低的线程。 针对阻塞频繁的线程需要设置较高的优先级。 偏重计算的线程设置较低的优先级。","text":"Java并发编程基础线程优先级在Java线程中，通过一个整型成员变量priority来控制优先级， 优先级分为从1-10， 在线程构建的时候可以通过setPriority(int)方法来修改优先级， 默认优先级是5， 优先级高的线程分配时间片的数量要多余优先级低的线程。 针对阻塞频繁的线程需要设置较高的优先级。 偏重计算的线程设置较低的优先级。 线程的状态 NEW： 初始状态， 线程被构建， 但是还没有调用start()方法 RUNNABLE： 运行状态， Java线程将操作系统中的就绪和运行两种状态笼统地称作“运行中” BLOCKED：阻塞状态，表示线程阻塞干锁 WAITING：等待状态， 表示线程进入等待状态，进入该状态的线程表示当前线程需要等待其他线程作出一些特定的动作 TIME_WAITING：超时等待状态， 它是可以在指定的时间自行返回 TERMINATED：终止状态，表示当前线程已经执行完毕 Daemon线程Daemon线程是一种支持型线程，因为它主要被用作程序中后台调度以及支持工作，当一个JAVA虚拟机中不存在非Daemon线程的时候，JAVA虚拟机将会退出。 可以使用Thread.setDaemon(true)来设置Daemon线程。 Deamon线程被用作支持性工作，但是在JAVA虚拟机退出时，Daemo线程中的finally块不一定会执行。 对象、监视器、同步队列和执行线程之间的关系 线程间的通信等待/通知机制 有一些细节上的东西需要注意一下： 使用wait、notify、notifyAll时需要对调用对象加锁。 调用wait方法后，线程状态由RUNNING变成WAITING，并将当前线程放置在对象的等待队列中。 notify和notifyAll调用后，等到线程依旧不会从wait返回，而是要等本线程释放锁之后，等待线程才有机会返回 notify是将等待队列中的一个等待线程从等待队列中移到同步队列中 notifyAll是将等待队列中所有的线程全部移到同步队列中，被移动的线程状态由WAITING变为BLOKCED 从wait方法返回后重新执行的前提是获得对象的锁 管道输入\\输出流管道输入输出流主要用于线程之间的数据传输，而传输的媒介是内存。 管道输入输出流主要包括：PipedOutputStream、PipedInputStream、PipedReader和PipedWriter，前两种面向字节，后两种面向字符。 123PipedWriter out = new PipedWriter();PipedReader in = new PipedReader();out.connect(in); 对于Piped类型的流，必须先要进行绑定（调用connect方法） Thread.join()的使用如果线程A执行了thread.join()语句， 意味着当前线程A等到thread线程终止之后才从thread.join()返回。 除此之外， 线程Thread还提供了join(long millis)和join(long millis, int nanos)两个具备超时特性的方法， 表示：如果线程thread在特定的超时时间里没有终止，那么将会从该超时方法中返回。 ThreadLocal的使用ThreadLocal是线程变量，是一个以ThreadLocal对象为键、任意对象为值的存储结构， 这个结构被附带在线程上，也就是说一个线程可以根据一个ThreadLocal对象查询到绑定到这个线程上的一个值。 可以通过set(T)方法来设置一个值，在当前线程下再过get()方法获取到原先设置的值。","categories":[],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://wt-git-repository.github.io/tags/JAVA/"}]},{"title":"《JAVA并发编程的艺术》读书笔记⑤","slug":"《JAVA并发编程的艺术》读书笔记⑤","date":"2019-06-17T01:20:09.000Z","updated":"2019-07-08T01:15:52.724Z","comments":true,"path":"2019/06/17/《JAVA并发编程的艺术》读书笔记⑤/","link":"","permalink":"https://wt-git-repository.github.io/2019/06/17/《JAVA并发编程的艺术》读书笔记⑤/","excerpt":"双重检查锁定引发的思考在学习双重版本版本的单例模式的时候， 我书写了如下代码 123456789101112131415161718public class Singleton &#123; private static Singleton uniqueInstance; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; //检查实例，如果不存在，就进入同步代码块 if (uniqueInstance == null) &#123; //只有第一次才彻底执行这里的代码 synchronized(Singleton.class) &#123; //进入同步代码块后，再检查一次，如果仍是null，才创建实例 if (uniqueInstance == null) &#123; uniqueInstance = new Singleton(); &#125; &#125; &#125; return uniqueInstance; &#125;&#125; 这段代码表面上很完美， 但是在高并发的环境下， 容易触发里面一个潜在的BUG， 问题的根源出自于uniqueInstance = new Singleton(); , 因为在线程读取到uniqueInstance不为null的时候， 该变量引用的对象有可能还没有完成初始化。","text":"双重检查锁定引发的思考在学习双重版本版本的单例模式的时候， 我书写了如下代码 123456789101112131415161718public class Singleton &#123; private static Singleton uniqueInstance; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; //检查实例，如果不存在，就进入同步代码块 if (uniqueInstance == null) &#123; //只有第一次才彻底执行这里的代码 synchronized(Singleton.class) &#123; //进入同步代码块后，再检查一次，如果仍是null，才创建实例 if (uniqueInstance == null) &#123; uniqueInstance = new Singleton(); &#125; &#125; &#125; return uniqueInstance; &#125;&#125; 这段代码表面上很完美， 但是在高并发的环境下， 容易触发里面一个潜在的BUG， 问题的根源出自于uniqueInstance = new Singleton(); , 因为在线程读取到uniqueInstance不为null的时候， 该变量引用的对象有可能还没有完成初始化。 将uniqueInstance = new Singleton()拆分为以下三行伪代码：123memory = allocate(); // 1:分配对象的内存空间ctorInstance(memory); // 2:初始化对象instance = memory; // 3：设置instance指向刚刚分配的内存空间 在Java语言规范中， 所有线程在执行Java程序是必须要遵守intra-thread semantics， 以保证重排序不会改变单线程内的程序执行结果， 重排序在没有改变单线程程序执行结果的前提下， 可以提高程序的执行性能。 单线程下： 多线程下触发Bug的原因（线程A执行到uniqueInstance = new Singleton()， 线程B执行到第一个if (uniqueInstance == null)）： 如果按上面的时序图执行， 线程B有可能会读取到还没有初始化成功的对象。 基于volatile的解决方案1234567891011121314151617181920public class Singleton &#123; //volatile保证，当uniqueInstance变量被初始化成Singleton实例时，多个线程可以正确处理uniqueInstance变量 private volatile static Singleton uniqueInstance; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; //检查实例，如果不存在，就进入同步代码块 if (uniqueInstance == null) &#123; //只有第一次才彻底执行这里的代码 synchronized(Singleton.class) &#123; //进入同步代码块后，再检查一次，如果仍是null，才创建实例 if (uniqueInstance == null) &#123; uniqueInstance = new Singleton(); &#125; &#125; &#125; return uniqueInstance; &#125;&#125; 当变量声明为volitle之后，创建该对象的中所触发的指令重排序， 将会在多线程环境中禁止。","categories":[],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://wt-git-repository.github.io/tags/JAVA/"}]},{"title":"乐融软件面经","slug":"乐融软件面经","date":"2019-06-14T15:18:56.000Z","updated":"2019-07-08T01:15:52.727Z","comments":true,"path":"2019/06/14/乐融软件面经/","link":"","permalink":"https://wt-git-repository.github.io/2019/06/14/乐融软件面经/","excerpt":"","text":"部分面经（笔试与面试） &amp; 与 &amp;&amp; 的区别 对称算法与非对称算法有哪些， 两种算法的区别是什么 TCP三次握手四次挥手 JVM堆内存和栈内存（注意Spring的创建， 引用的传递） GC 单例模式 二分查找 递归算法 I/O流 MySQL的ACID 死锁， 如何避免 Spring 事务 微服务 SSL的算法 Http与Https的区别 项目经历 获奖经历 面试流程笔试-&gt;根据笔试的情况，让你讲解几道题（我被抽到的是：加密算法， JVM， 单例模式， &amp;与递归算法）-&gt;根据你简历上的内容提问-&gt;根据他手上的题纲去提问-&gt;聊个人情况、期盼薪资等等","categories":[],"tags":[{"name":"面经","slug":"面经","permalink":"https://wt-git-repository.github.io/tags/面经/"}]},{"title":"如何成长为一名合格的架构师","slug":"如何成长为一名合格的架构师","date":"2019-06-13T01:49:07.000Z","updated":"2019-07-08T01:15:52.731Z","comments":true,"path":"2019/06/13/如何成长为一名合格的架构师/","link":"","permalink":"https://wt-git-repository.github.io/2019/06/13/如何成长为一名合格的架构师/","excerpt":"今日， 在Google检索高性能、高可用以及高并发相关的书籍的时候， 无意中在知乎中看到了一场讨论， 从前辈们的分享中， 我猛然发现， 这么久以来， 我把大部分时间都花在了研究各种成熟的架构上面， 而忽略了底层的技术， 如数据结构、计算机网络、数据库存储原理等等， 殊不知， 一名合格的架构师永远都不是以你会用多少多少框架为衡量标准的， 相反， 要想成为一名合格的架构师， 数据结构，操作系统，网络原理，数据库原理等这些都是决定着我以后的高度和深度的， 虽然， 道路走的有点偏， 起码我还是能把握的正确的方向的， 因为为了相关的面试， 我也一直在对这些基础知识进行一个系统的学习， 而知道今天， 我才猛然发现这些基础知识的重要性， 还是十分庆幸自己及早看到了知乎的这一场讨论， 感恩！","text":"今日， 在Google检索高性能、高可用以及高并发相关的书籍的时候， 无意中在知乎中看到了一场讨论， 从前辈们的分享中， 我猛然发现， 这么久以来， 我把大部分时间都花在了研究各种成熟的架构上面， 而忽略了底层的技术， 如数据结构、计算机网络、数据库存储原理等等， 殊不知， 一名合格的架构师永远都不是以你会用多少多少框架为衡量标准的， 相反， 要想成为一名合格的架构师， 数据结构，操作系统，网络原理，数据库原理等这些都是决定着我以后的高度和深度的， 虽然， 道路走的有点偏， 起码我还是能把握的正确的方向的， 因为为了相关的面试， 我也一直在对这些基础知识进行一个系统的学习， 而知道今天， 我才猛然发现这些基础知识的重要性， 还是十分庆幸自己及早看到了知乎的这一场讨论， 感恩！ 原文： 作者：匿名用户链接：https://www.zhihu.com/question/22988790/answer/23290615来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 1.你在未来很长一段时间内还不会碰到除你问的分布式以外的问题，我所说的问题是，无论那个项目，未来很长一段时间都不会让你来负责架构，保证高并发高可用高扩展高性能。为什么呢？你经验还远远不够，这里的任何一个词都是需要你投入巨大的精力和时间来研究和实验，并且还需要提供跟你项目匹配的测试环境，来测试你的方案是否能达到高性能高并发等等。总结就是两点，先不说架构，你需要有机会参与到这种项目中来并学习，你需要有能测试你的技术方案的环境。放眼望去，光满足第一点你都要等待机会的来临。否则，你的预期都是水中月境中花。2.你所说的这些东西没有办法直接从任何书本上获得行之有效的方案，如有有，恐怕阿里百度这种企业会多如牛毛，遍地开花。有方案保密是一回事，公开了你看不懂驾驭不了那是另外一回事。3.如果没有机会怎么办呢？可能需要把这些看起来无比牛逼高端的字眼从你脑子里踢出来。好好的学习计算机体系的课程。数据结构，操作系统，网络原理，数据库原理等。以后能站多高取决于对这些东西的掌握程度。不搞学院派，我说的掌握不是大学里形式化的考试。这好懂，这叫广积粮4.在3进行的过程中，动手，找准技术方向。看原理，教程，写demo做测试，一步步来，这步是你迈向开发必经之路，理论转向实践，而且即使参加工作之后，这项活动还会不断进行。高筑墙不多说。5有机会接触到有一定规模的项目了，这个时候可以把你提的高端字眼考虑进来了。尝试学习思考和改进现有方案。相信到这一步已经走向正轨，不会再问这种让人摸不到头脑的问题了。而且也知道怎么学习。 你的问题是很多新手都会碰到的困惑，急功近利的表现。题主题的问题，不知道有多少人工作数年后都不会去考虑，要么项目规模不够，要么无测试环境，要么自己积粮不够无力解决。 以上，水文，看看即可，也期待知友能给出一步能至千里的方案，让我也学习学习 如果题主实在对这些技术感到困惑的话，我推荐你看一本书《淘宝技术这十年》，讲淘宝的技术演变。即使淘宝如此庞大的系统，都是实际生产环境下的问题倒逼各种牛逼方案的诞生。 空看空说无用。 github，stackoverflow，你值得拥有 附上链接：构建分布式、高并发、高性能、高可用、大规模并发、高可扩展性、高可维护性Java应用系统,书籍推荐或经验之谈?","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://wt-git-repository.github.io/tags/随笔/"}]},{"title":"Spring相关知识","slug":"Spring相关知识","date":"2019-06-12T08:26:14.000Z","updated":"2019-07-08T01:15:52.695Z","comments":true,"path":"2019/06/12/Spring相关知识/","link":"","permalink":"https://wt-git-repository.github.io/2019/06/12/Spring相关知识/","excerpt":"Spring 模块（4.x）最新的5.x版本中Web模块的Portlet已经废弃， 同时增加了异步响应式处理的WebFlux组件。 Spring Core： 基础模块， Spring其它的功能都依赖于这个类库， 主要提供IOC依赖注入功能 Spring Aspects： 该模块与AspectJ的集成提供支持 Spring AOP： 提供了面向切面的编程实现 Spring JDBC： JAVA数据库连接 Spring JMS： JAVA消息服务 Spring ORM： 用于支持Hibernate等ORM工具 Spring Web：为了创建Web应用程序提供支持 Spring Test：提供了对Junit和TestNG测试支持","text":"Spring 模块（4.x）最新的5.x版本中Web模块的Portlet已经废弃， 同时增加了异步响应式处理的WebFlux组件。 Spring Core： 基础模块， Spring其它的功能都依赖于这个类库， 主要提供IOC依赖注入功能 Spring Aspects： 该模块与AspectJ的集成提供支持 Spring AOP： 提供了面向切面的编程实现 Spring JDBC： JAVA数据库连接 Spring JMS： JAVA消息服务 Spring ORM： 用于支持Hibernate等ORM工具 Spring Web：为了创建Web应用程序提供支持 Spring Test：提供了对Junit和TestNG测试支持 Spring IoC（工厂模式）IoC 是一种设计思想， 将原本在程序中手动创建对象的控制权， 交由Spring框架来管理。 IoC容器是Spring用来实现IoC的载体， IoC容器实际上就是个Map(K, V)， 存放各种对象。 IoC容器就像是一个工厂一样，当我们需要创建一个对象的时候， 只需要配置好配置文件或注解即可， 完全不用考虑对象是怎么被创建出来的。 为了更好地去了解IoC， 此处我需要补充几个知识点 依赖倒置原则： 把原本的高层建筑依赖底层建筑倒置过来， 变成底层建筑依赖高层建筑， 高层建筑需要什么， 底层建筑便去实现这样的需求， 高层并不需要管底层是怎么实现的， 这样就不会出现牵一发而动全身的情况。 DI(Dependecy Inject,依赖注入)是实现控制反转的一种设计模式，依赖注入就是将实例变量传入到一个对象中去 控制反转就是依赖倒置原则的一种代码设计思路， 具体方法是依赖注入。 Spring IoC有什么好处 AOPAOP（面向切面编程）能够将那些与业务代码无关， 却为业务模块所共同调用的逻辑或责任（如事务处理、日志处理、权限控制等）封装起来， 以便于减少系统的重复代码， 降低模块间的耦合度， 并有利于未来的可拓展性和可维护性。 Spring AOP基于动态代理， 如果要代理的对象， 实现了某个接口， 那么Spring AOP就会使用JDK Proxy， 去创建代理对象， 没有接口的话，就无法使用JDK Proxy去代理， 此时便要使用Cglib Spring AOP 与 AspectJ AOP前者集成了后者， 前者比后者简单， 后者比前者强大 Spring AOP是运行时增强， AspectJ AOP是编译时增强 Spring 中的事务管理 编程式事务：在代码中硬编码（不推荐使用） 声明式事务：在配置文件中配置（推荐使用） 声明式事务又分为两种 基于XML的声明式事务 基于注解的声明式事务 Spring 事务中的隔离级别 TransactionDefinition.ISOLATION_DEFAULT: 使用后端数据库默认的隔离级别，Mysql 默认采用的 REPEATABLE_READ隔离级别 Oracle 默认采用的 READ_COMMITTED隔离级别. TransactionDefinition.ISOLATION_READ_UNCOMMITTED: 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读 TransactionDefinition.ISOLATION_READ_COMMITTED: 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生 TransactionDefinition.ISOLATION_REPEATABLE_READ: 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。 TransactionDefinition.ISOLATION_SERIALIZABLE: 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。但是这将严重影响程序的性能。通常情况下也不会用到该级别。 Spring 设计模式 工厂设计模式 : Spring使用工厂模式通过 BeanFactory、ApplicationContext 创建 bean 对象。 代理设计模式 : Spring AOP 功能的实现。 单例设计模式 : Spring 中的 Bean 默认都是单例的。 模板方法模式 : Spring 中 jdbcTemplate、hibernateTemplate 等以 Template 结尾的对数据库操作的类，它们就使用到了模板模式。 包装器设计模式 : 我们的项目需要连接多个数据库，而且不同的客户在每次访问中根据需要会去访问不同的数据库。这种模式让我们可以根据客户的需求能够动态切换不同的数据源。 观察者模式: Spring 事件驱动模型就是观察者模式很经典的一个应用。 适配器模式 :Spring AOP 的增强或通知(Advice)使用到了适配器模式、spring MVC 中也是用到了适配器模式适配Controller。 面试官:“谈谈Spring中都用到了那些设计模式?”。 参考JavaGuide","categories":[],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://wt-git-repository.github.io/tags/Spring/"}]},{"title":"设计模式之建造者模式","slug":"设计模式之建造者模式","date":"2019-06-12T07:46:35.000Z","updated":"2019-07-08T01:15:52.736Z","comments":true,"path":"2019/06/12/设计模式之建造者模式/","link":"","permalink":"https://wt-git-repository.github.io/2019/06/12/设计模式之建造者模式/","excerpt":"","text":"待办参考深入理解建造者模式 ——组装复杂的实例图说设计模式","categories":[],"tags":[{"name":"设计模式， JAVA","slug":"设计模式，-JAVA","permalink":"https://wt-git-repository.github.io/tags/设计模式，-JAVA/"}]},{"title":"Java基础知识","slug":"Java基础知识","date":"2019-06-12T01:01:34.000Z","updated":"2019-07-08T01:15:52.669Z","comments":true,"path":"2019/06/12/Java基础知识/","link":"","permalink":"https://wt-git-repository.github.io/2019/06/12/Java基础知识/","excerpt":"","text":"牛客网上，错题相关的知识点 子类A继承父类B， A a = new A()， 问代码块的执行顺序 父类B静态代码块 -&gt; 子类A的静态代码块 -&gt; 父类B非静态代码块 -&gt; 父类B的构造函数 -&gt; 子类A非静态代码块 -&gt; 子类A的构造函数 “&gt;&gt;&gt;”表示无符号右移， 高位用0填充， 如 1&gt;&gt;&gt;2 为0 sleep是线程类（Thread）的方法， wait是Object的方法， 前者不释放对象锁， 后者释放对象锁。 Float f = 0.1f, (后面必须要加f, 负责会被识别成double) 接口中的方法默认是public abstract的，且实现接口的类中对应的方法的可见性不能小于接口方法的可见性 接口中的变量默认是public static final 接口中不能定义私有方法 重载是在同一个类中，有多个方法名相同，参数列表不同， 与方法的返回值无关， 与权限修饰符无关。 Java程序的种类有：内嵌于Web文件夹中，由浏览器来观看的_Applet、可独立运行的Application和服务器端的servlets.","categories":[],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://wt-git-repository.github.io/tags/JAVA/"}]},{"title":"设计模式之工厂模式","slug":"设计模式之工厂模式","date":"2019-06-11T13:13:55.000Z","updated":"2019-07-08T01:15:52.735Z","comments":true,"path":"2019/06/11/设计模式之工厂模式/","link":"","permalink":"https://wt-git-repository.github.io/2019/06/11/设计模式之工厂模式/","excerpt":"工厂模式介绍定义在基类中定义创建对象的一个接口，让子类决定实例化哪个类。工厂方法让一个类的实例化延迟到子类中进行。 工厂模式的分类 简单工厂， 又称为静态工厂方法模式 工厂方法， 又称为多态性工厂模式 抽象工厂， 又称为工具箱模式","text":"工厂模式介绍定义在基类中定义创建对象的一个接口，让子类决定实例化哪个类。工厂方法让一个类的实例化延迟到子类中进行。 工厂模式的分类 简单工厂， 又称为静态工厂方法模式 工厂方法， 又称为多态性工厂模式 抽象工厂， 又称为工具箱模式 使用工厂模式的好处 解耦：把对象的创建和使用的过程分开 降低代码重复：如果创建某个对象的过程十分复杂，需要一定的代码量，如果很多地方都要用到，那么就会有很多重复的代码。 降低维护成本：由于创建过程都有工厂统一管理，所以发生业务逻辑变化，不需要找到所以创建对象的方法逐个去修正，只需要在工厂里修改即可，降低维护成本。 简单工厂（此处使用反射机制实现）适用场景 需要创建的对象较少 客户端不关心对象的创建过程 简单工厂模式角色分配 抽象产品角色：简单工厂模式所创建的所有对象的父类，它负责描述所有公共接口 123public interface Animal &#123; void sing();&#125; 具体产品角色：简单工厂模式的创建目标 12345678910111213public class Dog implements Animal &#123; @Override public void sing() &#123; System.out.println(\"Wang Wang ~~\"); &#125;&#125;public class Cat implements Animal &#123; @Override public void sing() &#123; System.out.println(\"Miao miao ~~\"); &#125;&#125; 抽象产品角色：简单工厂模式的核心，它负责实现创建所有实例的内部逻辑。 12345678910111213public class AnimalFactory &#123; public static Object getClass(Class&lt;? extends Animal&gt; clazz) &#123; Object obj = null; try &#123; obj = Class.forName(clazz.getName()).newInstance(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return obj; &#125;&#125; 工厂方法模式（使用最多）工厂方法是简单工厂的进一步深化，在工厂方法模式中， 我们不再提供一个统一的工厂类来创建所有的对象， 而是针对不同的对象去提供不同的工厂， 也就是说 每个对象都有一个与之对应的工厂 工厂方法模式的角色分配 抽象产品角色： 工厂方法模式锁创建的对象的父类 123public interface Animal &#123; void sing();&#125; 具体产品角色：这个角色实现了抽象产品角色所定义的接口 12345678910111213public class Dog implements Animal &#123; @Override public void sing() &#123; System.out.println(\"Wang Wang ~~\"); &#125;&#125;public class Cat implements Animal &#123; @Override public void sing() &#123; System.out.println(\"Miao miao ~~\"); &#125;&#125; 抽象工厂角色：工厂方法模式的核心， 是所有工程类的接口类 123public interface Factory &#123; Animal getAnimal();&#125; 具体工厂角色：实现抽象工厂接口的具体工厂类 123456public class DogFactory implements Factory &#123; @Override public Animal getAnimal() &#123; return new Dog(); &#125;&#125; 抽象工厂抽象工厂是生产出一套产品的（至少两个），这些产品是相互有关系或者有关联的， 而工厂方法是生产单一产品的工厂。 参考深入理解工厂模式——由对象工厂生成对象","categories":[],"tags":[{"name":"设计模式， JAVA","slug":"设计模式，-JAVA","permalink":"https://wt-git-repository.github.io/tags/设计模式，-JAVA/"}]},{"title":"设计模式之单例模式","slug":"设计模式之单例模式","date":"2019-06-11T12:45:49.000Z","updated":"2019-07-08T01:15:52.734Z","comments":true,"path":"2019/06/11/设计模式之单例模式/","link":"","permalink":"https://wt-git-repository.github.io/2019/06/11/设计模式之单例模式/","excerpt":"单例模式定义保证一个类只有一个实例， 并且提供一个访问它的全局访问点。 好处 对于频繁使用而且不需要记录某些状态的对象，可以省略创建对象所花费的时间，这对于这些重量级对象而言，这是非常客观的一笔系统开销。 由于new的次数减少，因为对系统内存的使用频率也会降低，这将减轻GC压力，缩短GC的停顿时间。 为什么不设置为静态变量因为我们要保证资源的可用性，静态变量在程序加载了类的字节码之后，不需要创建任何实例对象就会被分配相应的空间，静态变量就可以被使用了。 如果对象一直没有被使用，这么对资源也会是一种消耗，此时我们就需要在使用时才创建对象，避免不必要的资源浪费。","text":"单例模式定义保证一个类只有一个实例， 并且提供一个访问它的全局访问点。 好处 对于频繁使用而且不需要记录某些状态的对象，可以省略创建对象所花费的时间，这对于这些重量级对象而言，这是非常客观的一笔系统开销。 由于new的次数减少，因为对系统内存的使用频率也会降低，这将减轻GC压力，缩短GC的停顿时间。 为什么不设置为静态变量因为我们要保证资源的可用性，静态变量在程序加载了类的字节码之后，不需要创建任何实例对象就会被分配相应的空间，静态变量就可以被使用了。 如果对象一直没有被使用，这么对资源也会是一种消耗，此时我们就需要在使用时才创建对象，避免不必要的资源浪费。 单例模式的实现两种构建方式： 饿汉模式：指全局的单例实例在类装载时构建。 懒汉模式：指全局的单例实例在第一次被使用时构建。 共同点： 统一的private级别的构造函数 instance 成员变量和 uniqueInstance 方法必须是 static 的 饿汉模式（线程安全）12345678910public class Singleton &#123; //在静态初始化器中创建单例实例，这段代码保证了线程安全 //volatile保证，当uniqueInstance变量被初始化成Singleton实例时，多个线程可以正确处理uniqueInstance变量 private volatile static Singleton uniqueInstance = new Singleton(); //Singleton类只有一个构造方法并且是被private修饰的，所以用户无法通过new方法创建该对象实例 private Singleton()&#123;&#125; public static Singleton getInstance()&#123; return uniqueInstance; &#125;&#125; 懒汉模式（双重检查加锁版本）1234567891011121314151617181920public class Singleton &#123; //volatile保证，当uniqueInstance变量被初始化成Singleton实例时，多个线程可以正确处理uniqueInstance变量 private volatile static Singleton uniqueInstance; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; //检查实例，如果不存在，就进入同步代码块 if (uniqueInstance == null) &#123; //只有第一次才彻底执行这里的代码 synchronized(Singleton.class) &#123; //进入同步代码块后，再检查一次，如果仍是null，才创建实例 if (uniqueInstance == null) &#123; uniqueInstance = new Singleton(); &#125; &#125; &#125; return uniqueInstance; &#125;&#125; 参考深入理解单例模式——只有一个实例","categories":[],"tags":[{"name":"设计模式， JAVA","slug":"设计模式，-JAVA","permalink":"https://wt-git-repository.github.io/tags/设计模式，-JAVA/"}]},{"title":"centos7常用命令(IP与防火墙相关)","slug":"Linux常用命令","date":"2019-06-11T01:35:49.000Z","updated":"2019-07-08T01:15:52.682Z","comments":true,"path":"2019/06/11/Linux常用命令/","link":"","permalink":"https://wt-git-repository.github.io/2019/06/11/Linux常用命令/","excerpt":"查看自己所在的公网ip1curl members.3322.org/dyndns/getip 查看端口是否开放1telnet ip port","text":"查看自己所在的公网ip1curl members.3322.org/dyndns/getip 查看端口是否开放1telnet ip port 开放端口1234567891011121314151617181920- 查看已打开的端口 # netstat -anp- 查看想开的端口是否已开 # firewall-cmd --query-port=666/tcp 若此提示 FirewallD is not running 表示为不可知的防火墙 需要查看状态并开启防火墙- 查看防火墙状态 # systemctl status firewalldrunning 状态即防火墙已经开启dead 状态即防火墙未开启- 开启防火墙，# systemctl start firewalld 没有任何提示即开启成功- 开启防火墙 # service firewalld start 关闭防火墙 # systemctl stop firewalld centos7.3 上述方式可能无法开启，可以先#systemctl unmask firewalld.service 然后 # systemctl start firewalld.service- 查看想开的端口是否已开 # firewall-cmd --query-port=666/tcp 提示no表示未开- 开永久端口号 firewall-cmd --add-port=666/tcp --permanent 提示 success 表示成功- 重新载入配置 # firewall-cmd --reload 比如添加规则之后，需要执行此命令- 再次查看想开的端口是否已开 # firewall-cmd --query-port=666/tcp 提示yes表示成功- 若移除端口 # firewall-cmd --permanent --remove-port=666/tcp- 修改iptables 有些版本需要安装iptables-services # yum install iptables-services 然后修改进目录 /etc/sysconfig/iptables 修改内容 docker与centos7(firewall)123firewall-cmd --permanent --zone=trusted --change-interface=docker0 --permanentfirewall-cmd --reloadsystemctl restart docker 参考Centos7 使用firewalld代替了原来的iptables","categories":[],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://wt-git-repository.github.io/tags/操作系统/"}]},{"title":"软件工程管理","slug":"软件工程管理","date":"2019-06-10T08:14:53.000Z","updated":"2019-07-08T01:15:52.737Z","comments":true,"path":"2019/06/10/软件工程管理/","link":"","permalink":"https://wt-git-repository.github.io/2019/06/10/软件工程管理/","excerpt":"软件工程规范软件过程的分类 软件主要过程： 软件获取、供应、开发运行和维护的过程。 软件支持过程： 对软件的主要过程提供支持的过程。 软件组织过程：对软件主要过程和支持过程过程的提供组织保证的过程。 软件过程的组成管理工程、工程过程和支持过程。","text":"软件工程规范软件过程的分类 软件主要过程： 软件获取、供应、开发运行和维护的过程。 软件支持过程： 对软件的主要过程提供支持的过程。 软件组织过程：对软件主要过程和支持过程过程的提供组织保证的过程。 软件过程的组成管理工程、工程过程和支持过程。 过程规范过程规范指的是对输入、输出和活动所构成的过程进行明文规定或约定俗成的标准。 作用： 帮助团队实现共同的目标， 一个规范的软件过程必将能带来稳定、高水平的过程质量， 过程规范使软件组织的生产效率更高。 软件过程规范软件过程规范是软件开发组织行动的准则与指南， 可以依据上垒各类过程的特点而建立相应的规范。 软件过程规范的建立 软件能力成熟度模型（CMM/CMMI） 个体软件过程（PSP） 团体软件过程（TSP） IBM-Raional 统一过程（RUP） 极限编程 （eXtreme Programming，XP） 微软软件框架（MSF） 软件生命周期的过程需求 软件工程过程 软件支持过程 软件管理过程 软件组织过程 软件客户-供应商的过程 软件过程模型 瀑布模型 螺旋模型 增量模型 软件过程成熟度CMMCMM是软件过程能力成熟度模型， 描述一条从无序混乱到成熟有纪律的过程的改进途径， 描绘出软件组织如何增加对软件开发和维护的过程控制等方面的指导。 CMMICMMI是能力成熟度模型集成， 前身是CMM CMM/CMMI五个等级 初始级: 具有明显不成熟过程的特点 可重复级： 建立了管理软件项目的方针和实施这些方针的规程， 使软件项目的有效管理制度化 已定义级：包含一组协调的、集成的、适度定义的软件工程过程和管理过程，具有良好的文档化、标准化，使软件过程具有可视性、一致性、稳定性和可重复性，软件过程被集成为一个有机的整体 定量管理级： 在上述已定义级的基础上，可以建立有关软件过程和产品质量的、一致的度量体系，采集详细的数据进行分析，从而对软件产品和过程进行有效的定量控制和管理。 优化级： 断改善组织的软件过程能力和项目的过程性能，利用来自过程和来自新思想、新技术的先导性试验的定量反馈信息，使持续过程改进成为可能。为了预防缺陷出现，组织有办法识别出弱点并预先针对性地加强过程 CMMI过程域 工程管理 支持管理 项目管理 过程管理 PSP/TSP和CMM组成的软件过程框架软件过程的组织管理组织过程定义-过程裁剪 剪裁指南和准则的主要作用： 选择一个适合项目的生命周期模型。 剪裁和细化组织标准软件过程和所选择的软件生命周期，使之适合项目的具体特征。 组织过程焦点-执行约定 组织应该遵循一个文档化的关于协调软件流程的指定和改进活动的组织方针 高级管理人员发起对软件过程制定和改进的组织活动 高级管理人员进度软件过程的指定和改进的组织活动 组织过程焦点-执行能力 建立一个负责整个组织的软件过程活动的工作组 为软件过程活动提供足够的资源和资金 组织软件过程活动的组员进行培训 软件过程组和其它工程组的组员接受软件过程活动的相关培训 组织过程焦点-执行活动 定期评估软件过程并根据评估结果制订相应的更改计划 组织制定和维护有关软件过程和改进活动的计划 协调组织的标准软件过程和项目自定义的软件过程的制定和改进工作 协调组织的软件过程数据库的使用 新过程、新方法、新工具的评价、监控和推广 对有关组织和项目的软件过程培训进行统一管理 及时将有关软件过程制定和改进的活动通知与实施软件过程相关的组和人员 组织过程焦点-评估 度量和分析 实施验证 PSP过程框架和成熟度模型 PSP过程框架：PSP过程由一系列方法、表格、脚本等组成，用以指导软件开发人员计划、度量和管理他们的工作。 PSP成熟度模型：PSP是一个具有4个等级的成熟度框架， 其中四个等级分别为个体度量过程、个体计划过程、个体质量管理过程和个体循环过程。 TSP软件需求管理业务需求、用户需求、功能需求 需求开发需求开发的目的是通过调查与分析，获取用户需求并定义产品需求。 需求获取概述需求回去是通过各种途径获取用户的需求信息 需求获取的方法 需求研讨会 头脑风暴 用例模型 访谈 角色扮演 原型法 需求跟踪 需求的标识 需求的属性 需求的状态： 已建议、已批准、已实现和已删除 正向跟踪：以用户需求为切入点，检查《用户需求说明书》或《需求规格说明书》中的每个需求是否都能在后继工作产品中找到对应点。 逆向跟踪：检查设计文档、代码、测试用例等工作产品是否都能在《需求规格说明书》中找到出处。 正向跟踪和逆向跟踪合称为“双向跟踪”。 需求变更软件过程的技术管理技术路线 软件项目过程的技术解决流程 技术解决计划的建立和实施 开发设计 编程和单元测试 验证、确认与测试 软件过程的项目管理PMI项目管理知识域 整合管理 范围管理 时间管理 成本管理 质量管理 人力资源管理 沟通管理 风险管理 采购管理 干系人管理 PMI将47个管理过程归纳为5大类 启动过程组：获得授权，定义一个新项目或现有项目的一个新阶段，正式开始该项目或阶段的一组过程。 规划过程组：明确项目范围，优化目标，为实现目标而制定行动方案的一组过程。 执行过程组：完成项目管理计划中确定的工作以实现项目目标的一组过程。 监控过程组：跟踪、审查和调整项目进展与绩效，识别必要的计划变更并启动相应变更的一组过程。 收尾过程组：为完结所有过程组的所有活动以正式结束项目或阶段而实施的一组过程。 估算活动持续时间的方法三点估算 最乐观时间（tO）。基于活动的最好情况，所估算的活动持续时间 最悲观时间（tP）。基于活动的最差情况，所估算的活动持续时间 最可能时间（tM）。基于最可能获得的资源、最可能取得的资源生产率、对资源可用时间的现实预计、资源对其他参与者的可能依赖及可能发生的各种干扰等，所估算的活动持续时间。 基于持续时间在三种估算值区间内的假定分布情况（β分布），使用公式来计算期望持续时间tE tE = (t0 + 4 * tM + tP) / 6 正态曲线下，横轴区间（μ-σ,μ+σ）内的面积为68.268949%。P{|X-μ|&lt;σ}=2Φ（1）-1=0.6826 横轴区间（μ-1.96σ,μ+1.96σ）内的面积为95.449974%。P{|X-μ|&lt;2σ}=2Φ（2）-1=0.9544 横轴区间（μ-2.58σ,μ+2.58σ）内的面积为99.730020%。P{|X-μ|&lt;3σ}=2Φ（3）-1=0.9974 其余公式 PV[Planned Value]计划值：应该完成多少工作？[96版的BCWS] EV[Earned Value]挣值：完成了多少预算工作？[96版的BCWP] AC[Actual Cost]实际成本：完成工作的实际成本是多少？[96版的ACWP] BAC[Budget cost at completion]完工预算：全部工作的预算是多少？不改变成本基准，BAC就不会发生变化 EAC[Estimate at completion]完成预估：全部工作的成本是多少？是根据项目的绩效和风险量化对项目最可能的总成本所做的一种预测。 ETC完工尚需估算：剩余工作在当前的估算是多少？ CPI成本绩效指数：CPI=EV/AC CPI&gt;1代表工作价值高，好 SPI进度绩效指数：SPI=EV/PV SPI&gt;1代表实际进度快，好 PC任务完成指数：PC=EV/BA CV成本差异：CV=EV-AC CV&gt;0代表成本节约，好 成本差异比例%=CV/EV=(EV-AC)/EV=1-1/CPI SV进度差异：SV=EV-PV SV&gt;0代表进度提前，好 成本差异比例%=SV/PV=(EV-PV)/PV=SPI-1 EAC=BAC+AC-EV=BAC-CV EAC=BAC/CPI EAC=ETC+AC","categories":[],"tags":[{"name":"软件过程管理","slug":"软件过程管理","permalink":"https://wt-git-repository.github.io/tags/软件过程管理/"}]},{"title":"操作系统之进程与线程","slug":"操作系统之进程与线程","date":"2019-06-10T06:09:11.000Z","updated":"2019-07-08T01:15:52.732Z","comments":true,"path":"2019/06/10/操作系统之进程与线程/","link":"","permalink":"https://wt-git-repository.github.io/2019/06/10/操作系统之进程与线程/","excerpt":"进程与线程进程进程是资源分配的基本单位. 进程控制块PCB: 描述了进程的基本信息和运行状态, 所谓的创建进程和撤销进程都是指对PCB的操作 线程线程是独立调度的基本单位. 一个进程中可以有多个线程, 它们共享进程资源.","text":"进程与线程进程进程是资源分配的基本单位. 进程控制块PCB: 描述了进程的基本信息和运行状态, 所谓的创建进程和撤销进程都是指对PCB的操作 线程线程是独立调度的基本单位. 一个进程中可以有多个线程, 它们共享进程资源. 线程与进程的区别 一个进程至少有一个线程 在同一个进程中,线程的切换不会引起进程的切换,从一个进程中的线程切换到另一个进程中的线程,会引起进程切换. 创建和销毁进程的开销远大于创建或销毁线程时的开销. 线程间的通信可以通过直接读写统一进程中的数据进行通信, 但是进程间的通信需要借助IPC. 进程状态的转换 就绪 运行 阻塞 进程调度算法批处理系统批处理系统没有太多的用户操作, 在该系统中, 调度算法的目标是保证吞吐量和周转时间. 先来先服务(FCFS) 短作业优先(SJF) 最短剩余时间优先(SRTN) 交互式系统交互式系统有大量的用户交互操作, 在该系统中调度算法的目的是快速地响应 时间片轮转 优先级调度 多级反馈队列 实时系统实时系统要求一个请求在一个确定的时间内得到响应 硬实时: 满足绝对的截止时间 软实时: 可以容忍一定的超时 进程同步临界区对临界资源访问的那段代码成为临界区 同步和互斥 同步: 多个进程按照一定的顺序执行 互斥: 多个进程在统一时刻只有一个进程能够进入临界区 信号量信号量(Semaphore)是一个整形变量, 是常见的PV操作 进程通信管道管道是通过调用pipe函数创建的, fd[0]用于读, fd[1]用于写. 支持半双工, 只能在父子进程中使用 FIFO命名管道常用于客户-服务器应用程序, 在二者的进程中传递数据. 消息队列相比于FIFO, 有一下优点: 消息队列可以独立与读写进程存在, 从而避免了FIFO中同步管道的打开和关闭时可能产生的困难. 避免了FIFO同步阻塞问题, 不需要进程自己提供同步方法 读进程可以根据消息类型有选择接受, 而不像FIFO那样只能默认接收 信号量计数器, 用于为多个进程提供对共享对象的访问服务. 共享存储云溪多个进程共享一个给定的存储区 需要使用信号量来同步对共享存储的访问 套接字用于不同机器间的进程通信","categories":[],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://wt-git-repository.github.io/tags/操作系统/"}]},{"title":"Redis","slug":"Redis","date":"2019-06-09T01:35:35.000Z","updated":"2019-07-08T01:15:52.692Z","comments":true,"path":"2019/06/09/Redis/","link":"","permalink":"https://wt-git-repository.github.io/2019/06/09/Redis/","excerpt":"简介Redis使用C语言开发的一个开源的高性能键值对(key-value)数据库,它通过提供多种键值数据类型来适应不同场景下的存储需求,目前Redis支持的键值数据类型如下: 字符串类型 散列类型 列表类型 集合类型 有序集合类型","text":"简介Redis使用C语言开发的一个开源的高性能键值对(key-value)数据库,它通过提供多种键值数据类型来适应不同场景下的存储需求,目前Redis支持的键值数据类型如下: 字符串类型 散列类型 列表类型 集合类型 有序集合类型 应用场景 缓存(主要用途) 分布式集群架构中的session分离 聊天室的在线好友列表 任务队列 应用排行榜 网络访问统计 数据过期处理 数字的自增(高并发下,订单号为yyyymmddHHmmsss001,使用Redis的自增功能,避免重复) Redis HA方案HA(High Available, 高可用性集群)集群系统的简称, 是 保证业务连续性的有效解决方案, 一般有两个或两个以上的结点,分为活动结点以及备用结点, 若活动结点出现了问题,导致正在运行的业务不能正常运行,备用结点此时就能侦测得到,并立即代替活动结点来执行业务,从而实现业务的不中断或短暂中断. Redis一般以主/从方式部署,官方推荐使用sentinel(哨兵)来实现高可用. sentinel是解决HA问题,cluster是解决主从复制问题. Redis集群可以在一组Redis节点之间实现高可用性,在集群中有一个master和多个slave节点,当master节点失效时,应选举出一个slave节点作为新的master, 然后Redis本身并没有自动发现故障并且进行主从切换的能力, 需要外部的监控方案来实现自动故障恢复. Redis Sentinel是官方推荐的高可用性解决方案,它是Redis集群的监控管理工具,可以提供节点监控.通知,自动故障恢复和客户端配置发现服务. 搭建Redis集群12345678910111213141516171819version: '3.1'services: master: image: redis container_name: redis-master ports: - 6379:6379 slave1: image: redis container_name: redis-slave-1 ports: - 6380:6379 command: redis-server --slaveof redis-master 6379 slave2: image: redis container_name: redis-slave-2 ports: - 6381:6379 command: redis-server --slaveof redis-master 6379 搭建Redis Sentinel集群12345678910111213141516171819202122232425262728version: '3.1'services: sentinel1: image: redis container_name: redis-sentinel-1 ports: - 26379:26379 command: redis-sentinel /usr/local/etc/redis/sentinel.conf volumes: - ./sentinel1.conf:/usr/local/etc/redis/sentinel.conf sentinel2: image: redis container_name: redis-sentinel-2 ports: - 26380:26379 command: redis-sentinel /usr/local/etc/redis/sentinel.conf volumes: - ./sentinel2.conf:/usr/local/etc/redis/sentinel.conf sentinel3: image: redis container_name: redis-sentinel-3 ports: - 26381:26379 command: redis-sentinel /usr/local/etc/redis/sentinel.conf volumes: - ./sentinel3.conf:/usr/local/etc/redis/sentinel.conf redis sentinel.conf12345678910port 26379dir /tmp# 自定义集群名,其中127.0.0.1为Redis-master的IP,6379为redis-master的端口,2为最小投票数# 如果使用docker部署, 切记别使用127.0.0.1, 要具体的IP地址sentinel monitor mymaster 127.0.0.1 6379 2sentinel down-after-milliseconds mymaster 30000sentinel parallel-syncs mymaster 1sentinel failover-timeout mymaster 180000sentinel deny-scripts-reconfig yes 相关命令123redis-cli -p 26379 sentinel master mymastersentinel slaves mymaster lettcue依赖12345678&lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; application.yml1234567891011spring: redis: lettuce: pool: max-active: 8 max-idle: 8 max-wait: -1ms min-idle: 0 sentinel: master: mymaster nodes: 192.168.75.140:26379, 192.168.75.140:26380, 192.168.75.140:26381 接口1234public interface RedisService &#123; public void set(String key, Object value, long seconds); public Object get(String key);&#125; 参考李卫民的教学视频","categories":[],"tags":[{"name":"Nosql","slug":"Nosql","permalink":"https://wt-git-repository.github.io/tags/Nosql/"}]},{"title":"SpringMVC","slug":"SpringMVC","date":"2019-06-08T07:53:17.000Z","updated":"2019-07-08T01:15:52.695Z","comments":true,"path":"2019/06/08/SpringMVC/","link":"","permalink":"https://wt-git-repository.github.io/2019/06/08/SpringMVC/","excerpt":"MVC设计模式","text":"MVC设计模式 Spring MVC工作原理（适配器模式）1、前端控制器DispatcherServlet（不需要工程师开发）,由框架提供（重要）作用：Spring MVC 的入口函数。接收请求，响应结果，相当于转发器，中央处理器。有了 DispatcherServlet 减少了其它组件之间的耦合度。用户请求到达前端控制器，它就相当于mvc模式中的c，DispatcherServlet是整个流程控制的中心，由它调用其它组件处理用户的请求，DispatcherServlet的存在降低了组件之间的耦合性。 2、处理器映射器HandlerMapping(不需要工程师开发),由框架提供作用：根据请求的url查找Handler。HandlerMapping负责根据用户请求找到Handler即处理器（Controller），SpringMVC提供了不同的映射器实现不同的映射方式，例如：配置文件方式，实现接口方式，注解方式等。 3、处理器适配器HandlerAdapter作用：按照特定规则（HandlerAdapter要求的规则）去执行Handler 通过HandlerAdapter对处理器进行执行，这是适配器模式的应用，通过扩展适配器可以对更多类型的处理器进行执行。 4、处理器Handler(需要工程师开发)注意：编写Handler时按照HandlerAdapter的要求去做，这样适配器才可以去正确执行Handler Handler 是继DispatcherServlet前端控制器的后端控制器，在DispatcherServlet的控制下Handler对具体的用户请求进行处理。 由于Handler涉及到具体的用户业务请求，所以一般情况需要工程师根据业务需求开发Handler。 5、视图解析器View resolver(不需要工程师开发),由框架提供作用：进行视图解析，根据逻辑视图名解析成真正的视图（view） View Resolver负责将处理结果生成View视图，View Resolver首先根据逻辑视图名解析成物理视图名即具体的页面地址，再生成View视图对象，最后对View进行渲染将处理结果通过页面展示给用户。 springmvc框架提供了很多的View视图类型，包括：jstlView、freemarkerView、pdfView等。 一般情况下需要通过页面标签或页面模版技术将模型数据通过页面展示给用户，需要由工程师根据业务需求开发具体的页面。 6、视图View(需要工程师开发)View是一个接口，实现类支持不同的View类型（jsp、freemarker、pdf…） 注意：处理器Handler（也就是我们平常说的Controller控制器）以及视图层view都是需要我们自己手动开发的。其他的一些组件比如：前端控制器DispatcherServlet、处理器映射器HandlerMapping、处理器适配器HandlerAdapter等等都是框架提供给我们的，不需要自己手动开发。 参考JavaGuide","categories":[],"tags":[{"name":"SpringMVC","slug":"SpringMVC","permalink":"https://wt-git-repository.github.io/tags/SpringMVC/"}]},{"title":"SpringBean","slug":"SpringBean","date":"2019-06-08T07:06:40.000Z","updated":"2019-07-08T01:15:52.692Z","comments":true,"path":"2019/06/08/SpringBean/","link":"","permalink":"https://wt-git-repository.github.io/2019/06/08/SpringBean/","excerpt":"前言在Spring中，那些组成应用程序的主体以及那些由Spring IoC 容器锁管理的对象，被称之为bean。 简单来讲，bean就是由IoC容器初始化、装配及管理的对象。 Spring中的bean默认是单例的，Spring的单例基于JVM，每个JVM内只有一个实例。 在大多数情况下，单例子bean都是很理想的方案，除了使用一些需要保持一些状态的bean.","text":"前言在Spring中，那些组成应用程序的主体以及那些由Spring IoC 容器锁管理的对象，被称之为bean。 简单来讲，bean就是由IoC容器初始化、装配及管理的对象。 Spring中的bean默认是单例的，Spring的单例基于JVM，每个JVM内只有一个实例。 在大多数情况下，单例子bean都是很理想的方案，除了使用一些需要保持一些状态的bean. bean的作用域 配置和注解1&lt;bean id=\"ServiceImpl\" class=\"cn.csdn.service.ServiceImpl\" scope=\"singleton\"&gt; 1234@Service@Scope(\"singleton\")public class ServiceImpl&#123;&#125; bean的生命周期initialization and destroySpring 框架提供了很多方法让我们在Spring Bean生命周期中执行initialization和pre-destroy方法. 使用@PostConstruct和@PreDestroy注解 12345678910public class GiraffeService &#123; @PostConstruct public void initPostConstruct()&#123; System.out.println(\"执行PostConstruct注解标注的方法\"); &#125; @PreDestroy public void preDestroy()&#123; System.out.println(\"执行preDestroy注解标注的方法\"); &#125;&#125; 通过bean的配置文件中指定init-method和destroy-method方法 123&lt;bean name=\"giraffeService\" class=\"com.giraffe.spring.service.GiraffeService\" init-method=\"initMethod\" destroy-method=\"destroyMethod\"&gt;&lt;/bean&gt; 12345678910public class GiraffeService &#123; //通过&lt;bean&gt;的destroy-method属性指定的销毁方法 public void destroyMethod() throws Exception &#123; System.out.println(\"执行配置的destroy-method\"); &#125; //通过&lt;bean&gt;的init-method属性指定的初始化方法 public void initMethod() throws Exception &#123; System.out.println(\"执行配置的init-method\"); &#125;&#125; Aware接口 ApplicationContextAware: 获得ApplicationContext对象,可以用来获取所有Bean definition的名字。 BeanFactoryAware:获得BeanFactory对象，可以用来检测Bean的作用域。 BeanNameAware:获得Bean在配置文件中定义的名字。 ResourceLoaderAware:获得ResourceLoader对象，可以获得classpath中某个文件。 ServletContextAware:在一个MVC应用中可以获取ServletContext对象，可以读取context中的参数。 ServletConfigAware： 在一个MVC应用中可以获取ServletConfig对象，可以读取config中的参数。 总结 Bean容器找到配置文件中 Spring Bean 的定义。 Bean容器利用Java Reflection API创建一个Bean的实例。 如果涉及到一些属性值 利用set方法设置一些属性值。 如果Bean实现了BeanNameAware接口，调用setBeanName()方法，传入Bean的名字。 如果Bean实现了BeanClassLoaderAware接口，调用setBeanClassLoader()方法，传入ClassLoader对象的实例。 如果Bean实现了BeanFactoryAware接口，调用setBeanClassLoader()方法，传入ClassLoader对象的实例。 与上面的类似，如果实现了其他Aware接口，就调用相应的方法。 如果有和加载这个Bean的Spring容器相关的BeanPostProcessor对象，执-行postProcessBeforeInitialization()方法 如果Bean实现了InitializingBean接口，执行afterPropertiesSet()方法。 如果Bean在配置文件中的定义包含init-method属性，执行指定的方法。 如果有和加载这个Bean的Spring容器相关的BeanPostProcessor对象，执 行postProcessAfterInitialization()方法 当要销毁Bean的时候，如果Bean实现了DisposableBean接口，执行destroy()方法。 当要销毁Bean的时候，如果Bean在配置文件中的定义包含destroy-method属性，执行指定的方法。 Spring IoC（工厂模式）IoC 是一种设计思想， 将原本在程序中手动创建对象的控制权， 交由Spring框架来管理。 IoC容器是Spring用来实现IoC的载体， IoC容器实际上就是个Map(K, V)， 存放各种对象。 IoC容器就像是一个工厂一样，当我们需要创建一个对象的时候， 只需要配置好配置文件或注解即可， 完全不用考虑对象是怎么被创建出来的。 为了更好地去了解IoC， 此处我需要补充几个知识点 依赖倒置原则： 把原本的高层建筑依赖底层建筑倒置过来， 变成底层建筑依赖高层建筑， 高层建筑需要什么， 底层建筑便去实现这样的需求， 高层并不需要管底层是怎么实现的， 这样就不会出现牵一发而动全身的情况。 DI(Dependecy Inject,依赖注入)是实现控制反转的一种设计模式，依赖注入就是将实例变量传入到一个对象中去 控制反转就是依赖倒置原则的一种代码设计思路， 具体方法是依赖注入。 Spring IoC有什么好处 工厂设计模式Spring 使用工厂模式可以通过BeanFactory 和 ApplicationContext创建bean对象 BeanFactory： 延迟注入， 需要使用到某个Bean时才会注入， 占用较少内存， 程序启动速度更快 ApplicationContext: 启动是一次性创建所有的Bean 对比： BeanFactory仅仅提供了最基本的依赖注入支持， ApplicationContext扩展了BeanFactory， 所以一般会使用ApplicationContext会更多一点。 ApplicationContext三个实现类： ClassPathXmlApplication: 从上下文中加载资源文件 FileSystemXmlApplication: 从文件系统中加载资源文件 XmlWebApplicationContext: 从Web系统中加载资源文件 参考JavaGuide-Spring Bean","categories":[],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://wt-git-repository.github.io/tags/Spring/"}]},{"title":"MySQL三范式","slug":"MySQL三范式","date":"2019-06-08T02:13:16.000Z","updated":"2019-07-08T01:15:52.686Z","comments":true,"path":"2019/06/08/MySQL三范式/","link":"","permalink":"https://wt-git-repository.github.io/2019/06/08/MySQL三范式/","excerpt":"","text":"第一范式（1st NF - 列都是不可再分的）要求：第一范式的目标是确保每一列的原子性，每一列都是不可再分的最小数据单元。 第二范式（2st NF - 每张表只描述一件事情）前提： 满足第一范式要求： 表中的非主键列不存在对主键的部分依赖。 第三范式（3st NF - 不存在对非主键列的传递依赖）前提：满足第二范式要求：表中的列不存在对非主键列的传递依赖。 参考数据库，部分函数依赖，传递函数依赖，完全函数依赖，三种范式的区别","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://wt-git-repository.github.io/tags/MySQL/"}]},{"title":"Manjaro配置中国源","slug":"Manjaro配置中国源","date":"2019-06-06T03:40:34.000Z","updated":"2019-07-08T01:15:52.684Z","comments":true,"path":"2019/06/06/Manjaro配置中国源/","link":"","permalink":"https://wt-git-repository.github.io/2019/06/06/Manjaro配置中国源/","excerpt":"","text":"配置镜像源123sudo pacman-mirrors -gb testing -c Chinasudo pacman-mirrors -g 系统更新1sudo pacman -Syyu","categories":[],"tags":[]},{"title":"Kubernetes","slug":"Kubernetes","date":"2019-06-06T02:28:19.000Z","updated":"2019-07-08T01:15:52.679Z","comments":true,"path":"2019/06/06/Kubernetes/","link":"","permalink":"https://wt-git-repository.github.io/2019/06/06/Kubernetes/","excerpt":"","text":"简介（容器编排工具）Kubernetes 是Google创建管理的容器集群关系系统，开源，开源实现容器集群的自动化部署、自动扩缩容、维护等功能，其目标是促进完善组件和工具的生态系统，以减轻应用程序在公有云或私有云中运行的负担。 安装kubeadmkubeadm是kubernetes的集群安装工具，能够快速安装kubernetes集群。 待定","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://wt-git-repository.github.io/tags/Docker/"}]},{"title":"数据结构-树相关","slug":"数据结构-树相关","date":"2019-06-05T07:53:43.000Z","updated":"2019-07-08T01:15:52.733Z","comments":true,"path":"2019/06/05/数据结构-树相关/","link":"","permalink":"https://wt-git-repository.github.io/2019/06/05/数据结构-树相关/","excerpt":"","text":"堆排序堆分为最大堆和最小堆 最大堆定义：设数组a存放了n个数据元素，数组下标从0开始，如果当数组下标2i+1&lt;n时存在a[i].key&gt;a[2i+1].key&gt;=a[i].key，当数组下标2i+2&lt;n时，有a[i].key&gt;=a[2i+2].key，这样的数据结构称为最大堆。 最大堆的根节点是堆值中最大的数据元素。 对于最大堆，从根结点到每个叶结点的路径，数组元素组成的序列都是递减有序的 通常把堆的根节点称为堆顶元素。 最小堆（与最大堆类似，这里不再累赘） 创建堆在完全二叉树中，第一个非叶子结点a[i] (i = (n - 2) / 2) 创建思路：从第一个非叶子结点开始，找出a[2i+1]和a[2i+2]的最大值，并与a[i]进行比对，若比a[i]小，则说明以a[i]为更结点的堆已经是最大堆，否则，二者交换。以此类推，直到调整到根节点。 值得注意的是：若左右子节点并非叶子结点，与a[i]的调换可能会引起子节点的一连串调整，这也是值得我们注意的地方 1234567891011121314151617181920212223242526272829303132/** * @param data 待排序的数组 * @param n 元素的总个数 * @param h 当前的根节点 */void createHeap(int[] data, int n, int h) &#123; int i = h; int j = 2 * i + 1; int temp = data[i]; while (j &lt; n) &#123; // 寻找左右子节点的最大值 if (j + 1 &lt; n &amp;&amp; data[j] &lt; data[j + 1]) j++; // 对比根节点与左右子节点的最大值 if (temp &gt; data[j]) &#123; break; &#125; else &#123; data[i] = data[j]; i = j; j = 2 * i + 1; &#125; &#125; data[i] = temp;&#125;void initHeap(int[] data, int n) &#123; for (int i = (n - 2) / 2; i &gt; -1; i--) &#123; createHeap(data, n, i); &#125;&#125; 利用最大堆来进行排序12345678910void heapSort(int[] data, int n) &#123; initHeap(data, n); for (int i = n - 1;i &gt; -1;i--) &#123; int temp = data[i]; data[i] = data[0]; data[0] = temp; createHeap(data, i, 0); &#125;&#125;","categories":[],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://wt-git-repository.github.io/tags/数据结构/"}]},{"title":"Nginx","slug":"Nginx","date":"2019-06-05T06:20:12.000Z","updated":"2019-07-08T01:15:52.688Z","comments":true,"path":"2019/06/05/Nginx/","link":"","permalink":"https://wt-git-repository.github.io/2019/06/05/Nginx/","excerpt":"","text":"Nginx简介Nginx是一款高性能Http服务器、反向代理服务器以及电子邮件（IMAP、POP3）代理服务器，能支撑5万并发，CPU、内存等资源消耗非常低，运行稳定。 Nginx应用场景 HTTP服务器：Nginx是一个HTTP服务，可以独立提供HTTP服务，可以做网页静态服务器。 虚拟主机：可以实在一台服务器虚拟出多个网站。 反向代理、负载均衡：可以使用Nginx反向代理到多个集群。 docker-compose.yml123456789101112131415161718192021222324version: '3.1'services: tomcat9090: image: tomcat container_name: tomcat9090 restart: always ports: - 9090:8080 tomcat9091: image: tomcat container_name: tomcat9091 restart: always ports: - 9091:8080 nginx: image: nginx container_name: nginx restart: always ports: - 80:80 - 9000:9000 volumes: - ./conf/nginx.conf:/etc/nginx/nginx.conf - ./web:/usr/share/nginx/wwwroot 虚拟主机虚拟主机是一种特殊的软硬件技术，它可以将网络上的每一台计算机分成多个虚拟主机，每个虚拟主机可以独立对外提供www服务，这样就实现一台主机对外提供web服务。 通过Nginx可以实现虚拟主机的配置，Nginx支持三种类型的虚拟主机的配置 基于IP的虚拟主机 基于域名的虚拟主机 基于端口的虚拟主机 配置文件123456789101112131415161718192021222324252627282930313233343536373839404142# CPU多少核就填多少核，充分利用CPU资源worker_processes 1;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application:octet-stream; sendfile on; keepalive_timeout 65; server &#123; listen 80; # 基于 IP server_name 172.28.7.36; # 基于域名 # server_name endalin.com; location / &#123; root /usr/share/nginx/wwwroot/welcome; index index.html; &#125; &#125; server &#123; # 基于端口 # listen 81; listen 80; server_name 172.28.7.36; # 基于域名 # server_name oj.endalin.com; location / &#123; root /usr/share/nginx/wwwroot/welcome81; index index.html; &#125; &#125;&#125; 反向代理、负载均衡反向代理服务器架设在服务器端，通过缓存经常被请求的页面来缓解服务器的工作量，将客户机请求转发给内部网络上的目标服务器，并将从服务器上得到的结果返回给Internet上请求连接的客户端，此时代理服务器和目标主机对外表现为一个服务器。 docker-compose.yml123456789101112131415161718192021222324version: '3.1'services: tomcat9090: image: tomcat container_name: tomcat9090 restart: always ports: - 9090:8080 tomcat9091: image: tomcat container_name: tomcat9091 restart: always ports: - 9091:8080 nginx: image: nginx container_name: nginx restart: always ports: - 80:80 - 9000:9000 volumes: - ./conf/nginx.conf:/etc/nginx/nginx.conf - ./web:/usr/share/nginx/wwwroot 配置文件12345678910111213141516171819202122232425262728worker_processes 1;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application:octet-stream; sendfile on; keepalive_timeout 65; upstream tomcatServer&#123; server 10.42.29.120:9000 weight=10; server 10.42.29.120:9091 weight=10; &#125; server &#123; listen 80; server_name 10.42.29.120; location / &#123; proxy_pass http://tomcatServer; index index.html index.jsp; &#125; &#125;&#125;","categories":[],"tags":[{"name":"运维","slug":"运维","permalink":"https://wt-git-repository.github.io/tags/运维/"}]},{"title":"RabbitMQ","slug":"RabbitMQ","date":"2019-06-05T01:27:13.000Z","updated":"2019-07-08T01:15:52.690Z","comments":true,"path":"2019/06/05/RabbitMQ/","link":"","permalink":"https://wt-git-repository.github.io/2019/06/05/RabbitMQ/","excerpt":"","text":"RabbitMQ相关概念生产者和消费者 producer：消息的生产者 consumer：消息的消费者 Queue 消息队列：提供了FIFO的处理机制，具有缓存数据的能力 在RabbitMQ中，队列消息可以设置为持久化、临时或自动删除 持久化队列：队列中的消息会在Server本地磁盘存储一份，防止系统挂掉，导致数据丢失。 临时队列：队列中的数据在系统重启后就会丢失。 自动删除的队列：当不存在用户连接到Server，队列中的数据就会被自动删除。 ExChange类似于交换机，提供消息路由策略。在RabbitMQ中，Producer不是通过信道直接将消息发送给Queue的，而是先发给ExChange，一个ExChange与多个Queue绑定，Producer在传递消息的时候，会传递一个ROUTING_KEY,ExChange会根据这个值按照特定的路由算法，将消息分配给指定的Queue，与Queue一样，ExChange也有持久、临时和自动删除的。 Binding所谓绑定就是一个特定的Exchange与一个特定的Queue绑定起来。ExChange和Queue的绑定可以是多对多的关系。 VirtualRabbitMQ的使用过程 客户端连接到消息队列服务器，打开一个Channel 客户端声明一个ExChange，并设置相关属性 客户端声明一个Queue，并设置相关属性 客户端使用Routing Key，在ExChange与Queue之间建立好绑定关系 客户端投递消息到ExChange ExChange接收到消息之后，就根据消息的key和已经绑定好的binging，进行消息路由，将消息投递到一个或多个队列里 docker-compose.yml1234567891011121314version: '3.1'services: rabbitmq: restart: always image: rabbitmq:management container_name: rabbitmq ports: - 5672:5672 - 15672:15672 environment: RABBITMQ_DEFAULT_USER: rabbit RABBITMQ_DEFAULT_PASS: 123456 volumes: - ./data:/var/lib/rabbitmq 消息提供者123456spring: rabbitmq: host: 127.0.0.1 port: 5672 username: rabbit password: 123456 123456789101112131415161718192021@Configurationpublic class RabbitConfiguration &#123; @Bean public Queue queue() &#123; return new Queue(\"helloRabbit\"); &#125;&#125;@Componentpublic class RabbitProvider &#123; @Autowired private AmqpTemplate amqpTemplate; public void send() &#123; String content = \"Hello World \" + new Date(); System.out.println(\"Provider: \" + content); amqpTemplate.convertAndSend(\"helloRabbit\", content); &#125;&#125; 消息消费者123456789@Component@RabbitListener(queues = \"helloRabbit\")public class RabbitConsumer &#123; @RabbitHandler public void process(String content) &#123; System.out.println(\"Consumer:\" + content); &#125;&#125; 问题 如何保证消息队列中的数据百分之一百被消费掉","categories":[],"tags":[{"name":"消息队列","slug":"消息队列","permalink":"https://wt-git-repository.github.io/tags/消息队列/"}]},{"title":"计算机网络基础知识之运输层","slug":"计算机网络基础知识","date":"2019-06-03T10:39:19.000Z","updated":"2019-07-08T01:15:52.734Z","comments":true,"path":"2019/06/03/计算机网络基础知识/","link":"","permalink":"https://wt-git-repository.github.io/2019/06/03/计算机网络基础知识/","excerpt":"运输层基本术语 进程：指计算机正在运行的实体 应用进程的相互通信： 一台主机的进程和另一台主机的一个进程交换数据的过程 传输层的复用与分用：复用是指发送方不同的进程可以通过一个传输层协议传送数据， 分用指的是接收方的传输层在剥去报文的首部后能把这些数据正确地交到目的应用进程中。 TCP：传输控制协议 UDP：用户数据报协议 端口：为的是确认对方机器是哪一个进程在和自己交互 停止等待协议：指发送方每发送完一个分组就停止发送，等待对方确认，在收到确认之后再发送下一个分组。 流量控制：控制对方的发送速率，既要让接收方来得及接收，也不要使网络发送拥塞 拥塞控制：防止过多数据注入网络中，防止路由器或者链路过载。","text":"运输层基本术语 进程：指计算机正在运行的实体 应用进程的相互通信： 一台主机的进程和另一台主机的一个进程交换数据的过程 传输层的复用与分用：复用是指发送方不同的进程可以通过一个传输层协议传送数据， 分用指的是接收方的传输层在剥去报文的首部后能把这些数据正确地交到目的应用进程中。 TCP：传输控制协议 UDP：用户数据报协议 端口：为的是确认对方机器是哪一个进程在和自己交互 停止等待协议：指发送方每发送完一个分组就停止发送，等待对方确认，在收到确认之后再发送下一个分组。 流量控制：控制对方的发送速率，既要让接收方来得及接收，也不要使网络发送拥塞 拥塞控制：防止过多数据注入网络中，防止路由器或者链路过载。 重要知识 网络层为主机提供逻辑通信，运输层为进程提供逻辑通信。 运输层两个重要协议：TCP和UDP。 硬件端口是不同硬件设备进行交互的接口，而软件端口是应用层各种进程交互的一种地址。 运输层的端口号分为服务器端使用的端口号和客户端暂时使用的端口号。 UDP的主要特点：无连接、尽最大努力交互、面向报文、无拥塞控制、支持一对一，一对多，多对一和多对多的交互通信，首部开销小 TCP：面向连接、只能是一对一，提供可靠交互，提供全双工通信，面向字节流 TCP用主机的IP地址加上主机上的端口号作为TCP连接的端点，这个端点就称为套接字，每一条TCP连接都被两个可确定的端口所确定。 停止等待协议：为了实现可靠传输，每传输完一个分组就停止发送，等对方确认之后，再继续发送下一个分组。 停止等待协议的超时重传（自动重传ARQ）：只要超过一段时间仍然没有收到确定，就重传前面发送过的分组。若在该协议中收到重复分组，则还要继续发送确认（因为确认分组也有可能会丢失） 发送维持一个发送窗口，凡是位于窗口之内的分组可以连续发送出去，而不需要等待对方确认，接收方按最后一个分组发送确认，表面到这个分组的位置的全部分组已经全部接收。（滑动窗口机制） 滑动窗口机制：用于流量控制 发送窗口：拥塞控制窗口的大小取决于网络的拥挤程度，并且动态变化，TCP发送方让自己的发送窗口取为拥塞窗口和接收方的接受窗口较小的一个。 流量控制：点对点通信量的控制，是个端对端的问题，流量控制所要做到的就是抑制发送端发送数据的速率，以适应接收方的接受能力。 拥塞：在某段时间，软对某一资源的需求超过了该资源所能提供的可用部分，网络性能就会变差，如信道运输数据的能力 拥塞控制：复制过多的数据注入到网络中，防止路由器或者链路不至于过载，拥塞控制是一个全局性的过程，设计到所有主机、路由器以及降低网络传输性能有关的所有因素 TCP拥塞控制的四种算法：慢开始、拥塞避免、快重传和快恢复。 运输层连接的三个阶段：连接建立、数据传送和连接释放。 TCP三次握手四次挥手一开始，服务器首先创建传输块TCB（存储每一个连接中的重要信息），准备接受客户进程的连接请求，此处，服务器进程便进入的LISTEN（监听）状态。 三次握手 客户端首先创建一个TCB，在打算建立TCP连接之时，向服务器发出连接请求报文，SYM=1（SYM=1的报文段表示为一个连接请求报文），seq=x ，TCP规定，SYM=1的报文段需要消耗掉一个序列号。此处客户端进入SYN-SENT（同步已发送）状态 服务器收到请求之后，如果同意建立连接，则向客户端发出确认。ACK=1,SYM=1,ack=x+1,seq=y.TCP 规定，在连接建立后，所有传送的报文端都需要把ACK置为1，此时服务器端进入SYN-RCVD(同步收到)状态 客户端收到服务器端的确认后，还要给服务器确认。ACK=1,ack=y+1,seq=x+1, 此时不是SYN请求连接报文了，ACK报文段是可以携带数据的，但是此处不用，所以seq=x+1.此时客户端进入ESTABLISHED(已经建立)的状态 四次挥手数据传输结束后，通信双方都可释放连接，现在客户端和服务器端都处于ESTABLISHED状态。 客户端发送连接释放报文，FIN=1，seq=u，u是前面已经传送过的数据的最后一个字节加1.TCP规定，FIN报文段即使不携带数据，它也要消耗一个序号。此时，客户端进入FIN-WAIT-1（终止等待1）状态，等待B确认。 服务器收到连接释放报文段后发出确认，ACK=1(ACK=1时，ack才有效),ack=u+1,seq=v，V是服务器之前传送过的数据的最后一个字节的序号+1，此时服务器进入CLOSE-WAIT(关闭等待)状态此时客户端进入FIN-WAIT-2(终止等待2)状态,等待B发出连接释放报文 若服务器已经没有要向客户端发出的数据，应用进程就通知TCP释放连接。FIN=1，ACK=1，ack=u+1,seq=w，seq之所以为w，是因为B可能还有一些数据发送到了给A，此时服务器进入LAST-ACK(最后确认状态)。 客户端收到服务器段的连接释放报文后，必须要对服务器进行确认。ACK=1，ack=w+1,seq=u+1客户端进入TIME—WAIT（时间等待）状态，然后在进入CLOSE状态。 问题 端口和套接字的意义 无连接UDP的特点 面向连接TCP的特点 在不可靠的网络上实现可靠传输的工作原理，停止等待协议和APQ协议 TCP滑动窗口、流量控制、拥塞控制和连接管理。 参考TCP三次握手四次挥手","categories":[],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://wt-git-repository.github.io/tags/计算机网络/"}]},{"title":"SpringCloud微服务架构实战读书笔记②","slug":"SpringCloud微服务架构实战读书笔记②","date":"2019-06-03T07:45:27.000Z","updated":"2019-07-08T01:15:52.694Z","comments":true,"path":"2019/06/03/SpringCloud微服务架构实战读书笔记②/","link":"","permalink":"https://wt-git-repository.github.io/2019/06/03/SpringCloud微服务架构实战读书笔记②/","excerpt":"","text":"使用Feign实现声明式REST调用为服务消费者整合Feign 添加依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt;&lt;/dependency&gt; 创建一个Feign接口，并添加@FeignClient注解 12345@FeignClient(name=\"applicationName\")public interface UserFeignClient &#123; @RequestMapping(value = \"/&#123;id&#125;\") public User findById(@PathVatiable(\"id\")Long id);&#125; @FeignClient注解是任意一个服务提供方的名称，用以创建Ribbon负载均衡器。 自定义Feign配置修改接口1@FeignClient(name=\"applicationName\"， configuration = FeignConfiguration.class) 有一点值得注意的是，本例中的FeignConfiguration类不能包括在主程序上下文的@ComponentScan中，否则该类中的配置信息就会被所有的@FeignClient共享， 如果只想定义某个FeignClient客户端的配置，该点需要特别注意。此处可以配置@ComponentScan不扫描配置类的所在包 手动创建FeignFeign对继承的支持Feign对压缩的支持Feign的日志使用Feign构造多参数请求Spring Cloud为Feign添加了Spring MVC的注解支持。 例子一 12345@FeignClient(name=\"applicationName\")public interface UserFeignClient &#123; @GetMapping(value = \"/&#123;id&#125;\") public User findById(@RequestParam Map&lt;String, Object&gt; map);&#125; 例子二 12345@FeignClient(name=\"applicationName\")public interface UserFeignClient &#123; @PostMapping(value = \"/&#123;id&#125;\") public User findById(User user);&#125;","categories":[],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://wt-git-repository.github.io/tags/JAVA/"}]},{"title":"MySQL索引与锁","slug":"MySQL索引与锁","date":"2019-06-03T02:58:02.000Z","updated":"2019-07-08T01:15:52.687Z","comments":true,"path":"2019/06/03/MySQL索引与锁/","link":"","permalink":"https://wt-git-repository.github.io/2019/06/03/MySQL索引与锁/","excerpt":"MySQL存储引擎的基础知识 MySQL的基本存储结构是页，所有记录都存储在页里面。 每个页之间组成的是一个双向链表。 每个数据页里面的记录可以组成一个单向链表。 每个数据页都会为存储在本页里面的数据生成一个页目录，在通过主键查找某条记录时可以使用二分法快速定位 而根据其它列进行检索时，就只能通过遍历的手段 在没有任何索引的的表中，select语句的执行会进行如下两次遍历 遍历双向链表，找到所在页 遍历页内的单链表，找到所在的记录","text":"MySQL存储引擎的基础知识 MySQL的基本存储结构是页，所有记录都存储在页里面。 每个页之间组成的是一个双向链表。 每个数据页里面的记录可以组成一个单向链表。 每个数据页都会为存储在本页里面的数据生成一个页目录，在通过主键查找某条记录时可以使用二分法快速定位 而根据其它列进行检索时，就只能通过遍历的手段 在没有任何索引的的表中，select语句的执行会进行如下两次遍历 遍历双向链表，找到所在页 遍历页内的单链表，找到所在的记录 索引提高检索速度索引的主要作用就是将无序变成有序。 record_type=1 代表存放的是普通目录项的记录record_type=0 代表存放的是普通用户的记录 底层结构一般都是B+树，B+树是平衡树的一种，它是一个空树或者是左右子树的高度差的绝对值不会超过1，左右子树都是一颗平衡二叉树。深度为lgn 索引在提高检索速度的同时，同时会降低增删改的速度，因为要对B+树做增删改的话，会破坏它原来的结构，而且要维护平衡树，就必要做额外的工作。 聚集索引和非聚集索引概括： 聚集索引是以主键创建的索引。 非聚集索引是以非主键创建的索引。InnoDB要求表必须有主键（MyISAM可以没有），Innodb会按照如下规则进行处理： 如果一个主键被定义了，那么这个主键就是作为聚集索引 如果没有主键被定义，那么该表的第一个唯一非空索引被作为聚集索引 如果没有主键也没有合适的唯一索引，那么innodb内部会生成一个隐藏的主键作为聚集索引，这个隐藏的主键是一个6个字节的列，改列的值会随着数据的插入自增。 区别： 聚集索引在叶子节点存储的是表中的数据。 非聚集索引在叶子节点存储的是主键和索引列。 使用非聚集索引查询出数据时，拿到叶子上的主键再去查想要查找的数据。（拿到主键再去查找的这个过程叫做回表） 聚集索引是物理上的连续，而非聚集索引是逻辑上的连续，物理存储并不连续。 非聚集索引和聚集索引的区别在于:通过聚集索引可以查到需要查找的数据， 而通过非聚集索引可以查到记录对应的主键值 ， 再使用主键的值通过聚集索引查找到需要的数据 覆盖索引： 如果不是聚集索引，叶子节点存储的是主键+索引列，如果需要查询的列，叶子节点都存在，那么就不用回表，提高效率。 索引最左匹配原则最左匹配原则： 索引可以简单如一个列(a)，也可以复杂如多个列(a, b, c, d)，即联合索引。 如果是联合索引，那么key也由多个列组成，同时，索引只能用于查找key是否存在（相等），遇到范围查询(&gt;、&lt;、between、like左匹配)等就不能进一步匹配了，后续退化为线性查找。 因此，列的排列顺序决定了可命中索引的列数。 例子： 如有索引(a, b, c, d)，查询条件a = 1 and b = 2 and c &gt; 3 and d = 4，则会在每个节点依次命中a、b、c，无法命中d。(很简单：索引命中只能是相等的情况，不能是范围匹配) 索引总结 最左匹配原则 尽量选择区分度高的列作为索引 索引列不能参与计算，尽量保持列干净 尽可能扩展索引，不要新建立索引 锁 对于UPDATE、DELETE、INSERT语句，InnoDB会自动给涉及数据集加排他锁 表锁（InnoDB行锁表锁都支持，MyISAM只支持表锁） 表锁：开销小，加锁快，不会出现死锁，锁的粒度大，并发度低。 行锁：开销大，加锁慢，会出现死锁，锁的粒度小，并发度大 行锁 InnoDB支持行锁 InnoDB支持表锁 行锁类型： 共享锁（S锁）：允许多个获得共享锁的事物同时读取同一个资源，但不允许其他客户端修改 排他锁（X锁）：允许获得排他锁的事物更新数据，阻止其他事物修改或读取同一数据集。 乐观锁与悲观锁 乐观锁（认为一个用户读数据时，别人不会去写自己所读的数据）：在表中添加一个版本字段，第一次读的时候，获取到这个字段，处理完业务逻辑准备更新的时候，需要再次查看这个字段是否和第一次获取到的字段是否一样，若一样则更新，否则则拒绝。 悲观锁（在读取数据是，不允许别人去修改）：直接在把数据库层面上加锁。 事物的隔离级别什么是事务事物是逻辑上的一组操作，要么全部执行，要么全部不执行。 事务的特性（ACID） 原子性：事务是最小的执行单位，要么全部执行，要么全部不执行 一致性：在事务执行的前后，所有事务对同一数据源的读取结果的一致的 隔离性：并发访问数据库时，各个事务互不干扰 持久性：在事务提交之后，它对数据库的改变是持久的，即使数据库发生故障，也不会有任何影响。 并发事务带来的问题 脏读：当一个事务对数据进行了修改之后就马上释放了排它锁，导致其它事务对未修改的数据进行了“脏数据”。 丢失修改：指两个事务同时对同一个数据进行了修改操作，导致一个事务的修改丢失 不可重复读：指在同一个事务中，对同一个数据进行多次读取，但是读出来的结果不一致，这里侧重于数据修改 幻读：在同一个事务中，同一次查询会多出或者少了一些数据，这是因为另一个并发的任务作出了增删操作，这里侧重与数据的增删 SQL标准定义的四个隔离级别(InnoDB 默认支持可重复读) READ-UNCOMMITTED(读取未提交)： 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。 READ-COMMITTED(读取已提交)： 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。 REPEATABLE-READ(可重复读)： 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。 SERIALIZABLE(可串行化)： 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。 参考资料 JavaGuide MySQL索引与锁 深入浅出数据库索引原理","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://wt-git-repository.github.io/tags/MySQL/"}]},{"title":"《JAVA并发编程的艺术》读书笔记④","slug":"《JAVA并发编程的艺术》读书笔记④","date":"2019-06-03T01:24:05.000Z","updated":"2019-07-08T01:15:52.722Z","comments":true,"path":"2019/06/03/《JAVA并发编程的艺术》读书笔记④/","link":"","permalink":"https://wt-git-repository.github.io/2019/06/03/《JAVA并发编程的艺术》读书笔记④/","excerpt":"","text":"数据依赖性 如果两个操作之间访问同一个变量，且这两个操作有一个为写操作，此时这两个操作就存在数据依赖性。 编译器和处理器在重排序时，会遵守数据依赖性，编译器和处理器不会改变存在数据依赖关系的两个操作的执行顺序。 这里所说的数据依赖性针对单个处理器中的指令序列和单个线程中执行的操作，不同处理器之间和不同线程之间的数据依赖性不被编译器和处理器考虑。 as-if-serial语义as-if-serial意思就是说：不管怎么重排序（编译器和处理器为了提高并行度），单线程程序的执行结果不能改变。 同步程序的顺序一致性效果 JMM在具体实现的基本方针是：在不改变正确同步的程序执行结果的前提下，尽可能地为编译器和处理器的优化打开方便之门。 JMM不保证对64位的long型和double型变量的写操作具有原子性。因为当JVM在一些32位的处理器上运行的时候，如果对64为数据的写操作要求原子性，会有比较大的开销，所以JVM可能会把一个64位的long/double写操作拆分成两个32位的写操作的来执行，这两个32位的写操作可能会被分配到不同的总线事务中，此时对这个64位的变量的写操作不具有原子性。 未同步程序的执行特性对于未同步或未正确同步的多线程程序,JMM只提供最小安全性: 线程执行时读取到的值, 要么是之前某个线程写入的值, 要么是默认值(0, NULL, false), JMM保证线程读操作读到的值不会无中生有. 为了实现最小安全性, JVM在堆上分配对象时,首先会对内存空间进行清零, 然后才会在上面分配对象(JVM会同步这两个操作), 因此, 在已清零的内存空间分配对象是,域的默认初始化已经完成了. 锁的内存语义锁的释放和获取的内存语义当线程获取锁的时候,JMM会把该线程对应的本地内存置为无效,从而是的被监视器保护的临界区代码必须从主内存中读取共享变量. 对锁释放和锁获取的内存含义做个总结: 线程A释放一个锁, 实质上是线程A向接下来将要获取这个锁的某个线程发出了线程A对共享变量所做出了修改的消息 线程B获取一个锁,实质上是线程B接收了之前某个线程(即A线程)对这个变量所作出的修改的消息 线程A释放锁, 然后线程B获取锁, 这个过程实质上是线程A通过主内存向线程B发送消息.","categories":[],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://wt-git-repository.github.io/tags/JAVA/"}]},{"title":"《JAVA并发编程的艺术》读书笔记③","slug":"《JAVA并发编程的艺术》读书笔记③","date":"2019-06-02T11:20:48.000Z","updated":"2019-07-08T01:15:52.722Z","comments":true,"path":"2019/06/02/《JAVA并发编程的艺术》读书笔记③/","link":"","permalink":"https://wt-git-repository.github.io/2019/06/02/《JAVA并发编程的艺术》读书笔记③/","excerpt":"","text":"JAVA内存模型的基础在命令式编程中，线程之间的通信机制有两种：共享内存和消息传递。 在共享内存的并发模型中，线程之间共享程序的公共状态，通过读写内存中的公共状态来进行隐式通信。 在消息传递的并发模型中，线程之间没有公共状态，线程之间必须通过发送消息来显式进行通信。 JAVA的并发采用的是共享内存模型。 JAVA内存模型的抽象结构 在JAVA中，所有实例域、静态域和数组元素都在堆内存中，堆内存在线程之间共享。 局部变量、方法定义参数和异常处理函数，在栈内存里面，不会在线程之间共享。 线程之间的共享变量存储在主内存中，每个线程都有一个私有的本地内存，本地内存存储了该内存以读写共享变量的副本。A与B之间的通信，需要通过以下2个步骤 线程A把本地内存A中更新过的共享变量刷新的主内存中。 线程B到主内存中去读取线程A之前已经更新过的共享变量。 从源代码到指令序列的重排序在执行程序时，为了提高性能，编译器和处理器通常会对指令做重排序，重排序分为三种： 编译器优化的重排序：编译器在不改变单线程语义的前提下，可以重新安排语句的执行顺序。 指令级并行的重排序：现代处理器采用了指令级并行技术来将多条指令重叠执行，如果不存在数据依赖性，处理器可以改变语句对应的机器指令的执行顺序。 内存系统的重排序：由于处理器使用缓存和读写缓冲区，这使得加载和存储操作看上去可能是乱序执行。 对于指令重排，JAVA内存模型的处理器重排序规则可以要求JAVA编译器在生成指令序列时，插入特定类型的内存屏障指令，通过内存屏障指令来禁止特定类型的处理器重排序。 内存屏障：指的是重排序时不能把后面的指令重排序到内存屏障之前的位置。 展示一个由于内存操作重排带来问题的例子（经典）在展示之前，首先补充一点知识：现代处理器使用写缓存区临时保存向内存下入的数据，以保证指令流水线持续运行，避免处理器停顿下来等待向内存写入数据而产生延迟，同时，以批处理的方式刷新缓存区，以及合并写缓存区对统一内存地址的多次写，减少堆内存总线的占用。 这个特性会对内存操作的顺序产生影响：处理器堆内存的读写操作的执行顺序，不一定与内存实际发生的读写操作顺序一致（因为内存操作重排） 如果AB同时执行，可能会得到读取到脏数据，原因如下： 此处由于指令重排，导致1-&gt;A2的顺序变成了A2-&gt;A1，所以读取了脏数据。 一般情况下，处理器都不允许对存在数据依赖的操作做重排序。 happens-before在JMM中，如果一个操作的结果需要对另一个操作可见，那么这两个操作之间必须要存在happens-before关系。 A happens-before B, JMM 并不要求A一定要在B之前执行, JMM仅仅要求前一个操作的结果对后一个操作课件,且前一个操作按顺序排在第二个操作之前.","categories":[],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://wt-git-repository.github.io/tags/JAVA/"}]},{"title":"一条SQL语句在MySQL中的执行流程","slug":"一条SQL语句在MySQL中的执行流程","date":"2019-06-02T08:24:55.000Z","updated":"2019-07-08T01:15:52.726Z","comments":true,"path":"2019/06/02/一条SQL语句在MySQL中的执行流程/","link":"","permalink":"https://wt-git-repository.github.io/2019/06/02/一条SQL语句在MySQL中的执行流程/","excerpt":"","text":"MySQL 架构分析首先，我们需要了解MySQL的一个简要的架构 连接器： 身份验证与权限相关 查询缓存：执行查询语句时，会先查询缓存（失效率过高，不推荐用） 分析器：分析SQL语句 优化器：优化SQL语句 执行器：执行SQL语句，并从存储引擎用返回数据 值得注意的是，Mysql分为了Server层和存储引擎层： Server层： 主要包括连接器、查询缓存、分析器、优化器和执行器等组件，很多功能都是在这一层实现的，如存储过程、触发器、视图、函数等等，还有一个日志模块binglog 存储引擎模块：支持InnoDB、MyISAM等等，InnoDB为默认的存储模块。 MySQL的日志模块这里，我们需要特别主义redo log 和 binlog这两个日志模块，前者是InnoDB自带的日志模块，后者是MySQL自带的日志模式。 SQL 语句的类型SQL语句的类型主要分为两种 查询： select 更新：update、delete 执行更新语句时，该如何操作这两个日志模块1update tb_student set name = 'wt' where name = 'name' 首先，要根据where查询到对应那一条数据 根据查询到的数据，先进行修改，然后调用引擎接口，写入这一行数据，InnoDB会把数据保存在缓存中，同时记录redo log,此时redo log 进入prepare状态，然后告诉执行器，执行结束 执行器收到通知后记录binlog，然后调用引擎接口，提交redo log为提交状态 更新完成 小结 MySQL 主要分为 Server 层和引擎层，Server 层主要包括连接器、查询缓存、分析器、优化器、执行器，同时还有一个日志模块（binlog），这个日志模块所有执行引擎都可以共用,redolog 只有 InnoDB 有。 引擎层是插件式的，目前主要包括，MyISAM,InnoDB,Memory 等。 查询语句的执行流程如下：权限校验（如果命中缓存）—》查询缓存—》分析器—》优化器—》权限校验—》执行器—》引擎 更新语句执行流程如下：分析器—-》权限校验—-》执行器—》引擎—redo log(prepare 状态—》binlog—》redo log(commit状态)","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://wt-git-repository.github.io/tags/MySQL/"}]},{"title":"《JAVA并发编程的艺术》读书笔记②","slug":"《JAVA并发编程的艺术》读书笔记②","date":"2019-06-01T10:44:37.000Z","updated":"2019-07-08T01:15:52.721Z","comments":true,"path":"2019/06/01/《JAVA并发编程的艺术》读书笔记②/","link":"","permalink":"https://wt-git-repository.github.io/2019/06/01/《JAVA并发编程的艺术》读书笔记②/","excerpt":"","text":"前言JAVA代码在编译之后会变成JAVA字节码，字节码被类加载器加载到JVM里面，JVM执行字节码，将字节码装换成汇编指令在CPU上执行。 JAVA中所执行的并发机制依赖JVM的实现和CPU的指令。 volatile在多线程并发编程中，volatile是轻量级的synchronized，它在多处理器开发中保证了共享变量的可见性，如果volatile变量修饰符使用恰当，它比synchronized的使用或执行成本更低，因为它不会引起线程上下文的切换和调度。 作用1（保证共享变量的可见性） 将当前处理器缓存行的数据写会到系统内存中。 这个写会内存的操作会使其他CPU里缓存了该内存地址的数据无效。 对作用1的解释：为了提高处理速度，处理器不直接与内存进行通信，而是将内存中的数据读到内部的缓存里面再进行操作，而为了保持缓存的一致性，在多处理器模式下，就实现缓存一致性的协议，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是否已经过期，当处理器发现自己缓存行对应的内存地址被修改，将会将当前处理器的缓存行设置为无效状态，当处理器对这个数据进行修改操作的时候，就会重新从系统内存中把数据督导处理器缓存中。 volatile实现原则 Lock前缀指令会引起处理器缓存写回到内存中。 一个处理器的缓存回写到内存中会导致其他处理器的缓存无效。 特性 可见性：对一个Volatile变量的读，总是能够看到任意线程对这个volatile的最后写入。 原子性：对任意单个volatile的变量的读写具有原子性，但是类似于volatile++这种复合操作不具有原子性。 volatile写-读建立的happens-before关系 从内存语义的角度来说，volatile的写-读与锁的释放-获取有相同的内存效果。 synchronized 对于普通同步方法，锁是当前实例对象。 对于静态同步方法，锁是当前类的Class对象。 对于同步方法块，锁是synchronized括号里配置的对象。 原子操作原子操作意思就是不可被中断的一个或一系列的操作。 处理器保证原子操作的措施 总线锁：举个例子，当CPU获取到共享变量时，会发出LOCK#信号去组织其它处理器对这个变量的请求 缓存锁：","categories":[],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://wt-git-repository.github.io/tags/JAVA/"}]},{"title":"《JAVA并发编程的艺术》读书笔记①","slug":"《JAVA并发编程的艺术》读书笔记①","date":"2019-06-01T09:50:59.000Z","updated":"2019-07-08T01:15:52.720Z","comments":true,"path":"2019/06/01/《JAVA并发编程的艺术》读书笔记①/","link":"","permalink":"https://wt-git-repository.github.io/2019/06/01/《JAVA并发编程的艺术》读书笔记①/","excerpt":"","text":"上下文切换在单核处理器下，支持多线程执行代码，CPU给每一个线程分配CPU时间片来实现这个机制，由于分配的时间片比较短，一般为几十毫秒，所以CPU需要不停地切换线程，在切换之前会通过程序计数器去保存上一个线程的任务状态，以便在下一次执行这个任务时，可以再次加载这个任务的状态。 任务从保存到再加载的过程就是一次上下文切换。 问题：多线程一定快吗答：不一定，因为多线程有上下文切换的开销。 如何减少上下文切换答：减少上下文切换的方法有无锁并发编程、CAS算法、使用最小线程和使用协程。 无锁并发编程：多线程竞争锁时，会引起上下文切换，所以多线程处理数据时，可以使用一些方法来避免使用锁 CAS算法 使用最小线程：避免创建不需要的线程，避免造成大量线程处于等待状态 协程：在当线程里面实现多任务的调度，并在单线程里维持多个任务间的切换 如何避免死锁 避免在一个线程同时获取多个锁 避免一个线程在锁内同时占用多个资源，尽量保证每个锁只用一个资源 尝试使用定时锁，使用lock,tryLock(timeout)来替代使用内部锁机制 对于数据库锁，加锁和解锁都必须在同一个数据库连接里，否则会出现解锁失败的情况 资源限制的问题所谓资源限制，通常所指的是硬件的条件不能满足程序的需求，在这种情况下，多线程可能会延长执行时间，因为存在上下文切换的开销，这个时候，通常可以考虑集群并行执行程序。 在资源受限的情况下，需要根据具体的情况去决定程序的并发度，以达到最优状态。","categories":[],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://wt-git-repository.github.io/tags/JAVA/"}]},{"title":"进程、程序与线程","slug":"进程、程序与线程","date":"2019-05-31T02:42:14.000Z","updated":"2019-07-08T01:15:52.737Z","comments":true,"path":"2019/05/31/进程、程序与线程/","link":"","permalink":"https://wt-git-repository.github.io/2019/05/31/进程、程序与线程/","excerpt":"","text":"线程线程是一个比进程更小的执行单位，一个进程在其执行的过程中可以产生多个线程，在同一个进程内，各个线程共享着同一块内存空间和同一组系统资源，线程的上下文切换也要比进程要小 程序程序是含有指令和数据的文件，被存储在磁盘或者其它数据存储设备中，程序是静态的代码。 进程进程是系统运行程序的基本单位，是动态的，是程序的一次执行过程。系统运行一个程序是一个进程从创建、运行到消亡的过程。简单来说， 一个进程就相当于一个执行中的程序，它在计算机中一个指令接着另一个指令地执行着， 同时每个进程还会占有某些系统资源如CPU时间、内存空间、文件、输入输出设备等等， 换句话说，当程序在执行时，程序会被操作系统载入内存中，。 JAVA线程状态 Daemon线程Daemon线程是一种支持型线程，因为它主要被用作程序中后台调度以及支持工作，当一个JAVA虚拟机中不存在非Daemon线程的时候，JAVA虚拟机将会退出。 可以使用Thread.setDaemon(true)来设置Daemon线程。 Deamon线程被用作支持性工作，但是在JAVA虚拟机退出时，Daemo线程中的finally块不一定会执行。 对象、监视器、同步队列和执行线程之间的关系 线程间的通信等待/通知机制 有一些细节上的东西需要注意一下： 使用wait、notify、notifyAll时需要对调用对象加锁。 调用wait方法后，线程状态由RUNNING变成WAITING，并将当前线程放置在对象的等待队列中。 notify和notifyAll调用后，等到线程依旧不会从wait返回，而是要等本线程释放锁之后，等待线程才有机会返回 notify是将等待队列中的一个等待线程从等待队列中移到同步队列中 notifyAll是将等待队列中所有的线程全部移到同步队列中，被移动的线程状态由WAITING变为BLOKCED 从wait方法返回后重新执行的前提是获得对象的锁","categories":[],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://wt-git-repository.github.io/tags/JAVA/"}]},{"title":"hashCode和equals","slug":"hashCode和equals","date":"2019-05-31T02:13:46.000Z","updated":"2019-07-08T01:15:52.719Z","comments":true,"path":"2019/05/31/hashCode和equals/","link":"","permalink":"https://wt-git-repository.github.io/2019/05/31/hashCode和equals/","excerpt":"","text":"问题缘由：重写equals时必须要重写hashCode方法 简介hashCode()的作用是获取哈希码， 也称为散列码，它实际上就是一个int整数， 这个哈希码的作用是确定该对象在哈希表中的索引位置。hashCode定义在JDK的Object中， 这就意味者所有的类都含有hashCode方法 散列表存储的是键值对， 它的特点是， 能够根据键快速检索出对应的值， 其中就利用到了散列码。 哈希码的作用是获取对象在哈希表中的索引位置。 HashSet的插入机制HashSet不允许重复的插入， 在每一次插入时， 会根据hashCode来判断对象的插入位置， 同时会与已经存在的hashcode作比较， 如果没有相符的hashCode， 则没有重复的对象， 如果有重复的hashCode, 则会使用equals来判断值是否相等， 若相等则不插入， 若不相等则重新散列到其它位置， 这样可以大大减少equals的次数， 大大提高执行速度。 重写equals时必须要重写hashCode方法因为在使用equals之前，首先是使用hashcode去判断对象的索引位置， hashCode() 的默认行为是对堆上的对象产生独特值。如果没有重写 hashCode()，则该 class 的两个对象无论如何都不会相等（即使这两个对象指向相同的数据） demo123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475import java.util.*;import java.lang.Comparable;public class ConflictHashCodeTest2&#123; public static void main(String[] args) &#123; // 新建Person对象， Person p1 = new Person(\"eee\", 100); Person p2 = new Person(\"eee\", 100); Person p3 = new Person(\"aaa\", 200); Person p4 = new Person(\"EEE\", 100); // 新建HashSet对象 HashSet set = new HashSet(); set.add(p1); set.add(p2); set.add(p3); // 比较p1 和 p2， 并打印它们的hashCode() System.out.printf(\"p1.equals(p2) : %s; p1(%d) p2(%d)\\n\", p1.equals(p2), p1.hashCode(), p2.hashCode()); // 比较p1 和 p4， 并打印它们的hashCode() System.out.printf(\"p1.equals(p4) : %s; p1(%d) p4(%d)\\n\", p1.equals(p4), p1.hashCode(), p4.hashCode()); // 打印set System.out.printf(\"set:%s\\n\", set); &#125; /** * @desc Person类。 */ private static class Person &#123; int age; String name; public Person(String name, int age) &#123; this.name = name; this.age = age; &#125; public String toString() &#123; return name + \" - \" +age; &#125; /** * @desc重写hashCode */ @Override public int hashCode()&#123; int nameHash = name.toUpperCase().hashCode(); return nameHash ^ age; &#125; /** * @desc 覆盖equals方法 */ @Override public boolean equals(Object obj)&#123; if(obj == null)&#123; return false; &#125; //如果是同一个对象返回true，反之返回false if(this == obj)&#123; return true; &#125; //判断是否类型相同 if(this.getClass() != obj.getClass())&#123; return false; &#125; Person person = (Person)obj; return name.equals(person.name) &amp;&amp; age==person.age; &#125; &#125;&#125;","categories":[],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://wt-git-repository.github.io/tags/JAVA/"}]},{"title":"LinkedList源码学习","slug":"LinkedList源码学习","date":"2019-05-31T00:34:52.000Z","updated":"2019-07-08T01:15:52.681Z","comments":true,"path":"2019/05/31/LinkedList源码学习/","link":"","permalink":"https://wt-git-repository.github.io/2019/05/31/LinkedList源码学习/","excerpt":"简介LinkedList 是一个实现了List和Deque接口的双向链表， List接口都是一个常规的增删改查操作， 而Deque是的LinkedList具有队列的特性， LinkList不是线程安全的，如果先是的LinkedList变成线程安全的，可以使用1List list=Collections.synchronizedList(new LinkedList(...));","text":"简介LinkedList 是一个实现了List和Deque接口的双向链表， List接口都是一个常规的增删改查操作， 而Deque是的LinkedList具有队列的特性， LinkList不是线程安全的，如果先是的LinkedList变成线程安全的，可以使用1List list=Collections.synchronizedList(new LinkedList(...)); 源码分析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753754755756757758759760761762763764765766767768769770771772773774775776777778779780781782783784785786787788789790791792793794795796797798799800801802803804805806807808809810811812813814815816public class LinkedList&lt;E&gt; extends AbstractSequentialList&lt;E&gt; implements List&lt;E&gt;, Deque&lt;E&gt;, Cloneable, Serializable &#123; //一旦变量被transient修饰，变量将不再是对象持久化的一部分，该变量内容在序列化后无法获得访问。 //transient关键字只能修饰变量，而不能修饰方法和类。注意，本地变量是不能被transient关键字修饰的。变量如果是用户自定义类变量，则该类需要实现Serializable接口。 //被transient关键字修饰的变量不再能被序列化，一个静态变量不管是否被transient修饰，均不能被序列化 transient int size; transient LinkedList.Node&lt;E&gt; first; transient LinkedList.Node&lt;E&gt; last; private static final long serialVersionUID = 876323262645176354L; public LinkedList() &#123; this.size = 0; &#125; // 根据指定集合添加元素 public LinkedList(Collection&lt;? extends E&gt; var1) &#123; this(); this.addAll(var1); &#125; // 将元素插入到队列首部 private void linkFirst(E var1) &#123; LinkedList.Node var2 = this.first; LinkedList.Node var3 = new LinkedList.Node((LinkedList.Node)null, var1, var2); this.first = var3; if (var2 == null) &#123; this.last = var3; &#125; else &#123; var2.prev = var3; &#125; ++this.size; ++this.modCount; &#125; // 将元素插入到队列尾部 void linkLast(E var1) &#123; LinkedList.Node var2 = this.last; LinkedList.Node var3 = new LinkedList.Node(var2, var1, (LinkedList.Node)null); this.last = var3; if (var2 == null) &#123; this.first = var3; &#125; else &#123; var2.next = var3; &#125; ++this.size; ++this.modCount; &#125; // 将元素插入到指定位置之前 void linkBefore(E var1, LinkedList.Node&lt;E&gt; var2) &#123; LinkedList.Node var3 = var2.prev; LinkedList.Node var4 = new LinkedList.Node(var3, var1, var2); var2.prev = var4; if (var3 == null) &#123; this.first = var4; &#125; else &#123; var3.next = var4; &#125; ++this.size; ++this.modCount; &#125; private E unlinkFirst(LinkedList.Node&lt;E&gt; var1) &#123; Object var2 = var1.item; LinkedList.Node var3 = var1.next; var1.item = null; var1.next = null; this.first = var3; if (var3 == null) &#123; this.last = null; &#125; else &#123; var3.prev = null; &#125; --this.size; ++this.modCount; return var2; &#125; private E unlinkLast(LinkedList.Node&lt;E&gt; var1) &#123; Object var2 = var1.item; LinkedList.Node var3 = var1.prev; var1.item = null; var1.prev = null; this.last = var3; if (var3 == null) &#123; this.first = null; &#125; else &#123; var3.next = null; &#125; --this.size; ++this.modCount; return var2; &#125; E unlink(LinkedList.Node&lt;E&gt; var1) &#123; Object var2 = var1.item; LinkedList.Node var3 = var1.next; LinkedList.Node var4 = var1.prev; if (var4 == null) &#123; this.first = var3; &#125; else &#123; var4.next = var3; var1.prev = null; &#125; if (var3 == null) &#123; this.last = var4; &#125; else &#123; var3.prev = var4; var1.next = null; &#125; var1.item = null; --this.size; ++this.modCount; return var2; &#125; public E getFirst() &#123; LinkedList.Node var1 = this.first; if (var1 == null) &#123; throw new NoSuchElementException(); &#125; else &#123; return var1.item; &#125; &#125; public E getLast() &#123; LinkedList.Node var1 = this.last; if (var1 == null) &#123; throw new NoSuchElementException(); &#125; else &#123; return var1.item; &#125; &#125; public E removeFirst() &#123; LinkedList.Node var1 = this.first; if (var1 == null) &#123; throw new NoSuchElementException(); &#125; else &#123; return this.unlinkFirst(var1); &#125; &#125; public E removeLast() &#123; LinkedList.Node var1 = this.last; if (var1 == null) &#123; throw new NoSuchElementException(); &#125; else &#123; return this.unlinkLast(var1); &#125; &#125; public void addFirst(E var1) &#123; this.linkFirst(var1); &#125; public void addLast(E var1) &#123; this.linkLast(var1); &#125; public boolean contains(Object var1) &#123; return this.indexOf(var1) != -1; &#125; public int size() &#123; return this.size; &#125; public boolean add(E var1) &#123; this.linkLast(var1); return true; &#125; public boolean remove(Object var1) &#123; LinkedList.Node var2; if (var1 == null) &#123; for(var2 = this.first; var2 != null; var2 = var2.next) &#123; if (var2.item == null) &#123; this.unlink(var2); return true; &#125; &#125; &#125; else &#123; for(var2 = this.first; var2 != null; var2 = var2.next) &#123; if (var1.equals(var2.item)) &#123; this.unlink(var2); return true; &#125; &#125; &#125; return false; &#125; public boolean addAll(Collection&lt;? extends E&gt; var1) &#123; return this.addAll(this.size, var1); &#125; public boolean addAll(int var1, Collection&lt;? extends E&gt; var2) &#123; this.checkPositionIndex(var1); Object[] var3 = var2.toArray(); int var4 = var3.length; if (var4 == 0) &#123; return false; &#125; else &#123; LinkedList.Node var5; LinkedList.Node var6; if (var1 == this.size) &#123; var6 = null; var5 = this.last; &#125; else &#123; var6 = this.node(var1); var5 = var6.prev; &#125; Object[] var7 = var3; int var8 = var3.length; for(int var9 = 0; var9 &lt; var8; ++var9) &#123; Object var10 = var7[var9]; LinkedList.Node var12 = new LinkedList.Node(var5, var10, (LinkedList.Node)null); if (var5 == null) &#123; this.first = var12; &#125; else &#123; var5.next = var12; &#125; var5 = var12; &#125; if (var6 == null) &#123; this.last = var5; &#125; else &#123; var5.next = var6; var6.prev = var5; &#125; this.size += var4; ++this.modCount; return true; &#125; &#125; public void clear() &#123; LinkedList.Node var2; for(LinkedList.Node var1 = this.first; var1 != null; var1 = var2) &#123; var2 = var1.next; var1.item = null; var1.next = null; var1.prev = null; &#125; this.first = this.last = null; this.size = 0; ++this.modCount; &#125; public E get(int var1) &#123; this.checkElementIndex(var1); return this.node(var1).item; &#125; public E set(int var1, E var2) &#123; this.checkElementIndex(var1); LinkedList.Node var3 = this.node(var1); Object var4 = var3.item; var3.item = var2; return var4; &#125; public void add(int var1, E var2) &#123; this.checkPositionIndex(var1); if (var1 == this.size) &#123; this.linkLast(var2); &#125; else &#123; this.linkBefore(var2, this.node(var1)); &#125; &#125; public E remove(int var1) &#123; this.checkElementIndex(var1); return this.unlink(this.node(var1)); &#125; private boolean isElementIndex(int var1) &#123; return var1 &gt;= 0 &amp;&amp; var1 &lt; this.size; &#125; private boolean isPositionIndex(int var1) &#123; return var1 &gt;= 0 &amp;&amp; var1 &lt;= this.size; &#125; private String outOfBoundsMsg(int var1) &#123; return \"Index: \" + var1 + \", Size: \" + this.size; &#125; private void checkElementIndex(int var1) &#123; if (!this.isElementIndex(var1)) &#123; throw new IndexOutOfBoundsException(this.outOfBoundsMsg(var1)); &#125; &#125; private void checkPositionIndex(int var1) &#123; if (!this.isPositionIndex(var1)) &#123; throw new IndexOutOfBoundsException(this.outOfBoundsMsg(var1)); &#125; &#125; LinkedList.Node&lt;E&gt; node(int var1) &#123; LinkedList.Node var2; int var3; if (var1 &lt; this.size &gt;&gt; 1) &#123; var2 = this.first; for(var3 = 0; var3 &lt; var1; ++var3) &#123; var2 = var2.next; &#125; return var2; &#125; else &#123; var2 = this.last; for(var3 = this.size - 1; var3 &gt; var1; --var3) &#123; var2 = var2.prev; &#125; return var2; &#125; &#125; // 从头开始找 public int indexOf(Object var1) &#123; int var2 = 0; LinkedList.Node var3; if (var1 == null) &#123; for(var3 = this.first; var3 != null; var3 = var3.next) &#123; if (var3.item == null) &#123; return var2; &#125; ++var2; &#125; &#125; else &#123; for(var3 = this.first; var3 != null; var3 = var3.next) &#123; if (var1.equals(var3.item)) &#123; return var2; &#125; ++var2; &#125; &#125; return -1; &#125; // 从后面开始找 public int lastIndexOf(Object var1) &#123; int var2 = this.size; LinkedList.Node var3; if (var1 == null) &#123; for(var3 = this.last; var3 != null; var3 = var3.prev) &#123; --var2; if (var3.item == null) &#123; return var2; &#125; &#125; &#125; else &#123; for(var3 = this.last; var3 != null; var3 = var3.prev) &#123; --var2; if (var1.equals(var3.item)) &#123; return var2; &#125; &#125; &#125; return -1; &#125; // 返回头部，为空则返回null public E peek() &#123; LinkedList.Node var1 = this.first; return var1 == null ? null : var1.item; &#125; public E element() &#123; return this.getFirst(); &#125; public E poll() &#123; LinkedList.Node var1 = this.first; return var1 == null ? null : this.unlinkFirst(var1); &#125; public E remove() &#123; return this.removeFirst(); &#125; public boolean offer(E var1) &#123; return this.add(var1); &#125; public boolean offerFirst(E var1) &#123; this.addFirst(var1); return true; &#125; public boolean offerLast(E var1) &#123; this.addLast(var1); return true; &#125; public E peekFirst() &#123; LinkedList.Node var1 = this.first; return var1 == null ? null : var1.item; &#125; public E peekLast() &#123; LinkedList.Node var1 = this.last; return var1 == null ? null : var1.item; &#125; public E pollFirst() &#123; LinkedList.Node var1 = this.first; return var1 == null ? null : this.unlinkFirst(var1); &#125; public E pollLast() &#123; LinkedList.Node var1 = this.last; return var1 == null ? null : this.unlinkLast(var1); &#125; public void push(E var1) &#123; this.addFirst(var1); &#125; public E pop() &#123; return this.removeFirst(); &#125; public boolean removeFirstOccurrence(Object var1) &#123; return this.remove(var1); &#125; public boolean removeLastOccurrence(Object var1) &#123; LinkedList.Node var2; if (var1 == null) &#123; for(var2 = this.last; var2 != null; var2 = var2.prev) &#123; if (var2.item == null) &#123; this.unlink(var2); return true; &#125; &#125; &#125; else &#123; for(var2 = this.last; var2 != null; var2 = var2.prev) &#123; if (var1.equals(var2.item)) &#123; this.unlink(var2); return true; &#125; &#125; &#125; return false; &#125; public ListIterator&lt;E&gt; listIterator(int var1) &#123; this.checkPositionIndex(var1); return new LinkedList.ListItr(var1); &#125; public Iterator&lt;E&gt; descendingIterator() &#123; return new LinkedList.DescendingIterator(); &#125; private LinkedList&lt;E&gt; superClone() &#123; try &#123; return (LinkedList)super.clone(); &#125; catch (CloneNotSupportedException var2) &#123; throw new InternalError(var2); &#125; &#125; public Object clone() &#123; LinkedList var1 = this.superClone(); var1.first = var1.last = null; var1.size = 0; var1.modCount = 0; for(LinkedList.Node var2 = this.first; var2 != null; var2 = var2.next) &#123; var1.add(var2.item); &#125; return var1; &#125; public Object[] toArray() &#123; Object[] var1 = new Object[this.size]; int var2 = 0; for(LinkedList.Node var3 = this.first; var3 != null; var3 = var3.next) &#123; var1[var2++] = var3.item; &#125; return var1; &#125; public &lt;T&gt; T[] toArray(T[] var1) &#123; if (var1.length &lt; this.size) &#123; var1 = (Object[])((Object[])Array.newInstance(var1.getClass().getComponentType(), this.size)); &#125; int var2 = 0; Object[] var3 = var1; for(LinkedList.Node var4 = this.first; var4 != null; var4 = var4.next) &#123; var3[var2++] = var4.item; &#125; if (var1.length &gt; this.size) &#123; var1[this.size] = null; &#125; return var1; &#125; private void writeObject(ObjectOutputStream var1) throws IOException &#123; var1.defaultWriteObject(); var1.writeInt(this.size); for(LinkedList.Node var2 = this.first; var2 != null; var2 = var2.next) &#123; var1.writeObject(var2.item); &#125; &#125; private void readObject(ObjectInputStream var1) throws IOException, ClassNotFoundException &#123; var1.defaultReadObject(); int var2 = var1.readInt(); for(int var3 = 0; var3 &lt; var2; ++var3) &#123; this.linkLast(var1.readObject()); &#125; &#125; public Spliterator&lt;E&gt; spliterator() &#123; return new LinkedList.LLSpliterator(this, -1, 0); &#125; static final class LLSpliterator&lt;E&gt; implements Spliterator&lt;E&gt; &#123; static final int BATCH_UNIT = 1024; static final int MAX_BATCH = 33554432; final LinkedList&lt;E&gt; list; LinkedList.Node&lt;E&gt; current; int est; int expectedModCount; int batch; LLSpliterator(LinkedList&lt;E&gt; var1, int var2, int var3) &#123; this.list = var1; this.est = var2; this.expectedModCount = var3; &#125; final int getEst() &#123; int var1; if ((var1 = this.est) &lt; 0) &#123; LinkedList var2; if ((var2 = this.list) == null) &#123; var1 = this.est = 0; &#125; else &#123; this.expectedModCount = var2.modCount; this.current = var2.first; var1 = this.est = var2.size; &#125; &#125; return var1; &#125; public long estimateSize() &#123; return (long)this.getEst(); &#125; public Spliterator&lt;E&gt; trySplit() &#123; int var2 = this.getEst(); LinkedList.Node var1; if (var2 &gt; 1 &amp;&amp; (var1 = this.current) != null) &#123; int var3 = this.batch + 1024; if (var3 &gt; var2) &#123; var3 = var2; &#125; if (var3 &gt; 33554432) &#123; var3 = 33554432; &#125; Object[] var4 = new Object[var3]; int var5 = 0; do &#123; var4[var5++] = var1.item; &#125; while((var1 = var1.next) != null &amp;&amp; var5 &lt; var3); this.current = var1; this.batch = var5; this.est = var2 - var5; return Spliterators.spliterator(var4, 0, var5, 16); &#125; else &#123; return null; &#125; &#125; public void forEachRemaining(Consumer&lt;? super E&gt; var1) &#123; if (var1 == null) &#123; throw new NullPointerException(); &#125; else &#123; LinkedList.Node var2; int var3; if ((var3 = this.getEst()) &gt; 0 &amp;&amp; (var2 = this.current) != null) &#123; this.current = null; this.est = 0; do &#123; Object var4 = var2.item; var2 = var2.next; var1.accept(var4); if (var2 == null) &#123; break; &#125; --var3; &#125; while(var3 &gt; 0); &#125; if (this.list.modCount != this.expectedModCount) &#123; throw new ConcurrentModificationException(); &#125; &#125; &#125; public boolean tryAdvance(Consumer&lt;? super E&gt; var1) &#123; if (var1 == null) &#123; throw new NullPointerException(); &#125; else &#123; LinkedList.Node var2; if (this.getEst() &gt; 0 &amp;&amp; (var2 = this.current) != null) &#123; --this.est; Object var3 = var2.item; this.current = var2.next; var1.accept(var3); if (this.list.modCount != this.expectedModCount) &#123; throw new ConcurrentModificationException(); &#125; else &#123; return true; &#125; &#125; else &#123; return false; &#125; &#125; &#125; public int characteristics() &#123; return 16464; &#125; &#125; private class DescendingIterator implements Iterator&lt;E&gt; &#123; private final LinkedList&lt;E&gt;.ListItr itr; private DescendingIterator() &#123; this.itr = LinkedList.this.new ListItr(LinkedList.this.size()); &#125; public boolean hasNext() &#123; return this.itr.hasPrevious(); &#125; public E next() &#123; return this.itr.previous(); &#125; public void remove() &#123; this.itr.remove(); &#125; &#125; private static class Node&lt;E&gt; &#123; E item; LinkedList.Node&lt;E&gt; next; LinkedList.Node&lt;E&gt; prev; Node(LinkedList.Node&lt;E&gt; var1, E var2, LinkedList.Node&lt;E&gt; var3) &#123; this.item = var2; this.next = var3; this.prev = var1; &#125; &#125; private class ListItr implements ListIterator&lt;E&gt; &#123; private LinkedList.Node&lt;E&gt; lastReturned; private LinkedList.Node&lt;E&gt; next; private int nextIndex; private int expectedModCount; ListItr(int var2) &#123; this.expectedModCount = LinkedList.this.modCount; this.next = var2 == LinkedList.this.size ? null : LinkedList.this.node(var2); this.nextIndex = var2; &#125; public boolean hasNext() &#123; return this.nextIndex &lt; LinkedList.this.size; &#125; public E next() &#123; this.checkForComodification(); if (!this.hasNext()) &#123; throw new NoSuchElementException(); &#125; else &#123; this.lastReturned = this.next; this.next = this.next.next; ++this.nextIndex; return this.lastReturned.item; &#125; &#125; public boolean hasPrevious() &#123; return this.nextIndex &gt; 0; &#125; public E previous() &#123; this.checkForComodification(); if (!this.hasPrevious()) &#123; throw new NoSuchElementException(); &#125; else &#123; this.lastReturned = this.next = this.next == null ? LinkedList.this.last : this.next.prev; --this.nextIndex; return this.lastReturned.item; &#125; &#125; public int nextIndex() &#123; return this.nextIndex; &#125; public int previousIndex() &#123; return this.nextIndex - 1; &#125; public void remove() &#123; this.checkForComodification(); if (this.lastReturned == null) &#123; throw new IllegalStateException(); &#125; else &#123; LinkedList.Node var1 = this.lastReturned.next; LinkedList.this.unlink(this.lastReturned); if (this.next == this.lastReturned) &#123; this.next = var1; &#125; else &#123; --this.nextIndex; &#125; this.lastReturned = null; ++this.expectedModCount; &#125; &#125; public void set(E var1) &#123; if (this.lastReturned == null) &#123; throw new IllegalStateException(); &#125; else &#123; this.checkForComodification(); this.lastReturned.item = var1; &#125; &#125; public void add(E var1) &#123; this.checkForComodification(); this.lastReturned = null; if (this.next == null) &#123; LinkedList.this.linkLast(var1); &#125; else &#123; LinkedList.this.linkBefore(var1, this.next); &#125; ++this.nextIndex; ++this.expectedModCount; &#125; public void forEachRemaining(Consumer&lt;? super E&gt; var1) &#123; Objects.requireNonNull(var1); while(LinkedList.this.modCount == this.expectedModCount &amp;&amp; this.nextIndex &lt; LinkedList.this.size) &#123; var1.accept(this.next.item); this.lastReturned = this.next; this.next = this.next.next; ++this.nextIndex; &#125; this.checkForComodification(); &#125; final void checkForComodification() &#123; if (LinkedList.this.modCount != this.expectedModCount) &#123; throw new ConcurrentModificationException(); &#125; &#125; &#125;&#125; JavaGuide的demo123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121package list;import java.util.Iterator;import java.util.LinkedList;public class LinkedListDemo &#123; public static void main(String[] srgs) &#123; //创建存放int类型的linkedList LinkedList&lt;Integer&gt; linkedList = new LinkedList&lt;&gt;(); /************************** linkedList的基本操作 ************************/ linkedList.addFirst(0); // 添加元素到列表开头 linkedList.add(1); // 在列表结尾添加元素 linkedList.add(2, 2); // 在指定位置添加元素 linkedList.addLast(3); // 添加元素到列表结尾 System.out.println(\"LinkedList（直接输出的）: \" + linkedList); System.out.println(\"getFirst()获得第一个元素: \" + linkedList.getFirst()); // 返回此列表的第一个元素 System.out.println(\"getLast()获得第最后一个元素: \" + linkedList.getLast()); // 返回此列表的最后一个元素 System.out.println(\"removeFirst()删除第一个元素并返回: \" + linkedList.removeFirst()); // 移除并返回此列表的第一个元素 System.out.println(\"removeLast()删除最后一个元素并返回: \" + linkedList.removeLast()); // 移除并返回此列表的最后一个元素 System.out.println(\"After remove:\" + linkedList); System.out.println(\"contains()方法判断列表是否包含1这个元素:\" + linkedList.contains(1)); // 判断此列表包含指定元素，如果是，则返回true System.out.println(\"该linkedList的大小 : \" + linkedList.size()); // 返回此列表的元素个数 /************************** 位置访问操作 ************************/ System.out.println(\"-----------------------------------------\"); linkedList.set(1, 3); // 将此列表中指定位置的元素替换为指定的元素 System.out.println(\"After set(1, 3):\" + linkedList); System.out.println(\"get(1)获得指定位置（这里为1）的元素: \" + linkedList.get(1)); // 返回此列表中指定位置处的元素 /************************** Search操作 ************************/ System.out.println(\"-----------------------------------------\"); linkedList.add(3); System.out.println(\"indexOf(3): \" + linkedList.indexOf(3)); // 返回此列表中首次出现的指定元素的索引 System.out.println(\"lastIndexOf(3): \" + linkedList.lastIndexOf(3));// 返回此列表中最后出现的指定元素的索引 /************************** Queue操作 ************************/ System.out.println(\"-----------------------------------------\"); System.out.println(\"peek(): \" + linkedList.peek()); // 获取但不移除此列表的头 System.out.println(\"element(): \" + linkedList.element()); // 获取但不移除此列表的头 linkedList.poll(); // 获取并移除此列表的头 System.out.println(\"After poll():\" + linkedList); linkedList.remove(); System.out.println(\"After remove():\" + linkedList); // 获取并移除此列表的头 linkedList.offer(4); System.out.println(\"After offer(4):\" + linkedList); // 将指定元素添加到此列表的末尾 /************************** Deque操作 ************************/ System.out.println(\"-----------------------------------------\"); linkedList.offerFirst(2); // 在此列表的开头插入指定的元素 System.out.println(\"After offerFirst(2):\" + linkedList); linkedList.offerLast(5); // 在此列表末尾插入指定的元素 System.out.println(\"After offerLast(5):\" + linkedList); System.out.println(\"peekFirst(): \" + linkedList.peekFirst()); // 获取但不移除此列表的第一个元素 System.out.println(\"peekLast(): \" + linkedList.peekLast()); // 获取但不移除此列表的第一个元素 linkedList.pollFirst(); // 获取并移除此列表的第一个元素 System.out.println(\"After pollFirst():\" + linkedList); linkedList.pollLast(); // 获取并移除此列表的最后一个元素 System.out.println(\"After pollLast():\" + linkedList); linkedList.push(2); // 将元素推入此列表所表示的堆栈（插入到列表的头） System.out.println(\"After push(2):\" + linkedList); linkedList.pop(); // 从此列表所表示的堆栈处弹出一个元素（获取并移除列表第一个元素） System.out.println(\"After pop():\" + linkedList); linkedList.add(3); linkedList.removeFirstOccurrence(3); // 从此列表中移除第一次出现的指定元素（从头部到尾部遍历列表） System.out.println(\"After removeFirstOccurrence(3):\" + linkedList); linkedList.removeLastOccurrence(3); // 从此列表中移除最后一次出现的指定元素（从尾部到头部遍历列表） System.out.println(\"After removeFirstOccurrence(3):\" + linkedList); /************************** 遍历操作 ************************/ System.out.println(\"-----------------------------------------\"); linkedList.clear(); for (int i = 0; i &lt; 100000; i++) &#123; linkedList.add(i); &#125; // 迭代器遍历 long start = System.currentTimeMillis(); Iterator&lt;Integer&gt; iterator = linkedList.iterator(); while (iterator.hasNext()) &#123; iterator.next(); &#125; long end = System.currentTimeMillis(); System.out.println(\"Iterator：\" + (end - start) + \" ms\"); // 顺序遍历(随机遍历) start = System.currentTimeMillis(); for (int i = 0; i &lt; linkedList.size(); i++) &#123; linkedList.get(i); &#125; end = System.currentTimeMillis(); System.out.println(\"for：\" + (end - start) + \" ms\"); // 另一种for循环遍历 start = System.currentTimeMillis(); for (Integer i : linkedList) ; end = System.currentTimeMillis(); System.out.println(\"for2：\" + (end - start) + \" ms\"); // 通过pollFirst()或pollLast()来遍历LinkedList LinkedList&lt;Integer&gt; temp1 = new LinkedList&lt;&gt;(); temp1.addAll(linkedList); start = System.currentTimeMillis(); while (temp1.size() != 0) &#123; temp1.pollFirst(); &#125; end = System.currentTimeMillis(); System.out.println(\"pollFirst()或pollLast()：\" + (end - start) + \" ms\"); // 通过removeFirst()或removeLast()来遍历LinkedList LinkedList&lt;Integer&gt; temp2 = new LinkedList&lt;&gt;(); temp2.addAll(linkedList); start = System.currentTimeMillis(); while (temp2.size() != 0) &#123; temp2.removeFirst(); &#125; end = System.currentTimeMillis(); System.out.println(\"removeFirst()或removeLast()：\" + (end - start) + \" ms\"); &#125;&#125;","categories":[],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://wt-git-repository.github.io/tags/JAVA/"}]},{"title":"String、StringBuilder和StringBuffer","slug":"String、StringBuilder和StringBuffer","date":"2019-05-30T11:13:33.000Z","updated":"2019-07-08T01:15:52.696Z","comments":true,"path":"2019/05/30/String、StringBuilder和StringBuffer/","link":"","permalink":"https://wt-git-repository.github.io/2019/05/30/String、StringBuilder和StringBuffer/","excerpt":"","text":"String12345678910111213141516171819public final class String implements Serializable, Comparable&lt;String&gt;, CharSequence &#123; private final char[] value; private int hash; private static final long serialVersionUID = -6849794470754667710L; private static final ObjectStreamField[] serialPersistentFields = new ObjectStreamField[0]; public static final Comparator&lt;String&gt; CASE_INSENSITIVE_ORDER = new String.CaseInsensitiveComparator(); public String() &#123; this.value = \"\".value; &#125; public String(String var1) &#123; this.value = var1.value; this.hash = var1.hash; &#125; public String(char[] var1) &#123; this.value = Arrays.copyOf(var1, var1.length); &#125; 从String 的源码中，我们不难发现， String存储的字符串， 对象是final类型的， 不可变， 线程安全。 StringBuffer and StringBuilderStringBuffer和StringBuilder都继承了AbstractStringBuilder并且使用的基本都是父类的方法，区别在于前程是线程安全的，后者是线程不安全的，前者比后者快。1234567891011abstract class AbstractStringBuilder implements Appendable, CharSequence &#123; char[] value; int count; private static final int MAX_ARRAY_SIZE = 2147483639; AbstractStringBuilder() &#123; &#125; AbstractStringBuilder(int var1) &#123; this.value = new char[var1]; &#125; 性能每次对 String 类型进行改变的时候，都会生成一个新的 String 对象，然后将指针指向新的 String 对象。StringBuffer 每次都会对 StringBuffer 对象本身进行操作，而不是生成新的对象并改变对象引用。相同情况下使用 StringBuilder 相比使用 StringBuffer 仅能获得 10%~15% 左右的性能提升，但却要冒多线程不安全的风险。 总结 操作少量的数据: 适用String 单线程操作字符串缓冲区下操作大量数据: 适用StringBuilder 多线程操作字符串缓冲区下操作大量数据: 适用StringBuffer","categories":[],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://wt-git-repository.github.io/tags/JAVA/"}]},{"title":"利用Python进行数据分析－Pandas入门","slug":"利用Python进行数据分析－Pandas入门","date":"2019-05-30T04:59:56.000Z","updated":"2019-07-08T01:15:52.729Z","comments":true,"path":"2019/05/30/利用Python进行数据分析－Pandas入门/","link":"","permalink":"https://wt-git-repository.github.io/2019/05/30/利用Python进行数据分析－Pandas入门/","excerpt":"本文出自&lt;利用Python进行数据分析 第二版&gt; 侵删 PandasPandas是一个非常巨大的库，采用了大量Numpy的编程风格，基于Numpy构建，含有使数据清洗和数据分析工作变得更加简单的工具． Pandas的数据结构Pandas两个主要的数据结构：Series和DataFrame","text":"本文出自&lt;利用Python进行数据分析 第二版&gt; 侵删 PandasPandas是一个非常巨大的库，采用了大量Numpy的编程风格，基于Numpy构建，含有使数据清洗和数据分析工作变得更加简单的工具． Pandas的数据结构Pandas两个主要的数据结构：Series和DataFrame SeriesSeries是由一组数据以及一组索引组成，其数据类型包括各种NumPy数据类型．可用Series()函数来定义12345678In [62]: obj = pd.Series([1,2,3])In [63]: objOut[63]:0 11 22 3dtype: int64 在没有指定索引形式的情况下，Pandas自动为数据指定了(０－Ｎ-1)的索引结构，我们可用通过index和values属性来查看相关的信息12345In [64]: obj.valuesOut[64]: array([1, 2, 3])In [65]: obj.indexOut[65]: RangeIndex(start=0, stop=3, step=1) 除此之外，我们在创建Series的时候，还可以指定索引的形式，这一次和有序字典相似，所以，其实我们可以直接将一个字典使用Series函数转换成Series，同时我们还可以通过索引来访问其中的value,此处和NumPy的数据匹配方面是十分相似1234567891011121314In [67]: obj2 = pd.Series([90,80,60],index = [&apos;a&apos;,&apos;b&apos;,&apos;c&apos;])In [68]: obj2Out[68]:a 90b 80c 60dtype: int64In [70]: obj2.index #此时访问index属性便会显示具体的索引值Out[70]: Index([&apos;a&apos;, &apos;b&apos;, &apos;c&apos;], dtype=&apos;object&apos;)In [69]: obj2[&apos;a&apos;]Out[69]: 90 与NumPy相比，Series有一个杰出的优点，Series可以通过索引来取一组数值，还可以借此来检索是否存在对应的数据，若有，则返回实际的value，若无，则返回NAN备注：Pandas的isnull和notnull函数可用于检测缺失数据，返回boolean值1234567891011In [74]: obj2[[&apos;c&apos;,&apos;a&apos;]]Out[74]:c 60a 90dtype: int64In [77]: obj2[[&apos;c&apos;,&apos;g&apos;]]Out[77]:c 60.0g NaNdtype: float64 同时，Series还可以使用NumPy的函数或者NumPy所拥有的一些运算123456789101112131415161718In [73]: obj2[obj2&gt;80]Out[73]:a 90dtype: int64In [75]: obj2*2Out[75]:a 180b 160c 120dtype: int64In [76]: np.exp(obj2)Out[76]:a 1.220403e+39b 5.540622e+34c 1.142007e+26dtype: float64 对于绝大多数的功能而言,Series最重要的一个跟你是,根据运算的索引标签来自动对齐数据 123456789101112131415161718192021222324In [35]: obj3Out[35]:Ohio 35000Oregon 16000Texas 71000Utah 5000dtype: int64In [36]: obj4Out[36]:California NaNOhio 35000.0Oregon 16000.0Texas 71000.0dtype: float64In [37]: obj3 + obj4Out[37]:California NaNOhio 70000.0Oregon 32000.0Texas 142000.0Utah NaNdtype: float64 Series对象本身及其索引都有一个name属性,该属性跟pandas其它的关键功能关系非常密切123456789101112In [38]: obj4.name = &apos;population&apos;In [39]: obj4.index.name = &apos;state&apos;In [40]: obj4Out[40]:stateCalifornia NaNOhio 35000.0Oregon 16000.0Texas 71000.0Name: population, dtype: float64 Series的索引可以通过赋值的方式就地修改：1234567891011121314151617In [41]: objOut[41]:0 41 72 -53 3dtype: int64In [42]: obj.index = [&apos;Bob&apos;, &apos;Steve&apos;, &apos;Jeff&apos;, &apos;Ryan&apos;]In [43]: objOut[43]:Bob 4Steve 7Jeff -5Ryan 3dtype: int64 DataFrameDataFrame是一个表格型的数据结构,以二维结构保存数组.构建DataFrame最常用的方法是闯入一个等长列表或者NumPy数组构成的字典,构建出来的DataFrame会被自动加上索引备注:head函数可以使得DataFrame只显示前五行,同时我们还可以像在Series一样,给DataFrame指定索引值12345678910In [84]: data = &#123;&apos;a&apos;:[1,2,3],&apos;b&apos;:[4,5,6],&apos;c&apos;:[7,8,9]&#125;In [85]: frame = pd.DataFrame(data)In [86]: frameOut[86]: a b c0 1 4 71 2 5 82 3 6 9 下面我们再来看一个典型的例子我们在构建的时候可以指定列序列,可以和数据源对不上,顺序以传入数据为准,但是,传入的index的长度必须要和数据源的列长度相等.1234567891011In [90]: frame2 = pd.DataFrame(data,columns=[&apos;a&apos;,&apos;c&apos;,&apos;d&apos;],index = [&apos;one&apos;,&apos;two&apos;,&apos;three&apos;])In [91]: frame2Out[91]: a c done 1 7 NaNtwo 2 8 NaNthree 3 9 NaNIn [92]: frame2.columnsOut[92]: Index([&apos;a&apos;, &apos;c&apos;, &apos;d&apos;], dtype=&apos;object&apos;) 可以通过列名来得到一个Series,有两种方法12345678910111213In [93]: frame2[&apos;a&apos;] #第一种Out[93]:one 1two 2three 3Name: a, dtype: int64In [95]: frame2.a #第二种Out[95]:one 1two 2three 3Name: a, dtype: int64 同理,可以通过行名来得到一个Series123456In [99]: frame2.loc[&apos;one&apos;]Out[99]:a 1c 7d NaNName: one, dtype: object","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"https://wt-git-repository.github.io/tags/Python/"}]},{"title":"利用Python进行数据分析－NumPy基础","slug":"利用Python进行数据分析－NumPy基础","date":"2019-05-30T04:59:21.000Z","updated":"2019-07-08T01:15:52.728Z","comments":true,"path":"2019/05/30/利用Python进行数据分析－NumPy基础/","link":"","permalink":"https://wt-git-repository.github.io/2019/05/30/利用Python进行数据分析－NumPy基础/","excerpt":"本文出自＜利用Python进行数据分析 第２版＞ 侵删 NumPyNumPy 是Python数值计算最重要的基础包，可以高效处理大数组的数据． NumPy的ndarray：一种多维的数组对象ndarray是一个快速而又灵活的同构数据多维容器，是一个Ｎ维数组对象，其中所有的元素对象必须要是相同的数据类型，每一个对象包含一个元组和一个属性，分别是shape（一个表示各维度大小的元组）和dtype（一个说明数组数据类型的对象）","text":"本文出自＜利用Python进行数据分析 第２版＞ 侵删 NumPyNumPy 是Python数值计算最重要的基础包，可以高效处理大数组的数据． NumPy的ndarray：一种多维的数组对象ndarray是一个快速而又灵活的同构数据多维容器，是一个Ｎ维数组对象，其中所有的元素对象必须要是相同的数据类型，每一个对象包含一个元组和一个属性，分别是shape（一个表示各维度大小的元组）和dtype（一个说明数组数据类型的对象） 创建ndarray创建ndarray最简单的方法是使用array函数，它接受一切序列型的对象（包括其它数组），然后产生一个新的含有传入数据的NumPy数组123456In [1]: list1 = (1,2,3)In [3]: import numpy as npIn [5]: data = np.array(list1)In [6]: dataOut[6]: array([1, 2, 3]) 嵌套序列会被转换成一个多维的数组，array函数会为新建的数组推断出一个较为合适的数据类型，数据类型保存在一个特殊的dtype对象中1234567891011121314In [7]: list2 = [[1,2,3],[4,5,6]]In [8]: data2 = np.array(list2)In [9]: data2Out[9]:array([[1, 2, 3], [4, 5, 6]])In [10]: data2.shape #查看维度大小Out[10]: (2, 3)In [11]: data2.dtype #查看元素类型Out[11]: dtype(&apos;int64&apos;) 常用函数zeros：创建指定长度或者形状全为０的数组ones：创建指定长度或者形状全为１的数组empty：可以创建一个没有任何具体值的数组使用这些方法创建数组，只需要传入一个可以表示形状的元组便可1234567891011121314151617181920212223In [12]: np.zeros((10))Out[12]: array([ 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])In [13]: np.ones((2,3))Out[13]:array([[ 1., 1., 1.], [ 1., 1., 1.]])In [14]: np.empty((2,3,4))Out[14]:array([[[ 6.94667955e-310, 4.65986064e-310, 6.94667972e-310, 6.94667971e-310], [ 6.94667972e-310, 6.94667971e-310, 6.94667852e-310, 6.94667972e-310], [ 6.94667852e-310, 6.94667852e-310, 3.55727265e-321, 5.53353523e-322]], [[ 0.00000000e+000, 6.94667867e-310, 6.94666603e-310, 6.94666605e-310], [ 6.94666603e-310, 6.94667969e-310, 6.94666603e-310, 6.94667725e-310], [ 6.94667974e-310, 6.94666603e-310, 6.94667974e-310, 6.94667971e-310]]]) arange是Python内置函数range的数组版12In [15]: np.arange(10)Out[15]: array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) 备注：数据类型基本都是float64(浮点数) 创建时可以指定类型1234567In [21]: data2 = np.array([1,2,3],dtype=np.float64)In [22]: data2Out[22]: array([ 1., 2., 3.])In [23]: data2.dtypeOut[23]: dtype(&apos;float64&apos;) 创建后可以修改类型，astype函数12345In [24]: data2.astype(int)Out[24]: array([1, 2, 3])In [25]: data2.dtype #注意，astype只会返回转换后的类型，但并不会实际地去转换元素类型 Out[25]: dtype(&apos;float64&apos;) #NumPy 数组的运算数组不需要通过循环便可执行批量运算12345678910111213141516171819202122232425In [51]: arr = np.array([[1., 2., 3.], [4., 5., 6.]])In [52]: arrOut[52]:array([[ 1., 2., 3.], [ 4., 5., 6.]])In [53]: arr * arr #乘Out[53]:array([[ 1., 4., 9.], [ 16., 25., 36.]])In [54]: arr - arr #减Out[54]:array([[ 0., 0., 0.], [ 0., 0., 0.]])In [55]: 1 / arr #除Out[55]:array([[ 1. , 0.5 , 0.3333], [ 0.25 , 0.2 , 0.1667]])In [56]: arr ** 0.5 #指数Out[56]:array([[ 1. , 1.4142, 1.7321], [ 2. , 2.2361, 2.4495]]) 大小相同的数组可以产生布尔值数组大小不同的数组之间的运算叫做广播1234567891011In [57]: arr2 = np.array([[0., 4., 1.], [7., 2., 12.]])In [58]: arr2Out[58]:array([[ 0., 4., 1.], [ 7., 2., 12.]])In [59]: arr2 &gt; arrOut[59]:array([[False, True, False], [ True, False, True]], dtype=bool) 切片和索引NumPy产生的切片是视图，而并非是新的对象，当将一个标量值传给一个切片时，如arr[5:8]=12时，该值会自动传播到整个选区，这意味这在视图上，任意数据的修改都会影响到源数组1234567891011121314In [32]: data2 = np.array([1,2,3])In [33]: data3 = data2[1:2]In [34]: data3Out[34]: array([2])In [35]: data3[0] = 12 #通过索引去赋值，也可以通过索引去访问In [36]: data3Out[36]: array([12])In [37]: data2Out[37]: array([ 1, 12, 3]) 切片［：］会给所有值赋值，例如arr[:] = 13NumPy对数据的处理不包括复制粘贴的优势将体现在处理大规模的数据中 ，如果我们需要的是一份副本而不是一个视图的话，我们可以使用arr[5:8].copy()索引的返回值可为元素也可为数组123456789101112131415161718In [39]: arrOut[39]:array([[[ 1, 2, 3], [ 4, 5, 6]], [[ 7, 8, 9], [10, 11, 12]]])In [40]: arr[1]Out[40]:array([[ 7, 8, 9], [10, 11, 12]])In [41]: arr[1,1] #访问索引以（１，１）开头的那些值Out[41]: array([10, 11, 12])In [45]: arr[:1,1:,2:3] #切片的用法基本一致Out[45]: array([[[6]]]) 布尔型索引常用于数据的匹配123456789In [46]: names = np.array([&apos;wt&apos;,&apos;Bob&apos;])In [47]: scores = np.array([90,80])In [48]: names == &apos;wt&apos;Out[48]: array([ True, False], dtype=bool)In [49]: scores[names == &apos;wt&apos;]Out[49]: array([90]) 注意：布尔型数组的长度需要匹配对应数组的最高维度，在匹配的同事，我们还可以索引列，例如scores[name == ‘wt’,2:]，还可以通过这样来赋值，例如：scores[names == ‘wt’] = 0备注：～操作符可以用来反转条件，例如cond = names == ‘wt’，~cond就等同于names != ‘wt’还有一点值得注意的是：Python关键字and和or在布尔型数组中无效，要使用＆和｜． 花式索引数组装置转置是重塑的一种特殊形式，它返回的是源数据的视图，不会进行任何的复制操作，转置使用数组的Ｔ属性高维数组的装置需要使用transpose123456789101112131415array([[ 0., 0., 0., 0.], [ 0., 0., 0., 0.], [ 0., 0., 0., 0.], [ 0., 0., 0., 0.], [ 0., 0., 0., 0.], [ 0., 0., 0., 0.], [ 0., 0., 0., 0.], [ 0., 0., 0., 0.]])In [11]: arr.TOut[11]:array([[ 0., 0., 0., 0., 0., 0., 0., 0.], [ 0., 0., 0., 0., 0., 0., 0., 0.], [ 0., 0., 0., 0., 0., 0., 0., 0.], [ 0., 0., 0., 0., 0., 0., 0., 0.]]) 计算矩阵内积使用np.dot(arr1, arr2)来计算两个矩阵的内积 通用函数：快速的元素级数组函数通用函数是一种对ndarray中的数据执行元素级运算的函数1234In [15]: arr1 = np.array([2,2])In [16]: np.sqrt(arr1)Out[16]: array([ 1.41421356, 1.41421356]) 将条件逻辑表述为数组运算假设我们想根据cond中的值来选取xarr和yarr的值12345678910In [29]: xarr = np.array([1.1,1.2,1.3,1.4,1.5])In [30]: yarr = np.array([2.1,2.2,2.3,2.4,2.5])In [31]: cond = np.array([True,False,True,True,False])In [32]: result = [(x if c else y) for x,y,c in zip(xarr,yarr,cond)]In [33]: resultOut[33]: [1.1000000000000001, 2.2000000000000002, 1.3, 1.3999999999999999, 2.5] 等同于1234In [34]: result = np.where(cond,xarr,yarr)In [35]: resultOut[35]: array([ 1.1, 2.2, 1.3, 1.4, 2.5]) np.where的第二个和第三个不必是数组，它们都可以是标量值．在数据分析的工作中，where的工作通常是根据一个数组产生另一个数组．假设一个由随机数组组成的矩阵，大于零的数都变成３，小于０的数都变成－３，若此时用利用where，则会变得非常方便12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364In [36]: arr = np.random.randn(6,6)In [37]: arrOut[37]:array([[-1.45536948, -0.01610929, -0.02849423, -0.82497092, 1.05006367, -0.20924655], [-0.4434815 , -0.33147041, -0.61486327, -0.5423556 , 1.512384 , -1.35921009], [-0.53875138, -0.25256538, 0.32190533, -0.20779243, 0.48525456, 0.97019284], [ 0.12193935, -0.26348046, 0.86740783, -0.32927907, 0.35186663, 2.24697225], [-0.49439342, 0.38880278, 0.52902035, 0.86600846, 1.31413569, 0.58566283], [ 0.34011322, 0.96141724, -1.00353822, -0.30896308, -1.03500063, -0.43719574]])In [38]: arr&gt;0Out[38]:array([[False, False, False, False, True, False], [False, False, False, False, True, False], [False, False, True, False, True, True], [ True, False, True, False, True, True], [False, True, True, True, True, True], [ True, True, False, False, False, False]], dtype=bool)In [39]: np.where(arr&gt;0,3,-3)Out[39]:array([[-3, -3, -3, -3, 3, -3], [-3, -3, -3, -3, 3, -3], [-3, -3, 3, -3, 3, 3], [ 3, -3, 3, -3, 3, 3], [-3, 3, 3, 3, 3, 3], [ 3, 3, -3, -3, -3, -3]])In [40]: np.where(arr&gt;0,3,arr) #把大于０的数赋值为３，其余赋值arrOut[40]:array([[-1.45536948, -0.01610929, -0.02849423, -0.82497092, 3. , -0.20924655], [-0.4434815 , -0.33147041, -0.61486327, -0.5423556 , 3. , -1.35921009], [-0.53875138, -0.25256538, 3. , -0.20779243, 3. , 3. ], [ 3. , -0.26348046, 3. , -0.32927907, 3. , 3. ], [-0.49439342, 3. , 3. , 3. , 3. , 3. ], [ 3. , 3. , -1.00353822, -0.30896308, -1.03500063, -0.43719574]])In [41]: np.where(arr&gt;0,arr,3) #把大于０的赋值为arr,其余赋值为３Out[41]:array([[ 3. , 3. , 3. , 3. , 1.05006367, 3. ], [ 3. , 3. , 3. , 3. , 1.512384 , 3. ], [ 3. , 3. , 0.32190533, 3. , 0.48525456, 0.97019284], [ 0.12193935, 3. , 0.86740783, 3. , 0.35186663, 2.24697225], [ 3. , 0.38880278, 0.52902035, 0.86600846, 1.31413569, 0.58566283], [ 0.34011322, 0.96141724, 3. , 3. , 3. , 3. ]]) 数学和统计方法 用于布尔型数组的方法1234In [47]: arr = np.array([-1,2,-3])In [48]: (arr &gt; 0).sum() #计算元素大于０的个数Out[48]: 1 另外还有两个方法any和all，它们对布尔型数组非常有用。any用于测试数组中是否存在一个或多个True，而all则检查数组中所有值是否都是True：1234567In [192]: bools = np.array([False, False, True, False])In [193]: bools.any()Out[193]: TrueIn [194]: bools.all()Out[194]: False 这两个方法也能用于非布尔型数组，所有非0元素将会被当做True。 排序123456789In [195]: arr = np.random.randn(6)In [196]: arrOut[196]: array([ 0.6095, -0.4938, 1.24 , -0.1357, 1.43 , -0.8469])In [197]: arr.sort()In [198]: arrOut[198]: array([-0.8469, -0.4938, -0.1357, 0.6095, 1.24 , 1.43 ]) 唯一化以及其它集合逻辑NumPy提供了一些针对ndarray的基本集合运算，最常用的是np.unique123456In [56]: arr = np.array([&apos;wt&apos;,&apos;jm&apos;,&apos;wt&apos;]) In [57]: np.unique(arr) #找到唯一值，并返回Out[57]:array([&apos;jm&apos;, &apos;wt&apos;], dtype=&apos;&lt;U2&apos;) 线性代数NumPy提供了一个用于矩阵乘法的dot函数（既是一个数组方法也是numpy命名空间中的一个函数） 伪随机数的生成numpy.random模块对Python内置的random进行了补充，增添一些可以高效生成多种概率发布的样本值的方法","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"https://wt-git-repository.github.io/tags/Python/"}]},{"title":"利用Python进行数据分析－数据结构准备（元组、列表、字典、集合、函数、推导式、柯里化、生成器、itertools模块以及文件读写）","slug":"利用Python进行数据分析－数据结构准备（元组、列表、字典、集合、函数、推导式、柯里化、生成器、itertools模块以及文件读写）","date":"2019-05-30T04:58:45.000Z","updated":"2019-07-08T01:15:52.730Z","comments":true,"path":"2019/05/30/利用Python进行数据分析－数据结构准备（元组、列表、字典、集合、函数、推导式、柯里化、生成器、itertools模块以及文件读写）/","link":"","permalink":"https://wt-git-repository.github.io/2019/05/30/利用Python进行数据分析－数据结构准备（元组、列表、字典、集合、函数、推导式、柯里化、生成器、itertools模块以及文件读写）/","excerpt":"本文引用《利用Python进行数据分析·第2版》 元组tuple元组是一个固定长度而且不可以改变的序列对象 定义元组的方法:(1) 最简单的方法:12345In [23]: top = 1,2,3In [24]: topOut[24]: (1, 2, 3)","text":"本文引用《利用Python进行数据分析·第2版》 元组tuple元组是一个固定长度而且不可以改变的序列对象 定义元组的方法:(1) 最简单的方法:12345In [23]: top = 1,2,3In [24]: topOut[24]: (1, 2, 3) (2) 复杂元组的定义:123456In [25]: top = (1,2,3),(4,5)In [26]: topOut[26]: ((1, 2, 3), (4, 5)) 常用方法:tuple : 将任意序列或者迭代器转换成元组12345678In [27]: tuple([1,2,3])Out[27]: (1, 2, 3)In [28]: tuple(&quot;wt&quot;)Out[28]: (&apos;w&apos;, &apos;t&apos;) count：统计频率12345In [50]: a = 1,2,2,3In [51]: a.count(2)Out[51]: 2 访问 : 可以直接通过下标来访问123In [29]: top[0]Out[29]: (1, 2, 3) 修改:元组的对象一旦定义便不可以修改，除非其中存储的对象是可变对象，例如：1234567In [30]: top = 1, [1,2,3],&apos;a&apos;In [31]: top[1].append(&apos;wt&apos;)In [32]: topOut[32]: (1, [1, 2, 3, &apos;wt&apos;], &apos;a&apos;) 备注: [1,2,3] 为列表，有序的集合，可以随时添加和删除其中的元素 串联： 可以使用加法运算符把元组串联起来1234567891011In [32]: topOut[32]: (1, [1, 2, 3, &apos;wt&apos;], &apos;a&apos;)In [33]: top + (4,5,6) ＃第一种情况Out[33]: (1, [1, 2, 3, &apos;wt&apos;], &apos;a&apos;, 4, 5, 6)In [45]: top * 2 ＃第二种情况Out[45]: (1, [1, 2, 3, &apos;wt&apos;], &apos;a&apos;, 1, [1, 2, 3, &apos;wt&apos;], &apos;a&apos;) 拆分：拆分有两种情况，一种是等量拆分，另一种是不等量拆分等量拆分：1234567In [34]: top = 1,2,3In [35]: a,b,c = topIn [36]: aOut[36]: 1 不等量拆分，ｐ可以分配不等长度的列表12345In [42]: a,*p = topIn [43]: pOut[43]: [2, 3] 变量拆分常用来迭代元组或者列表序列12345678910111213In [46]: seq = (1,2,3),(4,5,6)In [49]: for a,b,c in seq: ...: print(&quot;a = &#123;0&#125;, b = &#123;1&#125;, c = &#123;2&#125;&quot;.format(a,b,c)) ...: a = 1, b = 2, c = 3a = 4, b = 5, c = 6* * * 列表list与元组相比，列表的长度和内容都是可变的 定义的方法：１．直接定义12345In [52]: a_list = [1,2,3,&apos;wt&apos;]In [53]: a_listOut[53]: [1, 2, 3, &apos;wt&apos;] ２．使用list函数，list函数在数据处理中常用来实体化迭代器和生成器12345In [58]: b_list = range(2,10)In [59]: list(b_list)Out[59]: [2, 3, 4, 5, 6, 7, 8, 9] 添加和删除元素：１．使用append在列表末尾添加元素12345In [60]: a_list.append(&apos;wt&apos;)In [61]: a_listOut[61]: [1, 2, 3, &apos;wt&apos;, &apos;wt&apos;] ２．使用insert在指定位置上添加元素1234567In [63]: b_list = list(b_list)In [64]: b_list.insert(1,&apos;wt&apos;)In [65]: b_listOut[65]: [2, &apos;wt&apos;, 3, 4, 5, 6, 7, 8, 9] ３．使用pop去除指定的元素1234567In [66]: b_list.pop(2)Out[66]: 3In [67]: b_listOut[67]: [2, &apos;wt&apos;, 4, 5, 6, 7, 8, 9] ４．使用remove去除某个匹配值，优先去除找到的第一个1234567In [69]: b_list = [&apos;wt&apos;,1,2,&apos;wt&apos;]In [70]: b_list.remove(&apos;wt&apos;)In [71]: b_listOut[71]: [1, 2, &apos;wt&apos;] 常用方法：１．使用in去检查列表里面是否含有某个值（not ni）123In [72]: &apos;wt&apos; in b_listOut[72]: True 2.串联和组合列表(1) 使用 + 号将两个列表串联起来123In [73]: [1,2,3] + [4,5,6]Out[73]: [1, 2, 3, 4, 5, 6] (2) 使用extend方法追加多个元素（添加的新对象为列表类型，与append不同的是，append添加的是单个元素）12345In [76]: b_list.extend([&apos;wt&apos;,&apos;wt&apos;])In [77]: b_listOut[77]: [1, 2, &apos;wt&apos;, &apos;wt&apos;, &apos;wt&apos;] 区别：使用 + 号串联对象的开销比较大，因为要新建一个列表，如果对象是一个大列表的时候，使用extend追加元素会比较可取 ３．使用sort()函数进行原地排序（不创建新的对象）1234567In [80]: a = [3,2,1]In [81]: a.sort()In [82]: aOut[82]: [1, 2, 3] ４．切片 切片的赋值：（注意要与Numpy的特点区分开来，Numpy切片下产生的是视图，而不是新的对象）123456789101112131415161718192021222324252627In [83]: a = [1,2,3,4,5,6,7,8,9]In [85]: a[2:3] = [&apos;wt&apos;,&apos;wt&apos;]In [86]: aOut[86]: [1, 2, &apos;wt&apos;, &apos;wt&apos;, 4, 5, 6, 7, 8, 9]In [87]: b = a[2:3] ＃产生一个新的对象In [88]: b = [1,1] ＃赋值In [89]: bOut[89]: [1, 1]In [90]: aOut[90]: [1, 2, &apos;wt&apos;, &apos;wt&apos;, 4, 5, 6, 7, 8, 9] ＃a的切片区域，数值没有被改变，说明产生的并非视图In [91]: a[::2] ＃隔两个数取一个值，顺序Out[91]: [1, &apos;wt&apos;, 4, 6, 8]In [92]: a[::-1] ＃隔一个数取一个值，倒叙Out[92]: [9, 8, 7, 6, 5, 4, &apos;wt&apos;, &apos;wt&apos;, 2, 1] 序列函数：enumerate函数，可以返回（i,value）元组序列1234567891011In [93]: for i,value in enumerate(a): ＃测试用例 ...: print(i,value) ...: 0 11 22 wt sorted函数从任意序列中返回一个已经拍好序的列表（列表的元素需要为同一类型）：123In [96]: sorted([&quot;dscdcsd fsdf&quot;]) #空格为分割符Out[96]: [&apos;dscdcsd fsdf&apos;] zip函数可以将多个列别，元组或者其它序列组合成一个新的列表12345678910111213141516171819202122232425262728293031323334353637In [98]: seq1 = [1,2,3]In [99]: seq2 = [&apos;wt&apos;,&apos;wt&apos;]In [100]: seq3 = zip(seq1,seq2)In [101]: seq3 #注意，如需展示列表，需要收到转换list()Out[101]:报错信息In [102]: list(seq3)Out[102]: [(1, &apos;wt&apos;), (2, &apos;wt&apos;)]In [104]: list(zip(seq1,seq2,seq4)) #zip可以合并任意长度的列别，元素的个数取决于最短的序列Out[104]: [(1, &apos;wt&apos;, 4), (2, &apos;wt&apos;, 5)]In [107]: for i,j in zip(*(zip(seq1,seq2,seq4))): ＃zip还可以用来解压，注意需要在被解压对象之前添加一个＊号 ...: print(i,j) ...: 1 2wt wt4 5#### reversed函数可以对一个列表进行倒叙处理In [109]: list(reversed([1,2,3]))Out[109]: [3, 2, 1]* * * 字典dict字典是Python重要的数据结构，被我们称之为哈希映射或者关联数组，键和值都是python对象, 其中，值可变但键不可变 创建方法：常用的创建方法是使用｛｝尖括号：12345In [110]: dict = &#123;&quot;wt&quot;:10,&quot;wt2&quot;:20&#125;In [111]: dictOut[111]: &#123;&apos;wt&apos;: 10, &apos;wt2&apos;: 20&#125; 访问、插入和设定：访问、插入和设定的方式可以像数组一样123456789In [2]: dict[&apos;wt3&apos;] = 30 #通过访问键的方式去插入In [3]: dictOut[3]: &#123;&apos;wt&apos;: 10, &apos;wt2&apos;: 20, &apos;wt3&apos;: 30&#125;In [5]: dict[&apos;wt2&apos;] #通过键去访问值valueOut[5]: 20 删除值（同时也会删除键），使用del或者pop方法1234567891011121314151617181920212223In [7]: dictOut[7]: &#123;&apos;wt&apos;: 10, &apos;wt2&apos;: 20, &apos;wt3&apos;: 30&#125;In [8]: del dict[&apos;wt3&apos;] #使用del方法去删除键为‘wt3’的值In [9]: dictOut[9]: &#123;&apos;wt&apos;: 10, &apos;wt2&apos;: 20&#125;In [9]: dictOut[9]: &#123;&apos;wt&apos;: 10, &apos;wt2&apos;: 20&#125;In [10]: value = dict.pop(&apos;wt2&apos;) #使用pop方法去删除键为‘wt2’的值，并把删除的值赋值给valueIn [11]: valueOut[11]: 20In [12]: dictOut[12]: &#123;&apos;wt&apos;: 10&#125; 常用方法：通过 in 去检查字典中是否含有指定的键123In [6]: &apos;wt2&apos; in dictOut[6]: True 访问字典中所有的keys123In [13]: dict.keys()Out[13]: dict_keys([&apos;wt&apos;]) 访问字典中所有的values123In [14]: dict.values()Out[14]: dict_values([10]) 使用update融合字典12345In [16]: dict.update(&#123;&quot;wt2&quot;:20,&quot;wt3&quot;:30&#125;) #使用update合并字典In [17]: dictOut[17]: &#123;&apos;wt&apos;: 10, &apos;wt2&apos;: 20, &apos;wt3&apos;: 30&#125; 将两个序列组合成字典123456789101112131415161718192021In [18]: key_list = [1,2,3]In [19]: value_list = [4,5,6]In [20]: mapping = &#123;&#125;#组合的第一种方法In [21]: for key,value in zip(key_list,value_list): ...: mapping[key] = value ...: In [22]: mappingOut[22]: &#123;1: 4, 2: 5, 3: 6&#125;#组合的第二种方法In [23]: list = list(zip(key_list,value_list))In [24]: listOut[24]: [(1, 4), (2, 5), (3, 6)] #此为二元列表，可以使用dict方法来转换成字典In [31]: mapping2 = dict(list）In [32]: mapping2Out[32]: &#123;1: 4, 2: 5, 3: 6&#125; 默认值dict的方法get和pop可以取默认值，并返回123456#此种代码逻辑十分常见In [33]: if key in some_dict: ...: value = some_dict[key] ...: else: ...: value = default_value ...: 常用的方法还有collections, defaultdict, setdefault 集合set集合是无序而又没有重复元素的集合，可以看作只有键而没有值的字典 定义方法:直接使用{}尖括号1234In [34]: mySet = &#123;1,2,3&#125;In [35]: mySetOut[35]: &#123;1, 2, 3&#125; 使用方法set1234In [36]: mySet = set([4,5,6])In [37]: mySetOut[37]: &#123;4, 5, 6&#125; 常用方法：合并，取两个集合不重复的元素，然后组合成一个新的集合，可以用union方法或者 | 运算符123456789In [38]: set1 = &#123;1,2,3&#125;In [39]: set2 = &#123;2,3,4&#125;In [40]: set1.union(set2) #第一种方法，使用unionOut[40]: &#123;1, 2, 3, 4&#125;In [41]: set1 | set2 #第二种方法，使用 | 运算符Out[41]: &#123;1, 2, 3, 4&#125; 交集，取两个集合中重复的集合，然后组合成一个新的集合，可以用intersection 或者 &amp; 运算符12345In [42]: set1.intersection(set2) #第一种方法，使用intersectionOut[42]: &#123;2, 3&#125;In [43]: set1 &amp; set2 # 第二种方法，使用 &amp; 运算符Out[43]: &#123;2, 3&#125; 所有逻辑集合操作都有另外的原地实现方法，可以直接用结果替代集合的内容。对于大的集合，这么做效率更高。 列表，集合，字典推导式列表推导式：1[expr for val in collection if condition] 集合推导式1set_comp = &#123;expr for value in collection if condition&#125; 字典推导式1dict_comp = &#123;key-expr : value-expr for value in collection if condition&#125; 函数函数的应用十分广泛，其中，值得注意的是，函数的返回值的形式可以多种多样，例如，返回字典12345def f(): a = 5 b = 6 c = 7 return &#123;&apos;a&apos;:a,&apos;b&apos;:b,&apos;c&apos;:c&#125; 有时候，我们需要对同一个字符串做一系列的函数操作，此时，最简单的方法是，我们把所有的方法封装成一个列表，然后再遍历执行（多函数模式）123456789101112def remove_punctuation(value): return re.sub(&apos;[!#?]&apos;, &apos;&apos;, value)clean_ops = [str.strip, remove_punctuation, str.title] #一系列的函数名def clean_strings(strings, ops): result = [] for value in strings: for function in ops: #遍历调用列表中的函数 value = function(value) result.append(value) return result 等同于12345678def clean_strings(strings): result = [] for value in strings: value = value.strip() value = re.sub(&apos;[!#?]&apos;, &apos;&apos;, value) value = value.title() result.append(value) return result 我们还可以将函数作为另一个函数的参数，例如内置的map函数，它的作用是在一组数据上应用一个函数：123456789101112In [10]: def change(value): return str(str(value) + &quot;wt&quot;) ....:In [7]: list = [1,2,3]In [11]: for i in map(change,list): #将list的元素经过change()处理之后，再赋值给 i print(i) ....: 1wt2wt3wt 同时，我们还可以使用lambda匿名函数，这种用法要比完整的函数声明和定义要简洁得多123456In [3]: def double(list,f): return [f(x) for x in list] ...:In [4]: print(double(my_list,lambda x:x*2))[2, 4, 6] 柯里化，部分参数的应用柯里化是一个计算机科学术语，它的意思就是部分参数应用，由现有的函数组合成一个新的函数12345678In [5]: def add(x,y): ...: return x+y ...:In [6]: add_one = lambda x: add(x,1) #派生出一个新函数In [7]: print(add_one(2))3 等同于12345In [9]: from functools import partialIn [12]: add_one = partial(add,y=1)In [13]: print(add_one(2))3 生成器表达式1In [189]: gen = (x ** 2 for x in range(100)) itertools模块 读写文件读写文件一般使用with语句，不仅方便读取数据，而且在退出代码块之后会自动清理文件12345In [212]: with open(path , &quot;r&quot;) as f: #读文件 .....: lines = [x.rstrip() for x in f]In [225]: with open(&apos;path&apos;.txt&apos;, &apos;w&apos;) as handle: #写文件 .....: handle.writelines(x for x in open(path) if len(x) &gt; 1)","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"https://wt-git-repository.github.io/tags/Python/"}]},{"title":"SpringCloud微服务架构实战读书笔记①","slug":"SpringCloud微服务架构实战读书笔记①","date":"2019-05-29T07:27:56.000Z","updated":"2019-07-08T01:15:52.693Z","comments":true,"path":"2019/05/29/SpringCloud微服务架构实战读书笔记①/","link":"","permalink":"https://wt-git-repository.github.io/2019/05/29/SpringCloud微服务架构实战读书笔记①/","excerpt":"微服务架构概述微服务设计原则 单一设计原则： 单一职责原则指的是一个单元（类、方法或者是服务）关注的应该只是整个系统中单独且有界限的一部分。 服务自治原则： 服务自治指的是每个微服务都应具备独立的业务能力、依赖与运行环境， 服务与服务之间需要高度解耦， 每个服务从开发、测试、构建到部署都应该可以独立的运行， 而不需要依赖其它服务。 轻量级通信机制： 微服务之间应该通过轻量级的通信机制进行交互。 微服务粒度： 根据合理的粒度划分微服务， 而并非越小越好。","text":"微服务架构概述微服务设计原则 单一设计原则： 单一职责原则指的是一个单元（类、方法或者是服务）关注的应该只是整个系统中单独且有界限的一部分。 服务自治原则： 服务自治指的是每个微服务都应具备独立的业务能力、依赖与运行环境， 服务与服务之间需要高度解耦， 每个服务从开发、测试、构建到部署都应该可以独立的运行， 而不需要依赖其它服务。 轻量级通信机制： 微服务之间应该通过轻量级的通信机制进行交互。 微服务粒度： 根据合理的粒度划分微服务， 而并非越小越好。 Spring Cloud 实战服务提供者与服务消费者服务提供者定义： 服务的被调用方， 即为其它服务提供服务的服务 服务消费者定义： 服务的消费方， 即依赖其它服务的服务 Spring Boot Actuator提供了一些监控的端点 硬编码的问题硬编码指的是把网络地址嵌套在代码中， 如1@GetMapping(\"/user/&#123;id&#125;\") 在不使用注册中心的前提下， 最好将路径提取出来， 放在配置文件中，使用分布式配置中心统一去管理。 服务注册与发现 各个微服务在启动时，将自己的网络地址等信息注册到服务发现组件中，服务发现组件会存储这些信息。 服务消费者可以从服务发现组件查询服务提供者的网络地址，并使用该地址调用服务提供者的接口。 各个微服务与服务发现组件使用一定机制（如心跳）进行通信。服务发现组件若长时间服务与某服务实例通信，就会注销该实例。 微服务网络地址发生变更， 会重新注册到服务发现组件。 综上所述， 服务发现组件应该具备如下功能： 服务注册表： 服务发现组件的核心，它用来记录各个微服务的信息，例如微服务的名称、IP、端口等等，该表提供查询API和管理API， 查询API用于查询可用的微服务实例， 管理API用于管理服务的注册与注销。 服务注册与服务发现： 服务注册是指在微服务启动时，将自己的信息注册到服务发现组件上的过程。服务发现是指查询可用微服务列表及网络地址的机制。 服务检查： 服务发现组件使用一定机制定时检测已注册的服务。 EurekaRegion and Avaliability Zone Eureka 工作原理 MakeRemoteCall 是RESTFul API的调用行为 us-east-1c、us-east-1d等都是Avaliability Zone, 他们都属于us-east-1这个region Eureka 包含两个组件：一个是Eureka server， 另一个是Eureka client， 在Eureka集群的情况下， Eureka Server也是Eureka Client， 多个Eureka Server之间通过相互复制的方式来实现服务注册表中的数据同步。 几个比较重要的配置： eureka.client.registerWithEureka：表示是否将自己注册到EurekaServer eureka.client.fetchRegistry：表示是否从Eureka Server获取注册信息，默认为true。 eureka.client.serviceUrl.defaultZone：设置与EurekaServer交互的地址，查询服务和注册服务都需要依赖这个地址。默认是http://localhost:8761/eureka；多个地址间可使用,分隔。 将微服务注册到Eureka Server中几个比较重要的配置 Spring.application.name: 用于注册到Eureka Server上的应用名称 eureka.instance.prefer-ip-address=true 表示将自己的IP注册到Eureka Server中， 若为false， 一般会将操作系统的hostname注册到Eureka Server中。 为Eureka Server添加安全认证的支持， 可以使用Spring Security 将eureka.client.serviceUrl.defaultZone配置为http://user:password@EUREKA_HOST:EUREKA_PORT/eureka/的形式, 即可成功注册。 Eureka 元数据Eureka 的元数据包括两种，分别是标准元数据和自定义元数据。 标准元数据指的是主机名、IP地址、端口号、状态页和健康检查等信息，这些信息都会被发布在服务注册表中，用于服务之间的调用。 自定义元数据， 可以使用eureka.instance.metadata-map配置，这些元数据可以被远程客户端访问， 通过提前的约定使得远程客户端知道该如何使用 Eureka Server的REST端点 Eureka 的自我保护模式 默认情况下， Eureka Server心跳检测的默认限度是90s, 超过之后没有收到回复将会注销该服务 但在极端情况下， 如网络故障， 则会出现短时间内大规模注销的情况， 这时Eureka server将会启动自我保护模式， 在该模式下， 不会注销任何服务， 当网络恢复时， Eureka server会自动退出自我保护模式。 eureka.server.enable-self-preservation=false禁用自我保护模式 多网卡环境下的IP选择建议直接使用eureka.instance.ipAddress手动指定IP地址， 特别是在Docker容器中 Eureka 健康检查我们上面所说的心跳之类的，都只是Eureka与服务之间的通信是否正常，而通信正常不代表服务正常， 如服务不能与数据库进行连接， 此时便需要更加细化的检查了。 使用Ribbon实现客户端负载均衡在Spring Cloud中，当Ribbon与Eureka配合使用时，Ribbon可自动从Eureka Server获取服务提供者的地址列表，并基于负载均衡算法，请求其中一个服务提供者的实例。为RestTemplate添加@LoadBalanced注解 12345@Bean@LoadBalancedpublic RestTemplate restTemplate() &#123; return new RestTemplate();&#125; 相关注意事项： 不能将restTemplate.getForObject与loadBalancedClient.choose写在同一个方法中，因为前者已经有选择的意思，前者包括后者，restTemplate实际上已经是Ribbon客户端本身，已经包含Choose行为 虚拟主机名不能包括 _ 字符 Ribbon配置自定义(翻下官方文档自己配)脱离Eureka使用Ribbon有一些遗留的微服务，它们没有注册到Eureka Server上， 这个时候， 仍然可以使用Ribbon实现负载均衡 配置：microservice-provider-user.ribbon.listOfServers 饥饿加载Spring cloud 为每个名称的Ribbon Client维护一个子应用上下文，这个上下文默认的懒加载的，指定名称的Ribbon Client第一次请求的时候，对应的上下文才会被加载，因此第一次加载时，会比较慢，此时，我们可以配置懒加载这样，对于名为client1、client2的Ribbon Client，将在启动时加载对应的子应用程序上下文。","categories":[],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://wt-git-repository.github.io/tags/JAVA/"}]},{"title":"ArrayList源码学习","slug":"ArrayList源码学习","date":"2019-05-29T01:40:06.000Z","updated":"2019-07-08T01:15:52.669Z","comments":true,"path":"2019/05/29/ArrayList源码学习/","link":"","permalink":"https://wt-git-repository.github.io/2019/05/29/ArrayList源码学习/","excerpt":"ArrayList简介1public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, Serializable ArrayList 底层是数组队列， 属于动态数组， 可以根据实际的需要去动态地调整数组的大小 ArrayList 继承了AbstractList类，说明它提供了增删改查等功能 ArrayList 实现了RandomAccess接口， 说明实现这个接口的List集合是支持随机访问的 ArrayList 实现了Cloneable接口， 说明它是可克隆的 ArrayList 实现了Serialiable接口， 说明它是可以被序列化的","text":"ArrayList简介1public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, Serializable ArrayList 底层是数组队列， 属于动态数组， 可以根据实际的需要去动态地调整数组的大小 ArrayList 继承了AbstractList类，说明它提供了增删改查等功能 ArrayList 实现了RandomAccess接口， 说明实现这个接口的List集合是支持随机访问的 ArrayList 实现了Cloneable接口， 说明它是可克隆的 ArrayList 实现了Serialiable接口， 说明它是可以被序列化的 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989910010110210310410510610710810911011111211311411511611711811912012112212312412512612712812913013113213313413513613713813914014114214314414514614714814915015115215315415515615715815916016116216316416516616716816917017117217317417517617717817918018118218318418518618718818919019119219319419519619719819920020120220320420520620720820921021121221321421521621721821922022122222322422522622722822923023123223323423523623723823924024124224324424524624724824925025125225325425525625725825926026126226326426526626726826927027127227327427527627727827928028128228328428528628728828929029129229329429529629729829930030130230330430530630730830931031131231331431531631731831932032132232332432532632732832933033133233333433533633733833934034134234334434534634734834935035135235335435535635735835936036136236336436536636736836937037137237337437537637737837938038138238338438538638738838939039139239339439539639739839940040140240340440540640740840941041141241341441541641741841942042142242342442542642742842943043143243343443543643743843944044144244344444544644744844945045145245345445545645745845946046146246346446546646746846947047147247347447547647747847948048148248348448548648748848949049149249349449549649749849950050150250350450550650750850951051151251351451551651751851952052152252352452552652752852953053153253353453553653753853954054154254354454554654754854955055155255355455555655755855956056156256356456556656756856957057157257357457557657757857958058158258358458558658758858959059159259359459559659759859960060160260360460560660760860961061161261361461561661761861962062162262362462562662762862963063163263363463563663763863964064164264364464564664764864965065165265365465565665765865966066166266366466566666766866967067167267367467567667767867968068168268368468568668768868969069169269369469569669769869970070170270370470570670770870971071171271371471571671771871972072172272372472572672772872973073173273373473573673773873974074174274374474574674774874975075175275375475575675775875976076176276376476576676776876977077177277377477577677777877978078178278378478578678778878979079179279379479579679779879980080180280380480580680780880981081181281381481581681781881982082182282382482582682782882983083183283383483583683783883984084184284384484584684784884985085185285385485585685785885986086186286386486586686786886987087187287387487587687787887988088188288388488588688788888989089189289389489589689789889990090190290390490590690790890991091191291391491591691791891992092192292392492592692792892993093193293393493593693793893994094194294394494594694794894995095195295395495595695795895996096196296396496596696796896997097197297397497597697797897998098198298398498598698798898999099199299399499599699799899910001001100210031004100510061007100810091010101110121013101410151016101710181019102010211022102310241025102610271028102910301031103210331034103510361037103810391040104110421043104410451046104710481049105010511052105310541055105610571058105910601061106210631064106510661067106810691070107110721073107410751076107710781079108010811082108310841085108610871088108910901091109210931094109510961097109810991100110111021103110411051106110711081109public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, Serializable &#123; private static final long serialVersionUID = 8683452581122892189L; /** * 默认初始化大小， 为10 */ private static final int DEFAULT_CAPACITY = 10; /** * empty_element_data 默认空数组，对应下面var1==0时的构造方法 */ private static final Object[] EMPTY_ELEMENTDATA = new Object[0]; /** * */ private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = new Object[0]; /** * 保存ArrayList数据的数组 */ transient Object[] elementData; /** * 数组所包含的数据的个数，值得注意的是，此处并不是指数组的大小 */ private int size; /** * 数组容量的最大值 */ private static final int MAX_ARRAY_SIZE = 2147483639; /** * 带参构造函数，自定义容量 */ public ArrayList(int var1) &#123; if (var1 &gt; 0) &#123; this.elementData = new Object[var1]; &#125; else &#123; if (var1 != 0) &#123; throw new IllegalArgumentException(\"Illegal Capacity: \" + var1); &#125; this.elementData = EMPTY_ELEMENTDATA; &#125; &#125; /** * 默认空数组，， */ public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; &#125; /** * 构造一个包含指定集合的数组 */ public ArrayList(Collection&lt;? extends E&gt; var1) &#123; this.elementData = var1.toArray(); if ((this.size = this.elementData.length) != 0) &#123; // 判断是否为Objectp[]类型 if (this.elementData.getClass() != Object[].class) &#123; this.elementData = Arrays.copyOf(this.elementData, this.size, Object[].class); &#125; &#125; else &#123; this.elementData = EMPTY_ELEMENTDATA; &#125; &#125; /** * 修改当前数组的大小，调整为与当前的数据大小保持一致 */ public void trimToSize() &#123; ++this.modCount; if (this.size &lt; this.elementData.length) &#123; this.elementData = this.size == 0 ? EMPTY_ELEMENTDATA : Arrays.copyOf(this.elementData, this.size); &#125; &#125; /** * ArrayList的扩容机制， 算法为int var3 = var2 + (var2 &gt;&gt; 1);每次扩容约为原来的1.5倍 */ public void ensureCapacity(int var1) &#123; int var2 = this.elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA ? 0 : 10; if (var1 &gt; var2) &#123; this.ensureExplicitCapacity(var1); &#125; &#125; /** * 计算最小容量 */ private static int calculateCapacity(Object[] var0, int var1) &#123; return var0 == DEFAULTCAPACITY_EMPTY_ELEMENTDATA ? Math.max(10, var1) : var1; &#125; /** * 判断是否需要扩容 */ private void ensureCapacityInternal(int var1) &#123; this.ensureExplicitCapacity(calculateCapacity(this.elementData, var1)); &#125; private void ensureExplicitCapacity(int var1) &#123; ++this.modCount; if (var1 - this.elementData.length &gt; 0) &#123; this.grow(var1); &#125; &#125; /** * 扩容的核心算法 */ private void grow(int var1) &#123; int var2 = this.elementData.length; int var3 = var2 + (var2 &gt;&gt; 1); if (var3 - var1 &lt; 0) &#123; var3 = var1; &#125; if (var3 - 2147483639 &gt; 0) &#123; var3 = hugeCapacity(var1); &#125; this.elementData = Arrays.copyOf(this.elementData, var3); &#125; private static int hugeCapacity(int var0) &#123; if (var0 &lt; 0) &#123; throw new OutOfMemoryError(); &#125; else &#123; return var0 &gt; 2147483639 ? 2147483647 : 2147483639; &#125; &#125; public int size() &#123; return this.size; &#125; public boolean isEmpty() &#123; return this.size == 0; &#125; public boolean contains(Object var1) &#123; return this.indexOf(var1) &gt;= 0; &#125; /** * 这里分了两张情况，空或非空 */ public int indexOf(Object var1) &#123; int var2; if (var1 == null) &#123; for(var2 = 0; var2 &lt; this.size; ++var2) &#123; if (this.elementData[var2] == null) &#123; return var2; &#125; &#125; &#125; else &#123; for(var2 = 0; var2 &lt; this.size; ++var2) &#123; if (var1.equals(this.elementData[var2])) &#123; return var2; &#125; &#125; &#125; return -1; &#125; public int lastIndexOf(Object var1) &#123; int var2; if (var1 == null) &#123; for(var2 = this.size - 1; var2 &gt;= 0; --var2) &#123; if (this.elementData[var2] == null) &#123; return var2; &#125; &#125; &#125; else &#123; for(var2 = this.size - 1; var2 &gt;= 0; --var2) &#123; if (var1.equals(this.elementData[var2])) &#123; return var2; &#125; &#125; &#125; return -1; &#125; /** * 浅拷贝？？？ */ public Object clone() &#123; try &#123; ArrayList var1 = (ArrayList)super.clone(); //Arrays.copyOf功能是实现数组的复制，返回复制后的数组。参数是被复制的数组和复制的长度 var1.elementData = Arrays.copyOf(this.elementData, this.size); var1.modCount = 0; return var1; &#125; catch (CloneNotSupportedException var2) &#123; throw new InternalError(var2); &#125; &#125; /** * 此处返回的数组是安全的，因为ArrayList不会保留对它的引用 */ public Object[] toArray() &#123; return Arrays.copyOf(this.elementData, this.size); &#125; public &lt;T&gt; T[] toArray(T[] var1) &#123; if (var1.length &lt; this.size) &#123; return (Object[])Arrays.copyOf(this.elementData, this.size, var1.getClass()); &#125; else &#123; //调用System提供的arraycopy()方法实现数组之间的复制 // var1是目的数组 System.arraycopy(this.elementData, 0, var1, 0, this.size); if (var1.length &gt; this.size) &#123; var1[this.size] = null; &#125; return var1; &#125; &#125; E elementData(int var1) &#123; return this.elementData[var1]; &#125; public E get(int var1) &#123; this.rangeCheck(var1); return this.elementData(var1); &#125; public E set(int var1, E var2) &#123; this.rangeCheck(var1); Object var3 = this.elementData(var1); this.elementData[var1] = var2; return var3; &#125; public boolean add(E var1) &#123; this.ensureCapacityInternal(this.size + 1); this.elementData[this.size++] = var1; return true; &#125; public void add(int var1, E var2) &#123; this.rangeCheckForAdd(var1); this.ensureCapacityInternal(this.size + 1); System.arraycopy(this.elementData, var1, this.elementData, var1 + 1, this.size - var1); this.elementData[var1] = var2; ++this.size; &#125; /** * 通过数组间的复制， 使用System.arraycopy去删除指定索引的元素 */ public E remove(int var1) &#123; this.rangeCheck(var1); ++this.modCount; Object var2 = this.elementData(var1); int var3 = this.size - var1 - 1; if (var3 &gt; 0) &#123; System.arraycopy(this.elementData, var1 + 1, this.elementData, var1, var3); &#125; this.elementData[--this.size] = null; return var2; &#125; public boolean remove(Object var1) &#123; int var2; if (var1 == null) &#123; for(var2 = 0; var2 &lt; this.size; ++var2) &#123; if (this.elementData[var2] == null) &#123; this.fastRemove(var2); return true; &#125; &#125; &#125; else &#123; for(var2 = 0; var2 &lt; this.size; ++var2) &#123; if (var1.equals(this.elementData[var2])) &#123; this.fastRemove(var2); return true; &#125; &#125; &#125; return false; &#125; /* * Private remove method that skips bounds checking and does not * return the value removed. */ private void fastRemove(int var1) &#123; ++this.modCount; int var2 = this.size - var1 - 1; if (var2 &gt; 0) &#123; System.arraycopy(this.elementData, var1 + 1, this.elementData, var1, var2); &#125; this.elementData[--this.size] = null; &#125; /* * 删除所有元素 */ public void clear() &#123; ++this.modCount; for(int var1 = 0; var1 &lt; this.size; ++var1) &#123; this.elementData[var1] = null; &#125; this.size = 0; &#125; /** * 按指定集合的Iterator返回的顺序将指定集合中的所有元素追加到此列表的末尾。 */ public boolean addAll(Collection&lt;? extends E&gt; var1) &#123; Object[] var2 = var1.toArray(); int var3 = var2.length; this.ensureCapacityInternal(this.size + var3); System.arraycopy(var2, 0, this.elementData, this.size, var3); this.size += var3; return var3 != 0; &#125; /** * 将指定集合中的所有元素插入到此列表中，从指定的位置开始。 */ public boolean addAll(int var1, Collection&lt;? extends E&gt; var2) &#123; this.rangeCheckForAdd(var1); Object[] var3 = var2.toArray(); int var4 = var3.length; this.ensureCapacityInternal(this.size + var4); int var5 = this.size - var1; if (var5 &gt; 0) &#123; System.arraycopy(this.elementData, var1, this.elementData, var1 + var4, var5); &#125; System.arraycopy(var3, 0, this.elementData, var1, var4); this.size += var4; return var4 != 0; &#125; protected void removeRange(int var1, int var2) &#123; ++this.modCount; int var3 = this.size - var2; System.arraycopy(this.elementData, var2, this.elementData, var1, var3); int var4 = this.size - (var2 - var1); for(int var5 = var4; var5 &lt; this.size; ++var5) &#123; this.elementData[var5] = null; &#125; this.size = var4; &#125; /* * 检查索引是否越界 */ private void rangeCheck(int var1) &#123; if (var1 &gt;= this.size) &#123; throw new IndexOutOfBoundsException(this.outOfBoundsMsg(var1)); &#125; &#125; private void rangeCheckForAdd(int var1) &#123; if (var1 &gt; this.size || var1 &lt; 0) &#123; throw new IndexOutOfBoundsException(this.outOfBoundsMsg(var1)); &#125; &#125; /** * 返回越界的具体信息 */ private String outOfBoundsMsg(int var1) &#123; return \"Index: \" + var1 + \", Size: \" + this.size; &#125; /** * 删除集合内指定元素 */ public boolean removeAll(Collection&lt;?&gt; var1) &#123; Objects.requireNonNull(var1); return this.batchRemove(var1, false); &#125; public boolean retainAll(Collection&lt;?&gt; var1) &#123; Objects.requireNonNull(var1); return this.batchRemove(var1, true); &#125; private boolean batchRemove(Collection&lt;?&gt; var1, boolean var2) &#123; Object[] var3 = this.elementData; int var4 = 0; int var5 = 0; boolean var6 = false; while(true) &#123; boolean var11 = false; try &#123; var11 = true; if (var4 &gt;= this.size) &#123; var11 = false; break; &#125; if (var1.contains(var3[var4]) == var2) &#123; var3[var5++] = var3[var4]; &#125; ++var4; &#125; finally &#123; if (var11) &#123; if (var4 != this.size) &#123; System.arraycopy(var3, var4, var3, var5, this.size - var4); var5 += this.size - var4; &#125; if (var5 != this.size) &#123; for(int var9 = var5; var9 &lt; this.size; ++var9) &#123; var3[var9] = null; &#125; this.modCount += this.size - var5; this.size = var5; var6 = true; &#125; &#125; &#125; &#125; if (var4 != this.size) &#123; System.arraycopy(var3, var4, var3, var5, this.size - var4); var5 += this.size - var4; &#125; if (var5 != this.size) &#123; for(int var7 = var5; var7 &lt; this.size; ++var7) &#123; var3[var7] = null; &#125; this.modCount += this.size - var5; this.size = var5; var6 = true; &#125; return var6; &#125; private void writeObject(ObjectOutputStream var1) throws IOException &#123; int var2 = this.modCount; var1.defaultWriteObject(); var1.writeInt(this.size); for(int var3 = 0; var3 &lt; this.size; ++var3) &#123; var1.writeObject(this.elementData[var3]); &#125; if (this.modCount != var2) &#123; throw new ConcurrentModificationException(); &#125; &#125; private void readObject(ObjectInputStream var1) throws IOException, ClassNotFoundException &#123; this.elementData = EMPTY_ELEMENTDATA; var1.defaultReadObject(); var1.readInt(); if (this.size &gt; 0) &#123; int var2 = calculateCapacity(this.elementData, this.size); SharedSecrets.getJavaOISAccess().checkArray(var1, Object[].class, var2); this.ensureCapacityInternal(this.size); Object[] var3 = this.elementData; for(int var4 = 0; var4 &lt; this.size; ++var4) &#123; var3[var4] = var1.readObject(); &#125; &#125; &#125; /** * 从列表中的指定位置开始，返回列表中的元素（按正确顺序）的列表迭代器。 *指定的索引表示初始调用将返回的第一个元素为next 。 初始调用previous将返回指定索引减1的元素。 *返回的列表迭代器是fail-fast 。 */ public ListIterator&lt;E&gt; listIterator(int var1) &#123; if (var1 &gt;= 0 &amp;&amp; var1 &lt;= this.size) &#123; return new ArrayList.ListItr(var1); &#125; else &#123; throw new IndexOutOfBoundsException(\"Index: \" + var1); &#125; &#125; /** *返回列表中的列表迭代器（按适当的顺序）。 *返回的列表迭代器是fail-fast 。 */ public ListIterator&lt;E&gt; listIterator() &#123; return new ArrayList.ListItr(0); &#125; /** *以正确的顺序返回该列表中的元素的迭代器。 *返回的迭代器是fail-fast 。 */ public Iterator&lt;E&gt; iterator() &#123; return new ArrayList.Itr(); &#125; public List&lt;E&gt; subList(int var1, int var2) &#123; subListRangeCheck(var1, var2, this.size); return new ArrayList.SubList(this, 0, var1, var2); &#125; static void subListRangeCheck(int var0, int var1, int var2) &#123; if (var0 &lt; 0) &#123; throw new IndexOutOfBoundsException(\"fromIndex = \" + var0); &#125; else if (var1 &gt; var2) &#123; throw new IndexOutOfBoundsException(\"toIndex = \" + var1); &#125; else if (var0 &gt; var1) &#123; throw new IllegalArgumentException(\"fromIndex(\" + var0 + \") &gt; toIndex(\" + var1 + \")\"); &#125; &#125; public void forEach(Consumer&lt;? super E&gt; var1) &#123; Objects.requireNonNull(var1); int var2 = this.modCount; Object[] var3 = (Object[])this.elementData; int var4 = this.size; for(int var5 = 0; this.modCount == var2 &amp;&amp; var5 &lt; var4; ++var5) &#123; var1.accept(var3[var5]); &#125; if (this.modCount != var2) &#123; throw new ConcurrentModificationException(); &#125; &#125; public Spliterator&lt;E&gt; spliterator() &#123; return new ArrayList.ArrayListSpliterator(this, 0, -1, 0); &#125; public boolean removeIf(Predicate&lt;? super E&gt; var1) &#123; Objects.requireNonNull(var1); int var2 = 0; BitSet var3 = new BitSet(this.size); int var4 = this.modCount; int var5 = this.size; for(int var6 = 0; this.modCount == var4 &amp;&amp; var6 &lt; var5; ++var6) &#123; Object var7 = this.elementData[var6]; if (var1.test(var7)) &#123; var3.set(var6); ++var2; &#125; &#125; if (this.modCount != var4) &#123; throw new ConcurrentModificationException(); &#125; else &#123; boolean var10 = var2 &gt; 0; if (var10) &#123; int var11 = var5 - var2; int var8 = 0; for(int var9 = 0; var8 &lt; var5 &amp;&amp; var9 &lt; var11; ++var9) &#123; var8 = var3.nextClearBit(var8); this.elementData[var9] = this.elementData[var8]; ++var8; &#125; for(var8 = var11; var8 &lt; var5; ++var8) &#123; this.elementData[var8] = null; &#125; this.size = var11; if (this.modCount != var4) &#123; throw new ConcurrentModificationException(); &#125; ++this.modCount; &#125; return var10; &#125; &#125; public void replaceAll(UnaryOperator&lt;E&gt; var1) &#123; Objects.requireNonNull(var1); int var2 = this.modCount; int var3 = this.size; for(int var4 = 0; this.modCount == var2 &amp;&amp; var4 &lt; var3; ++var4) &#123; this.elementData[var4] = var1.apply(this.elementData[var4]); &#125; if (this.modCount != var2) &#123; throw new ConcurrentModificationException(); &#125; else &#123; ++this.modCount; &#125; &#125; public void sort(Comparator&lt;? super E&gt; var1) &#123; int var2 = this.modCount; Arrays.sort((Object[])this.elementData, 0, this.size, var1); if (this.modCount != var2) &#123; throw new ConcurrentModificationException(); &#125; else &#123; ++this.modCount; &#125; &#125; static final class ArrayListSpliterator&lt;E&gt; implements Spliterator&lt;E&gt; &#123; private final ArrayList&lt;E&gt; list; private int index; private int fence; private int expectedModCount; ArrayListSpliterator(ArrayList&lt;E&gt; var1, int var2, int var3, int var4) &#123; this.list = var1; this.index = var2; this.fence = var3; this.expectedModCount = var4; &#125; private int getFence() &#123; int var1; if ((var1 = this.fence) &lt; 0) &#123; ArrayList var2; if ((var2 = this.list) == null) &#123; var1 = this.fence = 0; &#125; else &#123; this.expectedModCount = var2.modCount; var1 = this.fence = var2.size; &#125; &#125; return var1; &#125; public ArrayList.ArrayListSpliterator&lt;E&gt; trySplit() &#123; int var1 = this.getFence(); int var2 = this.index; int var3 = var2 + var1 &gt;&gt;&gt; 1; return var2 &gt;= var3 ? null : new ArrayList.ArrayListSpliterator(this.list, var2, this.index = var3, this.expectedModCount); &#125; public boolean tryAdvance(Consumer&lt;? super E&gt; var1) &#123; if (var1 == null) &#123; throw new NullPointerException(); &#125; else &#123; int var2 = this.getFence(); int var3 = this.index; if (var3 &lt; var2) &#123; this.index = var3 + 1; Object var4 = this.list.elementData[var3]; var1.accept(var4); if (this.list.modCount != this.expectedModCount) &#123; throw new ConcurrentModificationException(); &#125; else &#123; return true; &#125; &#125; else &#123; return false; &#125; &#125; &#125; public void forEachRemaining(Consumer&lt;? super E&gt; var1) &#123; if (var1 == null) &#123; throw new NullPointerException(); &#125; else &#123; ArrayList var5; Object[] var6; if ((var5 = this.list) != null &amp;&amp; (var6 = var5.elementData) != null) &#123; int var3; int var4; if ((var3 = this.fence) &lt; 0) &#123; var4 = var5.modCount; var3 = var5.size; &#125; else &#123; var4 = this.expectedModCount; &#125; int var2; if ((var2 = this.index) &gt;= 0 &amp;&amp; (this.index = var3) &lt;= var6.length) &#123; while(var2 &lt; var3) &#123; Object var7 = var6[var2]; var1.accept(var7); ++var2; &#125; if (var5.modCount == var4) &#123; return; &#125; &#125; &#125; throw new ConcurrentModificationException(); &#125; &#125; public long estimateSize() &#123; return (long)(this.getFence() - this.index); &#125; public int characteristics() &#123; return 16464; &#125; &#125; private class SubList extends AbstractList&lt;E&gt; implements RandomAccess &#123; private final AbstractList&lt;E&gt; parent; private final int parentOffset; private final int offset; int size; SubList(AbstractList&lt;E&gt; var2, int var3, int var4, int var5) &#123; this.parent = var2; this.parentOffset = var4; this.offset = var3 + var4; this.size = var5 - var4; this.modCount = ArrayList.this.modCount; &#125; public E set(int var1, E var2) &#123; this.rangeCheck(var1); this.checkForComodification(); Object var3 = ArrayList.this.elementData(this.offset + var1); ArrayList.this.elementData[this.offset + var1] = var2; return var3; &#125; public E get(int var1) &#123; this.rangeCheck(var1); this.checkForComodification(); return ArrayList.this.elementData(this.offset + var1); &#125; public int size() &#123; this.checkForComodification(); return this.size; &#125; public void add(int var1, E var2) &#123; this.rangeCheckForAdd(var1); this.checkForComodification(); this.parent.add(this.parentOffset + var1, var2); this.modCount = this.parent.modCount; ++this.size; &#125; public E remove(int var1) &#123; this.rangeCheck(var1); this.checkForComodification(); Object var2 = this.parent.remove(this.parentOffset + var1); this.modCount = this.parent.modCount; --this.size; return var2; &#125; protected void removeRange(int var1, int var2) &#123; this.checkForComodification(); this.parent.removeRange(this.parentOffset + var1, this.parentOffset + var2); this.modCount = this.parent.modCount; this.size -= var2 - var1; &#125; public boolean addAll(Collection&lt;? extends E&gt; var1) &#123; return this.addAll(this.size, var1); &#125; public boolean addAll(int var1, Collection&lt;? extends E&gt; var2) &#123; this.rangeCheckForAdd(var1); int var3 = var2.size(); if (var3 == 0) &#123; return false; &#125; else &#123; this.checkForComodification(); this.parent.addAll(this.parentOffset + var1, var2); this.modCount = this.parent.modCount; this.size += var3; return true; &#125; &#125; public Iterator&lt;E&gt; iterator() &#123; return this.listIterator(); &#125; public ListIterator&lt;E&gt; listIterator(final int var1) &#123; this.checkForComodification(); this.rangeCheckForAdd(var1); final int var2 = this.offset; return new ListIterator&lt;E&gt;() &#123; int cursor = var1; int lastRet = -1; int expectedModCount; &#123; this.expectedModCount = ArrayList.this.modCount; &#125; public boolean hasNext() &#123; return this.cursor != SubList.this.size; &#125; public E next() &#123; this.checkForComodification(); int var1x = this.cursor; if (var1x &gt;= SubList.this.size) &#123; throw new NoSuchElementException(); &#125; else &#123; Object[] var2x = ArrayList.this.elementData; if (var2 + var1x &gt;= var2x.length) &#123; throw new ConcurrentModificationException(); &#125; else &#123; this.cursor = var1x + 1; return var2x[var2 + (this.lastRet = var1x)]; &#125; &#125; &#125; public boolean hasPrevious() &#123; return this.cursor != 0; &#125; public E previous() &#123; this.checkForComodification(); int var1x = this.cursor - 1; if (var1x &lt; 0) &#123; throw new NoSuchElementException(); &#125; else &#123; Object[] var2x = ArrayList.this.elementData; if (var2 + var1x &gt;= var2x.length) &#123; throw new ConcurrentModificationException(); &#125; else &#123; this.cursor = var1x; return var2x[var2 + (this.lastRet = var1x)]; &#125; &#125; &#125; public void forEachRemaining(Consumer&lt;? super E&gt; var1x) &#123; Objects.requireNonNull(var1x); int var2x = SubList.this.size; int var3 = this.cursor; if (var3 &lt; var2x) &#123; Object[] var4 = ArrayList.this.elementData; if (var2 + var3 &gt;= var4.length) &#123; throw new ConcurrentModificationException(); &#125; else &#123; while(var3 != var2x &amp;&amp; SubList.this.modCount == this.expectedModCount) &#123; var1x.accept(var4[var2 + var3++]); &#125; this.lastRet = this.cursor = var3; this.checkForComodification(); &#125; &#125; &#125; public int nextIndex() &#123; return this.cursor; &#125; public int previousIndex() &#123; return this.cursor - 1; &#125; public void remove() &#123; if (this.lastRet &lt; 0) &#123; throw new IllegalStateException(); &#125; else &#123; this.checkForComodification(); try &#123; SubList.this.remove(this.lastRet); this.cursor = this.lastRet; this.lastRet = -1; this.expectedModCount = ArrayList.this.modCount; &#125; catch (IndexOutOfBoundsException var2x) &#123; throw new ConcurrentModificationException(); &#125; &#125; &#125; public void set(E var1x) &#123; if (this.lastRet &lt; 0) &#123; throw new IllegalStateException(); &#125; else &#123; this.checkForComodification(); try &#123; ArrayList.this.set(var2 + this.lastRet, var1x); &#125; catch (IndexOutOfBoundsException var3) &#123; throw new ConcurrentModificationException(); &#125; &#125; &#125; public void add(E var1x) &#123; this.checkForComodification(); try &#123; int var2x = this.cursor; SubList.this.add(var2x, var1x); this.cursor = var2x + 1; this.lastRet = -1; this.expectedModCount = ArrayList.this.modCount; &#125; catch (IndexOutOfBoundsException var3) &#123; throw new ConcurrentModificationException(); &#125; &#125; final void checkForComodification() &#123; if (this.expectedModCount != ArrayList.this.modCount) &#123; throw new ConcurrentModificationException(); &#125; &#125; &#125;; &#125; public List&lt;E&gt; subList(int var1, int var2) &#123; ArrayList.subListRangeCheck(var1, var2, this.size); return ArrayList.this.new SubList(this, this.offset, var1, var2); &#125; private void rangeCheck(int var1) &#123; if (var1 &lt; 0 || var1 &gt;= this.size) &#123; throw new IndexOutOfBoundsException(this.outOfBoundsMsg(var1)); &#125; &#125; private void rangeCheckForAdd(int var1) &#123; if (var1 &lt; 0 || var1 &gt; this.size) &#123; throw new IndexOutOfBoundsException(this.outOfBoundsMsg(var1)); &#125; &#125; private String outOfBoundsMsg(int var1) &#123; return \"Index: \" + var1 + \", Size: \" + this.size; &#125; private void checkForComodification() &#123; if (ArrayList.this.modCount != this.modCount) &#123; throw new ConcurrentModificationException(); &#125; &#125; public Spliterator&lt;E&gt; spliterator() &#123; this.checkForComodification(); return new ArrayList.ArrayListSpliterator(ArrayList.this, this.offset, this.offset + this.size, this.modCount); &#125; &#125; private class ListItr extends ArrayList&lt;E&gt;.Itr implements ListIterator&lt;E&gt; &#123; ListItr(int var2) &#123; super(); this.cursor = var2; &#125; public boolean hasPrevious() &#123; return this.cursor != 0; &#125; public int nextIndex() &#123; return this.cursor; &#125; public int previousIndex() &#123; return this.cursor - 1; &#125; public E previous() &#123; this.checkForComodification(); int var1 = this.cursor - 1; if (var1 &lt; 0) &#123; throw new NoSuchElementException(); &#125; else &#123; Object[] var2 = ArrayList.this.elementData; if (var1 &gt;= var2.length) &#123; throw new ConcurrentModificationException(); &#125; else &#123; this.cursor = var1; return var2[this.lastRet = var1]; &#125; &#125; &#125; public void set(E var1) &#123; if (this.lastRet &lt; 0) &#123; throw new IllegalStateException(); &#125; else &#123; this.checkForComodification(); try &#123; ArrayList.this.set(this.lastRet, var1); &#125; catch (IndexOutOfBoundsException var3) &#123; throw new ConcurrentModificationException(); &#125; &#125; &#125; public void add(E var1) &#123; this.checkForComodification(); try &#123; int var2 = this.cursor; ArrayList.this.add(var2, var1); this.cursor = var2 + 1; this.lastRet = -1; this.expectedModCount = ArrayList.this.modCount; &#125; catch (IndexOutOfBoundsException var3) &#123; throw new ConcurrentModificationException(); &#125; &#125; &#125; private class Itr implements Iterator&lt;E&gt; &#123; int cursor; int lastRet = -1; int expectedModCount; Itr() &#123; this.expectedModCount = ArrayList.this.modCount; &#125; public boolean hasNext() &#123; return this.cursor != ArrayList.this.size; &#125; public E next() &#123; this.checkForComodification(); int var1 = this.cursor; if (var1 &gt;= ArrayList.this.size) &#123; throw new NoSuchElementException(); &#125; else &#123; Object[] var2 = ArrayList.this.elementData; if (var1 &gt;= var2.length) &#123; throw new ConcurrentModificationException(); &#125; else &#123; this.cursor = var1 + 1; return var2[this.lastRet = var1]; &#125; &#125; &#125; public void remove() &#123; if (this.lastRet &lt; 0) &#123; throw new IllegalStateException(); &#125; else &#123; this.checkForComodification(); try &#123; ArrayList.this.remove(this.lastRet); this.cursor = this.lastRet; this.lastRet = -1; this.expectedModCount = ArrayList.this.modCount; &#125; catch (IndexOutOfBoundsException var2) &#123; throw new ConcurrentModificationException(); &#125; &#125; &#125; public void forEachRemaining(Consumer&lt;? super E&gt; var1) &#123; Objects.requireNonNull(var1); int var2 = ArrayList.this.size; int var3 = this.cursor; if (var3 &lt; var2) &#123; Object[] var4 = ArrayList.this.elementData; if (var3 &gt;= var4.length) &#123; throw new ConcurrentModificationException(); &#125; else &#123; while(var3 != var2 &amp;&amp; ArrayList.this.modCount == this.expectedModCount) &#123; var1.accept(var4[var3++]); &#125; this.cursor = var3; this.lastRet = var3 - 1; this.checkForComodification(); &#125; &#125; &#125; final void checkForComodification() &#123; if (ArrayList.this.modCount != this.expectedModCount) &#123; throw new ConcurrentModificationException(); &#125; &#125; &#125;&#125; 小结在阅读源码的过程中， 我发现， 源码中使用System.arraycopy这个方法居多， 其次便是Arrays.copyOfSystem.arraycopy与Arrays.copyOf的区别是： arraycopy()需要目标数组，将原数组拷贝到你自己定义的数组里，而且可以选择拷贝的起点和长度以及放入新数组中的位置 copyOf()是系统自动在内部新建一个数组，并返回该数组。 ArrayList 核心扩容12345678910111213141516171819202122232425262728293031323334353637383940/*** 判断是否需要扩容*/private void ensureCapacityInternal(int var1) &#123; this.ensureExplicitCapacity(calculateCapacity(this.elementData, var1));&#125;private void ensureExplicitCapacity(int var1) &#123; ++this.modCount; if (var1 - this.elementData.length &gt; 0) &#123; this.grow(var1); &#125;&#125;/*** 扩容的核心算法*/private void grow(int var1) &#123; int var2 = this.elementData.length; // 对于大数据的2进制运算,位移运算符比那些普通运算符的运算要快很多,因为程序仅仅移动一下而已,不去计算,这样提高了效率,节省了资源 // 右移一位相当于除2，右移n位相当于除以 2 的 n 次方。这里 oldCapacity 明显右移了1位所以相当于oldCapacity /2。 int var3 = var2 + (var2 &gt;&gt; 1); if (var3 - var1 &lt; 0) &#123; var3 = var1; &#125; if (var3 - 2147483639 &gt; 0) &#123; var3 = hugeCapacity(var1); &#125; this.elementData = Arrays.copyOf(this.elementData, var3);&#125;private static int hugeCapacity(int var0) &#123; if (var0 &lt; 0) &#123; throw new OutOfMemoryError(); &#125; else &#123; return var0 &gt; 2147483639 ? 2147483647 : 2147483639; &#125;&#125; 来自JAVA Guid的demo1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public class ArrayListDemo &#123; public static void main(String[] srgs)&#123; ArrayList&lt;Integer&gt; arrayList = new ArrayList&lt;Integer&gt;(); System.out.printf(\"Before add:arrayList.size() = %d\\n\",arrayList.size()); arrayList.add(1); arrayList.add(3); arrayList.add(5); arrayList.add(7); arrayList.add(9); System.out.printf(\"After add:arrayList.size() = %d\\n\",arrayList.size()); System.out.println(\"Printing elements of arrayList\"); // 三种遍历方式打印元素 // 第一种：通过迭代器遍历 System.out.print(\"通过迭代器遍历:\"); Iterator&lt;Integer&gt; it = arrayList.iterator(); while(it.hasNext())&#123; System.out.print(it.next() + \" \"); &#125; System.out.println(); // 第二种：通过索引值遍历 System.out.print(\"通过索引值遍历:\"); for(int i = 0; i &lt; arrayList.size(); i++)&#123; System.out.print(arrayList.get(i) + \" \"); &#125; System.out.println(); // 第三种：for循环遍历 System.out.print(\"for循环遍历:\"); for(Integer number : arrayList)&#123; System.out.print(number + \" \"); &#125; // toArray用法 // 第一种方式(最常用) Integer[] integer = arrayList.toArray(new Integer[0]); // 第二种方式(容易理解) Integer[] integer1 = new Integer[arrayList.size()]; arrayList.toArray(integer1); // 抛出异常，java不支持向下转型 //Integer[] integer2 = new Integer[arrayList.size()]; //integer2 = arrayList.toArray(); System.out.println(); // 在指定位置添加元素 arrayList.add(2,2); // 删除指定位置上的元素 arrayList.remove(2); // 删除指定元素 arrayList.remove((Object)3); // 判断arrayList是否包含5 System.out.println(\"ArrayList contains 5 is: \" + arrayList.contains(5)); // 清空ArrayList arrayList.clear(); // 判断ArrayList是否为空 System.out.println(\"ArrayList is empty: \" + arrayList.isEmpty()); &#125;&#125;","categories":[],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://wt-git-repository.github.io/tags/JAVA/"}]},{"title":"探究Spring Boot 核心技术","slug":"探究Spring-Boot-核心技术","date":"2019-03-06T12:59:45.000Z","updated":"2019-07-08T01:15:52.731Z","comments":true,"path":"2019/03/06/探究Spring-Boot-核心技术/","link":"","permalink":"https://wt-git-repository.github.io/2019/03/06/探究Spring-Boot-核心技术/","excerpt":"探究Spring BootPOM 文件1.父项目12345678910111213141516&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.1.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&lt;/parent&gt;他的父项目是&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.1.1.RELEASE&lt;/version&gt; &lt;relativePath&gt;../../spring-boot-dependencies&lt;/relativePath&gt;&lt;/parent&gt;这个父项目是真正管理Spring Boot应用里面所有依赖版本,因为里面有一个dependency version, 为各种jar包定义了默认的版本号 Spring Boot的版本仲裁中心;以后我们导入依赖默认是不需要写版本的, (在没有dependencies里面管理的依赖自然要声明版本号)","text":"探究Spring BootPOM 文件1.父项目12345678910111213141516&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.1.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&lt;/parent&gt;他的父项目是&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.1.1.RELEASE&lt;/version&gt; &lt;relativePath&gt;../../spring-boot-dependencies&lt;/relativePath&gt;&lt;/parent&gt;这个父项目是真正管理Spring Boot应用里面所有依赖版本,因为里面有一个dependency version, 为各种jar包定义了默认的版本号 Spring Boot的版本仲裁中心;以后我们导入依赖默认是不需要写版本的, (在没有dependencies里面管理的依赖自然要声明版本号) 2.起步依赖 Spring-boot-starter 场景启动器1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; 举个例子,spring-boot-starter-web,帮我们导入web应用开发所需要的所有依赖 Spring boot 把所有的功能场景都抽取出来,做成一个个starters(启动器), 只需要在项目里面导入这些starters, 所有相关的依赖都会导入进来 一般需要什么功能就导入什么场景的启动器 主程序类,主入口类1234567891011/** * SpringBootApplication 来标注一个主程序类, 说明这是一个Spring Boot 应用 */@SpringBootApplicationpublic class SpringbootSampleApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringbootSampleApplication.class, args); &#125;&#125; @SpringBootApplication: Spring Boot应用标注在某个类上来说明这个类是Spring Boot的主配置类, Spring Boot就应该运行这个类的main方法来启动Spring Boot应用 12345678910111213141516171819/***SpringBootApplication 部分源码*/@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan( excludeFilters = &#123;@Filter( type = FilterType.CUSTOM, classes = &#123;TypeExcludeFilter.class&#125;), @Filter( type = FilterType.CUSTOM, classes = &#123;AutoConfigurationExcludeFilter.class&#125;)&#125;)public @interface SpringBootApplication &#123; @SpringBootConfiguration : Spring Boot的配置类 @EnableAutoConfiguration: 开启自动配置功能 1234567@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@AutoConfigurationPackage@Import(&#123;AutoConfigurationImportSelector.class&#125;)public @interface EnableAutoConfiguration &#123; @AutoConfiguraPackage:将主配置类(@SpringBootApplication标注的类)的所在包以及下面所有子包里面的所有组件都扫描到Spring容器中, 这一点要特别注意!!! 举个例子 Spring Boot 目录结构 这里主要说resources文件夹下面的结构 static: 保存所以静态资源, 如js css images等等 templates: 保存所以模板页面, Spring Boot默认jar包使用嵌入式tomcat, 默认不支持JSP页面, 可以使用模板引擎(freemarker, 或者Spring Boot推荐的thymeleaf) application.properties : Spring Boot 的配置文件, 可以修改一些默认配置 Spring Boot配置文件1.配置文件Spring Boot 使用一个全局的配置文件, 配置文件名是固定的 application.properties application.yml (推荐使用) 配置文件的作用在于: 修改Spring Boot自动配置的默认值 2.YAML基本语法 键值对的形式, 以空格来控制层级关系 k:(空格)v 空格不能省, 大小写敏感 推荐使用YMAL来做配置文件, 例子 12server: port: 8081 YAML value的写法值得需要注意的地方 字符串默认不用加上单引号或者双引号 如果加上双引号, 则不会转义字符串里面的特殊字符, 如 “wt \\n wt” 输出的是 “wt \\n wt” 如果加上单引号, 则会转义字符串里面的特殊字符, 如 “wt \\n wt” 输出的是 “wt 换行 wt” 数组, 使用-值表示数组中的一个元素12345&gt; pets:&gt; - cats&gt; - dog&gt; - pig&gt; 3. YAML配置文件值注入 此处举例子进行说明 首先编写YAML文件 1234567person: name: wt age: 22 maps: &#123;k1: v1, k2: v2&#125; dog: name: my_dog age: 2 导入依赖 123456&lt;!--导入配置文件处理器--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt; JAVABean 1234567891011121314151617181920/** * 将配置文件中配置的每一个属性的值,映射到这个组件中 * @ConfigurationProperties 告诉Spring Boot 将本类中的所有属性和配置文件中的相关配置进行绑定 * prefix = \"person\" 配置文件中哪一个属性进行绑定, 以person开头的值 * * 只有这个组件是容器中的组件,才能使用容器提供的@ConfigurationProperties功能 */@Component@ConfigurationProperties(prefix = \"person\")public class Person &#123; private String name; private Integer age; private Map&lt;String, Object&gt; maps; private Dog dog; ---&#125; JAVABean 123456public class Dog &#123; private String name; private Integer age; ---&#125; 测试 123456789101112131415@RunWith(SpringRunner.class)@SpringBootTestpublic class SpringbootSampleApplicationTests &#123; @Autowired Person person; @Test public void contextLoads() &#123; System.out.println(person); &#125;&#125;输出 Person&#123;name='wt', age=22, maps=&#123;k1=v1, k2=v2&#125;, dog=Dog&#123;name='my_dog', age=2&#125;&#125; 4. @Value 和 @ConfigurationProperties的区别 @ConfigurationProperties @Value 功能 批量注入配置属性文件的属性 一个个指定 松散绑定(松散语法) 支持 不支持 SpringEL 不支持 支持 JR303数据校验 支持 不支持 复杂类型 支持 不支持 如果说, 我们只是需要在某个业务逻辑中获取一下配置文件的某个值, 则使用@Value, 可读取YAML文件1234567891011@RestControllerpublic class HelloController &#123; @Value(\"$&#123;person.name&#125;\") private String name; @RequestMapping(\"/sayHello\") public String sayHello() &#123; return \"hello \" + name; &#125;&#125; 如果需要与一个JAVABean进行映射,则使用@ConfigurationProperties来批量注入 5.介绍两个有用且相关的注解, @PropertySource 和 @ImportResource首先先介绍@PropertySource, 此处有一点值得注意的是,官网里面有这样一句话:YAML files cannot be loaded by using the @PropertySource annotation. So, in the case that you need to load values that way, you need to use a properties file. 意思就是说, @PropertySource只能用于.properties文件而不能用于YMAL文件, 所以, 此处我们还是举个例子来进行说明. 创建person.properties 文件 123456person.name=wtperson.age=22person.maps.k1=v1person.maps.k2=v2person.dog.name=my_dogperson.dog.age=2 修改Person类, 添加@PropertySource(value = {“classpath:person.properties”}) 123456789101112131415161718/** * 将配置文件中配置的每一个属性的值,映射到这个组件中 * @ConfigurationProperties 告诉Spring Boot 将本类中的所有属性和配置文件中的相关配置进行绑定 * prefix = \"person\" 配置文件中哪一个属性进行绑定 默认从全局配置获取值, 以person开头的值 * * 只有这个组件是容器中的组件,才能使用容器提供的@ConfigurationProperties功能 */@PropertySource(value = &#123;\"classpath:person.properties\"&#125;)@Component@ConfigurationProperties(prefix = \"person\")public class Person &#123; private String name; private Integer age; private Map&lt;String, Object&gt; maps; private Dog dog; --- 接下来, 介绍@ImportResource, 它的作用是引入Spring 配置文件, Spring Boot里面没有Spring的配置文件, 我们自己写的配置文件是不能被自动识别的, 此时, 便要使用@ImportResource, 放在一个配置类上举个例子 创建一个XML文件 1234567&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;bean id=\"helloService\" class=\"com.example.springbootsample.service.HelloService\"&gt;&lt;/bean&gt;&lt;/beans&gt; 添加@ImportResource到主配置类中 123456789101112/** * SpringBootApplication 来标注一个主程序类, 说明这是一个Spring Boot 应用 */@ImportResource(locations = &#123;\"classpath:beans.xml\"&#125;)@SpringBootApplicationpublic class SpringbootSampleApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringbootSampleApplication.class, args); &#125;&#125; 测试 12345678910111213141516171819@RunWith(SpringRunner.class)@SpringBootTestpublic class SpringbootSampleApplicationTests &#123; @Autowired Person person; @Autowired ApplicationContext ioc; @Test public void testHelloService() &#123; boolean b = ioc.containsBean(\"helloService\"); System.out.println(b); &#125;&#125;输出true 然而, Spring Boot 不推荐使用XML, 而是使用全注解的方式来为容器添加组件 创建一个配置类 使用@Bean来给容器添加组件 12345678910111213141516171819202122package com.example.springbootsample.config;import com.example.springbootsample.service.HelloService;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * @Configuration 指明当前类是一个配置类, 来替代之前的Spring配置文件 * * 在Spring配置文件中, 这是用&lt;bean&gt;&lt;/bean&gt;标签来添加组件的 * */@Configurationpublic class MyAppConfiguration &#123; // 将方法的返回值添加到容器中, 容器中默认的组件id就是这个方法名helloService01 @Bean public HelloService helloService01() &#123; System.out.println(\"添加组件\"); return new HelloService(); &#125;&#125; 6.配置文件占位符 随机数 1$&#123;random.value&#125; $&#123;random.int&#125; $&#123;random.long&#125; $&#123;random.int[1024, 65536]&#125; 使用占位符获取之前配置的值, 如果没有, 则使用 : 指定默认值 123456person.name=wt$&#123;random.uuid&#125;person.age=22person.maps.k1=v1person.maps.k2=$&#123;person.hello:hello&#125;person.dog.name=my_dogperson.dog.age=2 7.ProfileProfile 是 Spring 对不同环境提供不同配置功能的支持, 可以通过激活或者指定参数等方式快速切换环境, 默认使用application.properties 多Profile文件形式: 格式: application-{profile}.properties/yml 如: application-dev.properties 激活指定的profile 在默认的配置文件中, 指定spring.profiles.ative=dev, 则会使用application-dev.properties 命令行的方式: –spring.profiles.ative=dev, 可以在java -jar 命令后面写入, 可以在idea tomcat那里配置 虚拟机参数-Dspring.profile.active=dev YAML可以用文档块来指定不同的环境, 如 123456789101112131415server: port: 8081spring: profiles: active: dev #激活dev环境, 如果不指明, 则使用默认的8081端口---server: port: 8082spring: profiles: dev---server: port: 8083spring: profiles: prod 8.配置文件的加载位置Spring Boot 启动会扫描以下位置的application.properties 或 application.yml文件作为spring boot 的配置文件, 优先级从高到底, 高优先级的内容会覆盖低优先级内容 file:./config/ file:./ classpath:/config/ classpath:/ 值得注意的是, Spring Boot会从这四个位置全部加载主配置文件, 且互补配置, 即, 高优先级有的, 使用高优先级, 高优先级没有的而低优先级有的, 则使用低优先级 9.外部配置文件的加载位置此处内容较多, 建议参考 官方文档中的Externalized Configuration 10.配置原理配置文件的配置内容, 参考官方文档附录Common application properties 11、@Conditional派生注解（Spring注解版原生的@Conditional作用）作用：必须是@Conditional指定的条件成立，才给容器中添加组件，配置配里面的所有内容才生效； @Conditional扩展注解 作用（判断是否满足当前指定条件） @ConditionalOnJava 系统的java版本是否符合要求 @ConditionalOnBean 容器中存在指定Bean； @ConditionalOnMissingBean 容器中不存在指定Bean； @ConditionalOnExpression 满足SpEL表达式指定 @ConditionalOnClass 系统中有指定的类 @ConditionalOnMissingClass 系统中没有指定的类 @ConditionalOnSingleCandidate 容器中只有一个指定的Bean，或者这个Bean是首选Bean @ConditionalOnProperty 系统中指定的属性是否有指定的值 @ConditionalOnResource 类路径下是否存在指定资源文件 @ConditionalOnWebApplication 当前是web环境 @ConditionalOnNotWebApplication 当前不是web环境 @ConditionalOnJndi JNDI存在指定项 12, 打印自动配置类启用报告在配置文件中加上debug=true属性控制台便会打印相关的信息1234567891011121314151617181920212223242526272829============================CONDITIONS EVALUATION REPORT============================Positive matches: (自动配置类启用的)----------------- AopAutoConfiguration matched: - @ConditionalOnClass found required classes 'org.springframework.context.annotation.EnableAspectJAutoProxy', 'org.aspectj.lang.annotation.Aspect', 'org.aspectj.lang.reflect.Advice', 'org.aspectj.weaver.AnnotatedElement' (OnClassCondition) - @ConditionalOnProperty (spring.aop.auto=true) matched (OnPropertyCondition) AopAutoConfiguration.CglibAutoProxyConfiguration matched: - @ConditionalOnProperty (spring.aop.proxy-target-class=true) matched (OnPropertyCondition) ---Negative matches: (自动配置类未启用的, 没有匹配成功)---------------- ActiveMQAutoConfiguration: Did not match: - @ConditionalOnClass did not find required class 'javax.jms.ConnectionFactory' (OnClassCondition) AopAutoConfiguration.JdkDynamicAutoProxyConfiguration: Did not match: - @ConditionalOnProperty (spring.aop.proxy-target-class=false) did not find property 'proxy-target-class' (OnPropertyCondition) ---","categories":[],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://wt-git-repository.github.io/tags/Spring-Boot/"}]},{"title":"JAVA内存区域与内存溢出异常","slug":"JAVA内存区域与内存溢出异常","date":"2019-03-06T12:58:35.000Z","updated":"2019-07-08T01:15:52.669Z","comments":true,"path":"2019/03/06/JAVA内存区域与内存溢出异常/","link":"","permalink":"https://wt-git-repository.github.io/2019/03/06/JAVA内存区域与内存溢出异常/","excerpt":"JAVA内存区域与内存溢出异常JAVA虚拟机管理下的内存包括如下几个运行时数据区域 程序计数器: 一块较小的内存空间,是当前线程所执行的字节码的行号指示器 每个线程都有独立的一个程序计数器,使得各个线程的切换可以恢复到正确的执行位置","text":"JAVA内存区域与内存溢出异常JAVA虚拟机管理下的内存包括如下几个运行时数据区域 程序计数器: 一块较小的内存空间,是当前线程所执行的字节码的行号指示器 每个线程都有独立的一个程序计数器,使得各个线程的切换可以恢复到正确的执行位置 JAVA虚拟机栈:描述的是JAVA方法执行的内存模型 每个方法在执行的同时都会创建一个栈帧(存储方法的相关信息) 一个方法从调用到执行的过程中就相当于一个栈帧在虚拟机栈中的入栈和出栈的过程 许多人喜欢把JAVA内存分为堆内存和栈内存(当然这不是研究的分法,只是与对象内存分配关系最密切的内存区域就是这两块),其中栈内存指的就是虚拟机栈中的局部变量表部分 虚拟机栈的局部变量表存放编译期可知的各种基本数据类型,对象引用以及returnAddress类型 这里指的注意的是:局部变量表所需的内存空间在编译期间完成分配,当进入一个方法时,这个方法需要在帧中分配多大的局部变量空间是完全确定的,这个方法运行期间不会改变局部变量表的大小 对于上一点,在JVM规范中定义了两种异常状况:① 如果线程请求的栈深度大于虚拟机所允许的深度,将抛出StackOverflowError的错误;② 如果虚拟机栈可以动态扩展,只是扩展时无法申请到足够的内存,就会抛出OutOfMemoryError异常. 本独方法栈: 与虚拟机栈的作用类似, 区别在于本地方法栈为虚拟机使用到的Native方法服务 该栈也会抛出StackOverflowError与OutOfMemoryError异常 JAVA堆: 存放对象实例,被所有线程共享 JVM所管理的内存中最大的一块 JAVA堆是垃圾收集器管理的主要区域, 很多时候被称作为”GC堆” 方法区 用于存储已被虚拟机加载的类方法,常量,静态变量,即时编译器编译后的代码等数据 运行时常量池 方法区的一部分,Class文件除了描述信息之外,还有一个常量池,用于存放编译期生成的各种字面量和符号引用,这部分内容将在类加载后进入方法区的运行时常量池存放 具备动态性,不要求常量一定是在编译器中产生,也可以在运行期间将新的常量放入池中, 如String类中的intern()方法 内存饱满是也会抛出OutOfMemoryError方法 直接内存 HotSpot虚拟机对象对象的创建 对象创建 (在语言层面上,创建对象通常相当于一个new关键字) 当虚拟机遇到一条new指令时,首先会去检查这个指令的参数是否能在常量池中定位到一个类的符号引用,并且检查这个符号引用代表的类是否已被加载或解析或初始化过,如果没有,那必须先执行相应的类加载过程 检查通过后,虚拟机为新生对象分配内存,对象所需要的内存的大小在类加载完成后便可完全确定 为对象分配内存就相当于把一块确定大小的内存从JAVA堆中划分出来 执行完new指令后,接着执行方法,把对象按照程序员的意愿进行初始化,这样一个真正可用的对象才算完全产生出来 对象的内存布局 在HotSpot虚拟机中,对象在内存中存储的布局可分为三块区域:对象头,实例数据和对齐填充 对象头包括两部分信息:① 存储对象自身的运行时数据, ② 类型指针(指向类元数据的指针, 虚拟机通过这个指针来确定这个对象是哪个类的实例, 如果对象是数组, 则对象头中还必须有一块用于记录数组长度的数据) 实例数据:对象头真正存储的有效信息,也是代码中所定义的各种类型的字段内容","categories":[],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://wt-git-repository.github.io/tags/JAVA/"}]},{"title":"docker| 数据管理","slug":"docker-数据管理","date":"2019-03-06T12:57:57.000Z","updated":"2019-07-08T01:15:52.700Z","comments":true,"path":"2019/03/06/docker-数据管理/","link":"","permalink":"https://wt-git-repository.github.io/2019/03/06/docker-数据管理/","excerpt":"数据管理在容器中管理数据的方式主要有两种 数据卷挂载主机目录 数据卷 定义：数据卷是一个可以供一个或者多个容器使用的特殊目录 特点 可以在容器之间共享和重用对数据卷的修改会马上生效对数据卷的更新不会影响镜像数据卷会一直存在，即使容器被删除","text":"数据管理在容器中管理数据的方式主要有两种 数据卷挂载主机目录 数据卷 定义：数据卷是一个可以供一个或者多个容器使用的特殊目录 特点 可以在容器之间共享和重用对数据卷的修改会马上生效对数据卷的更新不会影响镜像数据卷会一直存在，即使容器被删除 创建一个数据卷 命令 sudo docker volume create [volume_name] 查看所有的数据卷 命令 sudo docker volume ls 查看指定数据卷的信息-命令 sudo docker volume inspect [volume_name] 启动一个加载数据卷的容器 命令 sudo docker run -d \\-P 81:80 \\–name web \\–mount source=[volume_name],target=[target_name] \\[Image_name] -d后台运行 -P端口映射 –mount将[volume_name]数据卷加载到容器的[target_name]目录下 [Image_name]镜像名 app.py主体程序 查看数据卷的具体信息 命令 sudo docker inspect [container_name] 删除镜像 命令 sudo docker volume rm [volume_name] 挂载主机目录挂载一个主机目录作为数据卷 命令 sudo docker run -d \\-P 81:80 \\–name web \\-v /src/webapp:/opt/webapp [Image_name] Docker挂载目录默认的权限是读写，ro是只读","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"https://wt-git-repository.github.io/tags/docker/"}]},{"title":"docker| 操作容器","slug":"docker-操作容器","date":"2019-03-06T12:57:36.000Z","updated":"2019-07-08T01:15:52.699Z","comments":true,"path":"2019/03/06/docker-操作容器/","link":"","permalink":"https://wt-git-repository.github.io/2019/03/06/docker-操作容器/","excerpt":"操作容器启动容器 启动容器有两种方式 基于镜像新建一个容器并启动 在终止状态（stopped）的容器重新启动 新建启动并在后台运行 命令 sudo docker run －d –name [name] 镜像名[:标签] -d：后台运行，启动后会进入容器 –name可为容器取名，等同与容器ID 输出结果可以用 docker logs 查看","text":"操作容器启动容器 启动容器有两种方式 基于镜像新建一个容器并启动 在终止状态（stopped）的容器重新启动 新建启动并在后台运行 命令 sudo docker run －d –name [name] 镜像名[:标签] -d：后台运行，启动后会进入容器 –name可为容器取名，等同与容器ID 输出结果可以用 docker logs 查看 命令:docker logs [OPTIONS] [container ID or NAMES]-f：跟踪日志输出 使用docker run创建容器是，Docker在后台运行的标准操作包括:检查本地是否存在指定的镜像，不存在就从公有仓库下载利用镜像创建并启动一个容器分配一个文件系统，并在只读的镜像层外面挂载一层可读写层从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去从地址池配置一个 ip 地址给容器执行用户指定的应用程序执行完毕后容器被终止 终止运行中的容器 命令 sudo docker container stop &lt;Container_ID&gt; 查看容器信息 命令 sudo docker container ls 加-a 可以查看被终止的容器信息 启动被终止的容器 命令 sudo docker container start &lt;Container_ID&gt; 重启容器 命令 sudo docker container restart 进入容器 命令 docker exec -it &lt;Container_ID&gt; bash exit命令退出 导出容器 命令 docker export &lt;Container_ID&gt; &gt; &lt;local_file_name&gt;例如：docker export 7691a814370e &gt; ubuntu.tar 导入容器 命令 cat &lt;local_file_name&gt; | docker import - &lt;仓库名&gt;:例如：cat ubuntu.tar | docker import - test/ubuntu:v1.0ordocker import http://example.com/exampleimage.tgz example/imagerepo 删除容器 命令 sudo docker rm -v [container_name] -v删除容器的同时移除数据卷","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"https://wt-git-repository.github.io/tags/docker/"}]},{"title":"docker| 基本概念","slug":"docker-基本概念","date":"2019-03-06T12:56:53.000Z","updated":"2019-07-08T01:15:52.698Z","comments":true,"path":"2019/03/06/docker-基本概念/","link":"","permalink":"https://wt-git-repository.github.io/2019/03/06/docker-基本概念/","excerpt":"dockerwhat is docker Docker是基于Go语言开发实现的，是一种对进程进行封装隔离，属于操作系统层面的虚拟化技术 由于隔离的进程独立于宿主和其它隔离的进程，Docker也因此被称为容器 The discrimination between virtual machines and docker 传统虚拟机技术是虚拟出一套硬件，在其运行一个完整的操作系统，然后在这个系统运行所需的应用进程 Docker的应用进程是直接运行为宿主的内核上，容器内没有自己的内核，更没有硬件虚拟 Docker容器比传统的虚拟机更为轻便","text":"dockerwhat is docker Docker是基于Go语言开发实现的，是一种对进程进行封装隔离，属于操作系统层面的虚拟化技术 由于隔离的进程独立于宿主和其它隔离的进程，Docker也因此被称为容器 The discrimination between virtual machines and docker 传统虚拟机技术是虚拟出一套硬件，在其运行一个完整的操作系统，然后在这个系统运行所需的应用进程 Docker的应用进程是直接运行为宿主的内核上，容器内没有自己的内核，更没有硬件虚拟 Docker容器比传统的虚拟机更为轻便 The discrimination between virtual machines and docker The advantage of Docker 容器不需要硬件模拟或者运行操作系统等额外开外，故相比与传统的虚拟机技术，一个相同配置的主机，可以运行更多数量的容器 容器直接运行于宿主内核，无需启动完整的操作系统，因此可以做到毫秒级的启动 容器可以提供一致的开发环境 使用容器可以定制镜像来实现持续集成，交付和部署 Docker Image Docker镜像(Image)，就相当于是一个root文件系统 镜像使用的是分层存储 例如：官方镜像 ubuntu:16.04 就包含了完整的一套 Ubuntu 16.04 最小系统的 root 文件系统 Docker Container 镜像(Image)和容器(Container)的关系，就相当于面向对象程序设计的类和实例一样 镜像是静态的定义 容器是镜像运行时的实体 容器可以被创建，启动，停止，删除，暂停等等 容器是一个运行在隔离环境下的进程，与其它进程不同的是，容器可以拥有只属于自己的root文件系统,自己的网络配置，自己的进程空间以及自己的ID空间等等 如同镜像一样，容器也是使用分层存储，每一个容器运行时，以镜像为基础层，在其上创建一个当前容器的存储层，可称为容器运行时而准备的存储层，又称容器存储层 容器消亡时，容器存储层也随之消亡，故，容器不应向存储层写入任何数据需保持无状态化 所以的文件写入操作，都应该使用数据卷,或者绑定宿主目录,在这些位置的读写会跳过容器存储层，直接对宿主或者网络存储发生读写 容器消亡，数据卷不会消亡，使用数据卷后，容器删除或者重新运行之后，数据不会丢失 Docker Register 一个 Docker Registry 中可以包含多个仓库（Repository） 每个仓库可以包含多个标签（Tag）,每个标签对应一个镜像，如版本标签,如果忽略标签，则使用latest作为默认标签 Docker Hub 阿里云加速器","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"https://wt-git-repository.github.io/tags/docker/"}]},{"title":"docker| 镜像使用","slug":"docker-镜像使用","date":"2019-03-06T12:56:30.000Z","updated":"2019-07-08T01:15:52.701Z","comments":true,"path":"2019/03/06/docker-镜像使用/","link":"","permalink":"https://wt-git-repository.github.io/2019/03/06/docker-镜像使用/","excerpt":"使用镜像从 Docker 镜像仓库获取镜像的命令 命令格式 sudo docker pull [选项] [url : 端口号]/镜像名[:标签] 此处的url 默认为Docker Hub 标签可忽略，默认为latest 举个例子 $ docker pull ubuntu:16.04","text":"使用镜像从 Docker 镜像仓库获取镜像的命令 命令格式 sudo docker pull [选项] [url : 端口号]/镜像名[:标签] 此处的url 默认为Docker Hub 标签可忽略，默认为latest 举个例子 $ docker pull ubuntu:16.04 运行容器（容器是镜像的一个实例） 输入命令 sudo docker run -it -rm 镜像名[:标签] bash -it：这里包括两个参数 -i：交互式参数-t：终端 –rm：这个参数是说容器退出之后随之将其删除 bash启动交互式shell exit命令退出 列出镜像 命令 sudo docker images 列表包含了 仓库名（镜像名）、标签、镜像 ID、创建时间 以及 所占用的空间 镜像 ID 则是镜像的唯一标识 一个镜像可以对应多个标签 docker images 列表中的镜像体积总和并非是所有镜像实际硬盘消耗 因为不同镜像可能会因为使用相同的基础镜像，从而拥有共同的层，相同的层只需要保存一份即可，因此实际镜像硬盘占用空间很可能要比这个列表镜像大小的总和要小的多 镜像体积 宿主标识的镜像空间和Docker Hub上的不同，Docker Hub上的是经过压缩的 命令：docker system df可查看镜像、容器、数据卷所占用的空间 虚悬镜像 这个镜像既没有仓库名，也没有标签，均为 删除镜像 命令 sudo docker image rm &lt;Image_ID&gt; ID一般取前3个字符以上，只要足够区分于别的镜像便可成功删除 可以添加 -f 参数,可删除正在运行的容器 docker container prune 命令可以清理所有处于终止状态的容器","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"https://wt-git-repository.github.io/tags/docker/"}]},{"title":"Dockerfile 相关指令","slug":"Dockerfile-相关指令","date":"2019-03-06T12:55:54.000Z","updated":"2019-07-08T01:15:52.669Z","comments":true,"path":"2019/03/06/Dockerfile-相关指令/","link":"","permalink":"https://wt-git-repository.github.io/2019/03/06/Dockerfile-相关指令/","excerpt":"Dockerfile指令全解FROM 指定基础镜像注：scratch是空白镜像如：FROM mysql","text":"Dockerfile指令全解FROM 指定基础镜像注：scratch是空白镜像如：FROM mysql RUN 执行命令每一个run指令都会新建一层，并在其上执行这些命令，执行接收，commit这一层的修改，便构成了新的镜像如:RUN apt-get update一般来说，只需构建一层便可举个例子FROM debian:jessie RUN buildDeps=’gcc libc6-dev make’ \\ &amp;&amp; apt-get update \\ &amp;&amp; apt-get install -y $buildDeps \\ 构建镜像 在Dockerfile文件所在的目录执行命令docker build [选项] &lt;上下文路径/URL/-&gt;例如 docker build -t nginx:v3 .其中 －t nginx:v3 是指定镜像名称 最后一个 . 是指当前目录","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"https://wt-git-repository.github.io/tags/docker/"}]},{"title":"JAVA 编程规约","slug":"JAVA-编程规约","date":"2019-03-06T12:54:51.000Z","updated":"2019-07-08T01:15:52.669Z","comments":true,"path":"2019/03/06/JAVA-编程规约/","link":"","permalink":"https://wt-git-repository.github.io/2019/03/06/JAVA-编程规约/","excerpt":"编程规约(一) 命名风格 代码中的命名均不能以 下划线或美元符号 开始， 也不能以 下划线或美元符号 结束 代码中的命名禁止使用拼音与中文混合的方式， 应当使用正确的英文拼写，杜绝完全不规范的缩写，避免望文不知义, 为了达到代码自解释的目标，任何自定义编程元素在命名时，使用尽量完整的单词组合来表达其意。注 : alibaba/taobao等国际通用的名称，可视同英文","text":"编程规约(一) 命名风格 代码中的命名均不能以 下划线或美元符号 开始， 也不能以 下划线或美元符号 结束 代码中的命名禁止使用拼音与中文混合的方式， 应当使用正确的英文拼写，杜绝完全不规范的缩写，避免望文不知义, 为了达到代码自解释的目标，任何自定义编程元素在命名时，使用尽量完整的单词组合来表达其意。注 : alibaba/taobao等国际通用的名称，可视同英文 类名使用UpperCamelCase风格，但以下情形例外：DO/ BO / DTO/ VO/ AO/ PO/ UID等。如UserDO 方法名、参数名、成员变量、局部变量都统一使用lowerCamelCase风格，必须遵从驼峰形式。 常量命名全部大写，单词间用下划线隔开，力求语义表达完整清楚，不要嫌名字长。 抽象类命名使用Abstract或Base开头 异常类命名使用Exception结尾 测试类命名以它要测试的类的名称开始，以Test结尾。 定义整形数组int[] arrayDemo POJO类中布尔类型的变量，都不要加is前缀，否则部分框架解析会引起序列化错误。（重要） 包名统一使用小写, 单数形式 类名如果有复数含义，类名可以使用复数形式 如果模块、接口、类、方法使用了设计模式，在命名时需体现出具体模式。如 public classOrder Factory； public class LoginProxy； 接口类的方法和属性不要添加任何的修饰符号(public 也不能添加), 以求保持代码的简洁性能，而且接口类的变量均为与接口方法相关的常量． 接口和实现类的命名有两套规则 对于Service和DAO类, 暴露出来的服务一定是接口，而其中的实现类命名以Impl为后缀 枚举类名建议带上Enum后缀，枚举成员名称需要全大写，单词间用下划线隔开 各层命名规约整合 Service/DAO层方法命名规约 获取单个对象的方法用get做前缀获取多个对象的方法用list做前缀，复数形式结尾如：listObjects获取统计值的方法用count做前缀插入的方法用save/insert做前缀删除的方法用remove/delete做前缀修改的方法用update做前缀 领域模型命名规约 数据对象：xxxDO，xxx即为数据表名数据传输对象：xxxDTO，xxx为业务领域相关的名称展示对象：xxxVO，xxx一般为网页名称POJO是DO/DTO/BO/VO的统称，禁止命名成xxxPOJO (二) 常量定义 不允许任何魔法值（即未经预先定义的常量）直接出现在代码中 在long或者Long赋值时，数值后使用大写的L如: public Long data = 2L; 不要使用一个常量类维护所有常量，要按常量功能进行归类，分开维护。 常量的复用层次有五层：跨应用共享常量、应用内共享常量、子工程内共享常量、包内共享常量、类内共享常量。 跨应用共享常量：放置在二方库中，通常是client.jar中的constant目录下。应用内共享常量：放置在一方库中，通常是子模块中的constant目录下。子工程内部共享常量：即在当前子工程的constant目录下。包内共享常量：即在当前包下单独的constant目录下。类内共享常量：直接在类内部private static final定义。 如果变量值仅在一个固定范围内变化用enum类型来定义注：注意区分常量类和枚举类的区别 (三) 代码格式对于代码格式的规范，阿里巴巴给出了一个正例，这个例子基本囊括了所以基本的规范操作1234567891011121314151617public class Main &#123; public static void main(String[] args) &#123; // 注释的双斜线与注释内容之间有且仅有一个空格。 // 缩进四格 String say = \"hello\"; // 运算符左右必须有一个空格 int flag = 0; // if语句与括号之间必须有一个空格, 左大括号前加空格不换行， 左大括号后换行 if (flag == 0) &#123; System.out.println(say); //右大括号前换行，右大括号有else， 不用换行 &#125; else &#123; System.out.println(\"ok\"); //右大括号结束必须换行 &#125; &#125;&#125; 补充 单行字符数限制不超过120个，超出需要换行，换行时遵循如下原则 第二行相对第一行缩进4个空格，从第三行开始，不再继续缩进运算符与下文一起换行方法调用的点符号与下文一起换行方法调用中的多个参数需要换行时，在逗号后进行在括号前不要换行 方法参数在定义和传入时，多个参数逗号后边必须加空格，如method(args1, args2, args3); IDE的textfileencoding设置为UTF-8;IDE中文件的换行符使用Unix格式，不要使用Windows格式。 单个方法的总行数不超过80行 不同逻辑、不同语义、不同业务的代码之间插入一个空行分隔开来以提升可读性。 (四) OOP(面向对象程序设计)规约 避免通过一个类的对象引用访问此类的静态变量或静态方法，无谓增加编译器解析成本，直接用类名来访问即可。 所有的覆写方法，必须加@Override注解。 相同参数类型，相同业务含义，才可以使用Java的可变参数，避免使用Object 不能使用过时的类或方法, 接口过时必须加@Deprecated注解，作为调用方来说，有义务去考证过时方法的新实现是什么 Object的equals方法容易抛空指针异常，应使用常量或确定有值的对象来调用equals，如”test”.equals(object)此处，阿里巴巴推荐使用java.util.Objects#equals（JDK7引入的工具类） 所有的相同类型的包装类对象之间值的比较，全部使用equals方法比较。 所有的POJO类属性必须使用包装数据类型 定义DO/DTO/VO等POJO类时，不要设定任何属性默认值 POJO类必须写toString方法 序列化类新增属性时，请不要修改serialVersionUID字段，避免反序列失败；如果完全不兼容升级，避免反序列化混乱，那么请修改serialVersionUID值。 构造方法里面禁止加入任何业务逻辑，如果有初始化逻辑，请放在init方法中。 禁止在POJO类中，同时存在对应属性xxx的isXxx()和getXxx()方法 使用索引访问用String的split方法得到的数组时，需做最后一个分隔符后有无内容的检查，否则会有抛IndexOutOfBoundsException的风险。 当一个类有多个构造方法，或者多个同名方法，这些方法应该按顺序放置在一起，便于阅读，此条规则优先于第16条规则 类内方法定义的顺序依次是：公有方法或保护方法&gt; 私有方法&gt; getter/setter方法说明：公有方法是类的调用者和维护者最关心的方法，首屏展示最好；保护方法虽然只是子类关心，也可能是“模板设计模式”下的核心方法；而私有方法外部一般不需要特别关心，是一个黑盒实现；因为承载的信息价值较低，所有Service和DAO的getter/setter方法放在类体最后 setter方法中，参数名称与类成员变量名称一致，this.成员名=参数名。在getter/setter方法中，不要增加业务逻辑，增加排查问题的难度。 循环体内，字符串的连接方式，使用StringBuilder的append方法进行扩展，避免资源浪费 final可以声明类、成员变量、方法、以及本地变量，下列情况使用final关键字 不允许被继承的类，如：String类。不允许修改引用的域对象。不允许被重写的方法，如：POJO类的setter方法。 不允许运行过程中重新赋值的局部变量.避免上下文重复使用一个变量，使用final描述可以强制重新定义一个变量，方便更好地进行重构。 慎用Object的clone方法来拷贝对象，因为clone方法默认的是浅拷贝 类成员与方法访问控制从严 如果不允许外部直接通过new来创建对象，那么构造方法必须是private。工具类不允许有public或default构造方法类非static成员变量并且与子类共享，必须是protected类非static成员变量并且仅在本类使用，必须是private类static成员变量如果仅在本类使用，必须是private若是static成员变量，考虑是否为final类成员方法只供类内部调用，必须是private类成员方法只对继承类公开，那么限制为protected 注:任何类、方法、参数、变量，严控访问范围。过于宽泛的访问范围，不利于模块解耦。 (五) 集合处理 当equals()方法被override时，hashCode()也要被override。按照一般hashCode()方法的实现来说，相等的对象，它们的hash code一定相等。 因为Set存储的是不重复的对象，依据hashCode和equals进行判断，所以Set存储的对象必须重写这两个方法如果自定义对象作为Map的键，那么必须重写hashCode和equalsString重写了hashCode和equals方法，所以我们可以非常愉快地使用String对象作为key来使用 ArrayList的subList结果不可强转成ArrayList，否则会抛出ClassCastException subList返回的是ArrayList的内部类SubList，并不是ArrayList而是ArrayList的一个视图，对于SubList子列表的所有操作最终会反映到原列表上在subList场景中，高度注意对原集合元素的增加或删除，均会导致子列表的遍历、增加、删除产生ConcurrentModificationException异常。 使用集合转数组的方法，必须使用集合的toArray(T[]array)，传入的是类型完全一样的数组，大小就是list.size() 直接使用toArray无参方法存在问题，此方法返回值只能是Object[]类，若强转其它类型数组将出现ClassCastException错误。正例:String[] array = new String[list.size()];array = list.toArray(array); 使用工具类Arrays.asList()把数组转换成集合时，不能使用其修改集合相关的方法，它的add/remove/clear方法会抛出UnsupportedOperationException异常 asList的返回对象是一个Arrays内部类，并没有实现集合的修改方法。Arrays.asList体现的是适配器模式，只是转换接口，后台的数据仍是数组String[] str = new String[] { “you”, “wu” };Listlist = Arrays.asList(str);第一种情况：list.add(“yangguanbao”); 运行时异常。第二种情况：str[0]= “gujin”;那么list.get(0)也会随之修改。 泛型通配符&lt;? extendsT&gt;来接收返回的数据，此写法的泛型集合不能使用add方法，而&lt;? superT&gt;不能使用get方法，作为接口调用赋值时易出错 繁往外读取内容的，适合用&lt;? extendsT&gt;经常往里插入的，适合用&lt;? superT&gt; 不要在foreach循环里进行元素的remove/add操作。remove元素请使用Iterator方式，如果并发操作，需要对Iterator对象加锁。iterator.remove. 在JDK7版本及以上，Comparator实现类要满足如下三个条件，不然Arrays.sort，Collections.sort会报IllegalArgumentException异常。 x，y的比较结果和y，x的比较结果相反x&gt;y，y&gt;z，则x&gt;zx=y，则x，z比较结果和y，z比较结果相同 集合泛型定义时，在JDK7及以上，使用diamond语法或全省略。说明：菱形泛型，即diamond，直接使用&lt;&gt;来指代前边已经指定的类型。 1234// &lt;&gt; diamond方式HashMap&lt;String, String&gt; userCache = new HashMap&lt;&gt;(16);// 全省略方式ArrayList&lt;User&gt; users = new ArrayList(10); 集合初始化时，指定集合初始值大小。 initialCapacity=(需要存储的元素个数/负载因子) + 1。注意负载因子（即loader factor）默认为0.75，如果暂时无法确定初始值大小，请设置为16（即默认值）。 使用entrySet遍历Map类集合KV，而不是keySet方式进行遍历 keySet其实是遍历了2次，一次是转为Iterator对象，另一次是从hashMap中取出key所对应的value。而entrySet只是遍历了一次就把key和value都放到了entry中，效率更高。如果是JDK8，使用Map.foreach方法 高度注意Map类集合K/V能不能存储null值的情况 利用Set元素唯一的特性，可以快速对一个集合进行去重操作，避免使用List的contains方法进行遍历、对比、去重操作。 合理利用好集合的有序性(sort)和稳定性(order)，避免集合的无序性(unsort)和不稳定性(unorder)带来的负面影响 有序性是指遍历的结果是按某种比较规则依次排列的稳定性指集合每次遍历的元素次序是一定的如：ArrayList是order/unsort；HashMap是unorder/unsort；TreeSet是order/sort (六) 并发处理 获取单例对象需要保证线程安全，其中的方法也要保证线程安全 资源驱动类、工具类、单例工厂类都需要注意。 创建线程或线程池时请指定有意义的线程名称，方便出错时回溯 线程资源必须通过线程池提供，不允许在应用中自行显式创建线程 线程池不允许使用Executors去创建，而是通过ThreadPoolExecutor的方式 SimpleDateFormat是线程不安全的类，一般不要定义为static变量，如果定义为static，必须加锁，或者使用DateUtils工具类。 如果是JDK8的应用，可以使用Instant代替Date，LocalDateTime代替Calendar，DateTimeFormatter代替SimpleDateFormat，官方给出的解释：simplebeautifulstrongimmutablethread-safe 高并发时，同步调用应该去考量锁的性能损耗。能用无锁数据结构，就不要用锁；能锁区块，就不要锁整个方法体；能用对象锁，就不要用类锁 尽可能使加锁的代码块工作量尽可能的小，避免在锁代码块中调用RPC方法 对多个资源、数据库表、对象同时加锁时，需要保持一致的加锁顺序，否则可能会造成死锁 举个例子：线程一需要对表A、B、C依次全部加锁后才可以进行更新操作，那么线程二的加锁顺序也必须是A、B、C，否则可能出现死锁。 并发修改同一记录时，避免更新丢失，需要加锁。要么在应用层加锁，要么在缓存加锁，要么在数据库层使用乐观锁，使用version作为更新依据 如果每次访问冲突概率小于20%，推荐使用乐观锁，否则使用悲观锁。乐观锁的重试次数不得小于3次 多线程并行处理定时任务时，Timer运行多个TimeTask时，只要其中之一没有捕获抛出的异常，其它任务便会自动终止运行，使用ScheduledExecutorService则没有这个问题 使用CountDownLatch进行异步转同步操作，每个线程退出前必须调用countDown方法，线程执行代码注意catch异常，确保countDown方法被执行到，避免主线程无法执行至await方法，直到超时才返回结果 注意，子线程抛出异常堆栈，不能在主线程try-catch到 避免Random实例被多线程使用，虽然共享该实例是线程安全的，但会因竞争同一seed导致的性能下降 在JDK7之后，可以直接使用APIThreadLocalRandom，而在JDK7之前，需要编码保证每个线程持有一个实例 在并发场景下，通过双重检查锁（double-checkedlocking）实现延迟初始化的优化问题隐患(可参考The”Double-CheckedLockingisBroken” Declaration)，推荐解决方案中较为简单一种（适用于JDK5及以上版本），将目标属性声明为volatile型 HashMap在容量不够进行resize时由于高并发可能出现死链，导致CPU飙升，在开发过程中可以使用其它数据结构或加锁来规避此风险 ThreadLocal无法解决共享对象的更新问题，ThreadLocal对象建议使用static修饰。这个变量是针对一个线程内所有操作共享的，所以设置为静态变量，所有此类实例共享此静态变量，也就是说在类第一次被使用时装载，只分配一块存储空间，所有此类的对象(只要是这个线程内定义的)都可以操控这个变量(六) 控制语句 在一个switch块内，每个case要么通过break/return等来终止，要么注释说明程序将继续执行到哪一个case为止；在一个switch块内，都必须包含一个default语句并且放在最后，即使空代码 在if/else/for/while/do语句中必须使用大括号。 在高并发场景中，避免使用”等于”判断作为中断或退出的条件 表达异常的分支时，少用if-else方式，这种方式可以改写成12345if (condition) &#123;...return obj;&#125;// 接着写else的业务逻辑代码; 如果非得使用if()…else if()…else…方式表达逻辑，【强制】避免后续代码维护困难，请勿超过3层超过3层的if-else的逻辑判断代码可以使用卫语句、策略模式、状态模式等来实现 其中卫语句示例如下：1234567891011121314public void today() &#123;if (isBusy()) &#123;System.out.println(“change time.”);return;&#125;if (isFree()) &#123;System.out.println(“go to travel.”);return;&#125;System.out.println(“stay at home to learn Alibaba Java Coding Guidelines.”);return;&#125; 除常用方法（如getXxx/isXxx）等外，不要在条件判断中执行其它复杂的语句，将复杂逻辑判断的结果赋值给一个有意义的布尔变量名，以提高可读性。如： 1finalboolean existed = (file.open(fileName, &quot;w&quot;) != null) &amp;&amp;(...) || (...);finalboolean existed = (file.open(fileName, &quot;w&quot;) != null) &amp;&amp;(...) || (...); 循环体中的语句要考量性能，以下操作尽量移至循环体外处理，如定义对象、变量、获取数据库连接，进行不必要的try-catch操作（这个try-catch是否可以移至循环体外）。 避免采用取反逻辑运算符 – ! 接口入参保护，这种场景常见的是用作批量操作的接口 下列情形，需要进行参数校验 调用频次低的方法执行时间开销很大的方法。此情形中，参数校验时间几乎可以忽略不计，但如果因为参数错误导致中间执行回退，或者错误，那得不偿失需要极高稳定性和可用性的方法对外提供的开放接口，不管是RPC/API/HTTP接口敏感权限入口 下列情形，不需要进行参数校验 极有可能被循环调用的方法。但在方法说明里必须注明外部参数检查要求底层调用频度比较高的方法。毕竟是像纯净水过滤的最后一道，参数错误不太可能到底层才会暴露问题。一般DAO层与Service层都在同一个应用中，部署在同一台服务器中，所以DAO的参数校验，可以省略被声明成private只会被自己代码所调用的方法，如果能够确定调用方法的代码传入参数已经做过检查或者肯定不会有问题，此时可以不校验参数 (八) 代码规约 类、类属性、类方法的注释必须使用Javadoc规范，使用/*内容/格式，不得使用//xxx方式。 在IDE编辑窗口中，Javadoc方式会提示相关注释，生成Javadoc可以正确输出相应注释；在IDE中，工程调用方法时，不进入方法即可悬浮提示方法、参数、返回值的意义，提高阅读效率 所有的抽象方法（包括接口中的方法）必须要用Javadoc注释、除了返回值、参数、异常说明外，还必须指出该方法做什么事情，实现什么功能。 所有的类都必须添加创建者和创建日期 方法内部单行注释，在被注释语句上方另起一行，使用//注释。方法内部多行注释使用/ /注释，注意与代码对齐 所有的枚举类型字段必须要有注释，说明每个数据项的用途 与其“半吊子”英文来注释，不如用中文注释把问题说清楚。专有名词与关键字保持英文原文即可 代码修改的同时，注释也要进行相应的修改，尤其是参数、返回值、异常、核心逻辑等的修改 注释的要求： 第一、能够准确反应设计思想和代码逻辑第二、能够描述业务含义，使别的程序员能够迅速了解到代码背后的信息第三、注释力求精简准确、表达到位, 避免泛滥 特殊注释标记，请注明标记人与标记时间。注意及时处理这些标记，通过标记扫描，经常清理此类标记。线上故障有时候就是来源于这些标记处的代码 待办事宜（TODO）:（标记人，标记时间，[预计处理时间]）错误，不能工作（FIXME）:（标记人，标记时间，[预计处理时间]） (九)其它 在使用正则表达式时，利用好其预编译功能，可以有效加快正则匹配速度 说明：不要在方法体内定义：Patternpattern= Pattern.compile(“规则”) velocity调用POJO类的属性时，建议直接使用属性名取值即可，模板引擎会自动按规范调用POJO的getXxx()，如果是boolean基本数据类型变量（boolean命名不需要加is前缀），会自动调用isXxx()方法 后台输送给页面的变量必须加$!{var}——中间的感叹号 如果var等于null或者不存在，那么${var}会直接显示在页面上 注意Math.random()这个方法返回是double类型，注意取值的范围0≤x&lt;1（能够取到零值，注意除零异常），如果想获取整数类型的随机数,直接使用Random对象的nextInt或者nextLong方法 获取当前毫秒数System.currentTimeMillis();而不是newDate().getTime(); 如果想获取更加精确的纳秒级时间值，使用System.nanoTime()的方式。在JDK8中，针对统计时间等场景，推荐使用Instant类 不要在视图模板中加入任何复杂的逻辑 根据MVC理论，视图的职责是展示，不要抢模型和控制器的活 任何数据结构的构造或初始化，都应指定大小，避免数据结构无限增长吃光内存 及时清理不再使用的代码段或配置信息","categories":[],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"https://wt-git-repository.github.io/tags/JAVA/"}]}]}